{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "endToEndMemoryNetwork.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFUxjJECZlA7",
        "colab_type": "text"
      },
      "source": [
        "## Question Answering System using End to End Memory Networks..sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvFckIgvZlBB",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXPEo9yiZlBE",
        "colab_type": "code",
        "outputId": "261a4661-4571-4ca1-a8ba-4c689044fa22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Permute, dot, add, concatenate\n",
        "from keras.layers import LSTM, Dense, Dropout, Input, Activation\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from functools import reduce\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65OUlxGyZlBP",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ApTbsFLZlBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sent):\n",
        "    return [ x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKkzmV8WZlBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_stories(lines):\n",
        "    '''Parse stories provided in the bAbi tasks format\n",
        "    '''\n",
        "    data = []\n",
        "    story = []\n",
        "    for line in lines:\n",
        "        line = line.decode('utf-8').strip()\n",
        "        nid, line = line.split(' ', 1)\n",
        "        nid = int(nid)\n",
        "        if nid == 1:\n",
        "            story = []\n",
        "        if '\\t' in line:\n",
        "            print(line)\n",
        "            q, a, supporting = line.split('\\t')\n",
        "            q = tokenize(q)\n",
        "            # Provide all the substories\n",
        "            substory = [x for x in story if x]\n",
        "            data.append((substory, q, a))\n",
        "            story.append('')\n",
        "        else:\n",
        "            sent = tokenize(line)\n",
        "            story.append(sent)\n",
        "    return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkJ65tmDZlBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stories(f):\n",
        "    data = parse_stories(f.readlines())\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "    data = [(flatten(story), q, answer) for story, q, answer in data]\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8-ARVvkZlBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
        "    X = []\n",
        "    Xq = []\n",
        "    Y = []\n",
        "    for story, query, answer in data:\n",
        "        x = [word_idx[w] for w in story]\n",
        "        xq = [word_idx[w] for w in query]\n",
        "        # let's not forget that index 0 is reserved\n",
        "        y = np.zeros(len(word_idx) + 1)\n",
        "        y[word_idx[answer]] = 1\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "    return (pad_sequences(X, maxlen=story_maxlen),\n",
        "            pad_sequences(Xq, maxlen=query_maxlen), np.array(Y))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIhFHabfZlBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainingVisualizer(keras.callbacks.History):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        super().on_epoch_end(epoch, logs)\n",
        "        IPython.display.clear_output(wait=True)\n",
        "        pd.DataFrame({key: value for key, value in self.history.items() if key.endswith('loss')}).plot()\n",
        "        axes = pd.DataFrame({key: value for key, value in self.history.items() if key.endswith('acc')}).plot()\n",
        "        axes.set_ylim([0, 1])\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3ZnpMxL0D0b",
        "colab_type": "code",
        "outputId": "8c80578d-c3d5-433f-e8f7-43d5c90eb26b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-57ETmA7FtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cd '/content/gdrive/My Drive/course_allocation_keywords/theOne/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOXGkKmnZlBt",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIpuwKv-yrUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='/content/gdrive/My Drive/course_allocation_keywords/theOne/tasks_1-20_v1-2.tar.gz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_LIjVJJfEhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tar = tarfile.open(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfLcoOQVf4Wn",
        "colab_type": "code",
        "outputId": "78241ef8-3d8c-46ed-c325-0bde2d6b48c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/course_allocation_keywords/theOne/tasks_1-20_v1-2.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8YY_zSOZlBy",
        "colab_type": "text"
      },
      "source": [
        "## Getting train and test stories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzYADBporG_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZMjT5CAZlBz",
        "colab_type": "code",
        "outputId": "3ee49630-91a4-4abf-da44-4289ab232023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'\n",
        "\n",
        "print('Extracting stories for the challenge: single_supporting_fact_10k')\n",
        "train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
        "test_stories = get_stories(tar.extractfile(challenge.format('test')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting stories for the challenge: single_supporting_fact_10k\n",
            "Who is teaching ObjectOrientedProgramming(CS217) to sectionA Batch2018 ?\tMr.HassanMustafa\t1\n",
            "Who is teaching ObjectOrientedProgramming(CS217) to sectionB Batch2018 ?\tMr.HassanMustafa\t2\n",
            "Who is teaching ObjectOrientedProgramming(CS217) to sectionD Batch2018 ?\tMs.AtifaSarwar\t2\n",
            "Who is teaching ObjectOrientedProgramming(CS217) to sectionE Batch2018 ?\tDr.MuhammadArshadIslam\t1\n",
            "Who is teaching ObjectOrientedProgramming(CS217) to sectionF Batch2018 ?\tMr.JawadHassan\t2\n",
            "Who is teaching DigitalLogicDesign(EE227) to sectionA Batch2018 ?\tDr.MehwishHassan\t2\n",
            "Who is teaching DigitalLogicDesign(EE227) to sectionB Batch2018 ?\tDr.MehwishHassan\t1\n",
            "Who is teaching DigitalLogicDesign(EE227) to sectionA Batch2018 ?\tDr.MehwishHassan\t2\n",
            "Who is teaching DigitalLogicDesign(EE227) to sectionE Batch2018 ?\tMs.MehreenAlam\t2\n",
            "Who is teaching DigitalLogicDesign(EE227) to sectionF Batch2018 ?\tMs.SanaHassan\t1\n",
            "Who is teaching ProgrammingFundamentals(CS118) to sectionA Batch2018 Repeat ?\tMr.JawadHassan\t1\n",
            "Who is teaching ProgrammingFundamentals(CS118) to sectionB Batch2018 Repeat ?\tMr.JawadHassan\t2\n",
            "Who is teaching ProgrammingFundamentals(CS118) to sectionC Batch2018 Repeat ?\tMr.JawadHassan\t1\n",
            "Who is teaching DatabaseSystems(CS203) to sectionA Batch2017 ?\tDr.EjazAhmed\t2\n",
            "Who is teaching DatabaseSystems(CS203) to sectionC Batch2017 ?\tDr.AsmaAhmad\t2\n",
            "Who is teaching DatabaseSystems(CS203) to sectionE Batch2017 ?\tDr.AsmaAhmad\t2\n",
            "Who is teaching OperatingSystems(CS205) to sectionA Batch2017 ?\tDr.HasanMujtaba\t1\n",
            "Who is teaching OperatingSystems(CS205) to sectionC Batch2017 ?\tDr.MuhammadAdnanTariq\t1\n",
            "Who is teaching OperatingSystems(CS205) to sectionF Batch2017 ?\tMs.SidraKhalid\t2\n",
            "Who is teaching OperatingSystems(CS205) to sectionD Batch2017 ?\tDr.MuhammadAdnanTariq\t2\n",
            "Who is teaching ComputerArchitecture(EE204) to sectionA Batch2017 ?\tDr.AtifMughees\t1\n",
            "Who is teaching ComputerArchitecture(EE204) to sectionB Batch2017 ?\tDr.OmerBeg\t2\n",
            "Who is teaching ComputerArchitecture(EE204) to sectionC Batch2017 ?\tDr.OmerBeg\t1\n",
            "Who is teaching ComputerArchitecture(EE204) to sectionE Batch2017 ?\tMr.ShamsFarooq\t1\n",
            "Who is teaching ComputerOrganization&AssemblyLanguage(EE213) to sectionA Batch2017 Repeat ?\tMs.SabaRasheedMalik\t1\n",
            "Who is teaching DataStructures(CS201) to sectionA Batch2017 Repeat ?\tMr.HafizTayyebJaved\t1\n",
            "Who is teaching DataStructures(CS201) to sectionB Batch2017 Repeat ?\tMr.HafizTayyebJaved\t2\n",
            "Who is teaching Design&AnalysisofAlgorithms(CS302) to sectionA Batch2016 ?\tMr.ShujaatHussain\t1\n",
            "Who is teaching Design&AnalysisofAlgorithms(CS302) to sectionD Batch2016 ?\tMs.AmnaIrum\t2\n",
            "Who is teaching Design&AnalysisofAlgorithms(CS302) to sectionE Batch2016 ?\tMs.AmnaIrum\t1\n",
            "Who is teaching SoftwareEngineering(CS303) to sectionA Batch2016 ?\tDr.IrumInayat\t1\n",
            "Who is teaching SoftwareEngineering(CS303) to sectionC Batch2016 ?\tDr.ArshadAliShahid\t1\n",
            "Who is teaching SoftwareEngineering(CS303) to sectionE Batch2016 ?\tDr.LabibaFahad\t1\n",
            "Who is teaching SoftwareEngineering(CS303) to sectionE Batch2016 ?\tDr.LabibaFahad\t1\n",
            "Who is teaching WebProgramming(CS406) to sectionA Batch2016 ?\tDr.AtifJilani\t1\n",
            "Who is teaching WebProgramming(CS406) to sectionB Batch2016 ?\tMs.AtifaSarwar\t2\n",
            "Who is teaching WebProgramming(CS406) to sectionB Batch2016 ?\tMs.AtifaSarwar\t1\n",
            "Who is teaching MobileComputing(CS575) to sectionA Batch2016 ?\tDr.MuhammadAdnanTariq\t1\n",
            "Who is teaching DataMining(CS429) to sectionA Batch2016 ?\tDr.OmerIshaq\t1\n",
            "Who is teaching DataMining(CS429) to sectionB Batch2016 ?\tDr.OmerIshaq\t2\n",
            "Who is teaching ObjectOrientedAnalysis&Design(CS309) to sectionA Batch2016 ?\tDr.ArshadAliShahid\t1\n",
            "Who is teaching Project-II(CS492) to sectionA Batch2015 ?\tDr.AmnaBasharat\t1\n",
            "Who is teaching Project-I(CS491) to sectionA Batch2015 ?\tDr.AmnaBasharat\t1\n",
            "Who is teaching Project-II(CS492) to sectionC Batch2015 ?\tMr.HassanMustafa\t2\n",
            "Who is teaching Project-II(CS492) to sectionD Batch2015 ?\tMr.HassanMustafa\t1\n",
            "Who is teaching Project-II(CS492) to sectionC Batch2015 ?\tMr.HassanMustafa\t1\n",
            "Who is teaching ProfessionalIssuesinIT(CS449) to sectionA Batch2015 ?\tMs.NoorulAin\t1\n",
            "Who is teaching ProfessionalIssuesinIT(CS449) to sectionD Batch2015 ?\tMs.UzmaBibi\t2\n",
            "Who is teaching ProfessionalIssuesinIT(CS449) to sectionC Batch2015 ?\tMs.NoorulAin\t1\n",
            "Who is teaching HumanComputerInteraction(CS422) to sectionA Batch2015 Repeat ?\tMr.HafizTayyebJaved\t2\n",
            "Who is teaching NetworkSecurity(CS411) to sectionA Batch2015 ?\tDr.MuhammadAsim\t1\n",
            "Who is teaching NetworkSecurity(CS411) to sectionB Batch2015 ?\tDr.MuhammadAsim\t2\n",
            "Who is teaching MobileComputing(CS575) to sectionA Batch2015 ?\tDr.MuhammadAdnanTariq\t1\n",
            "Who is teaching UserExperienceEngineering(CS5107) to sectionB Batch2015 ?\tMs.SabaRasheedMalik\t1\n",
            "Who is teaching UserExperienceEngineering(CS5107) to sectionA Batch2015 ?\tMs.SabaRasheedMalik\t2\n",
            "Who is teaching Parallel&DistributedComputing(CS416) to sectionA Batch2015 ?\tDr.EhteshamZahoor\t1\n",
            "Who is teaching SoftwareTesting(CS497) to sectionA Batch2015 ?\tMs.UzmaBibi\t1\n",
            "Who is teaching SocialNetworksAnalysis(CS5115) to sectionA Batch2015 ?\tDr.MuhammadArshadIslam\t2\n",
            "Who is teaching Bio-Informatics(CS508) to sectionA Batch2015 ?\tDr.HammadNaveed\t1\n",
            "Who is teaching IntrotoSoftwareProjectManagement(CS450) to sectionA Batch2015 ?\tDr.NaveedAhmad\t1\n",
            "Who is teaching AdvancedAnalysisofAlgorithms(CS501) to sectionY1 MS(CS) ?\tDr.HammadMajeed\t2\n",
            "Who is teaching AdvancedAnalysisofAlgorithms(CS501) to sectionY2 MS(CS) ?\tDr.HammadMajeed\t1\n",
            "Who is teaching TheoryofProgrammingLanguages(CS507) to sectionY MS(CS) ?\tDr.LabibaFahad\t2\n",
            "Who is teaching CyberandNetworkSecurity(CS630) to sectionY MS(CS) ?\tDr.MuhammadAsim\t1\n",
            "Who is teaching MobileComputing(CS575) to sectionY MS(CS) ?\tDr.MuhammadAdnanTariq\t2\n",
            "Who is teaching AdvancedDatabaseSystem(CS502) to sectionY MS(CS) ?\tDr.EjazAhmed\t1\n",
            "Who is teaching CloudComputing(CS579) to sectionY MS(CS) ?\tDr.EhteshamZahoor\t1\n",
            "Who is teaching ComputationalIntelligence(CS549) to sectionY MS(CS) ?\tDr.WaseemShahzad\t1\n",
            "Who is teaching AppliedImageProcessing(CS553) to sectionY MS(CS) ?\tDr.OmerIshaq\t2\n",
            "Who is teaching EvolutionaryComputations(CS566) to sectionY MS(CS) ?\tDr.HasanMujtaba\t1\n",
            "Who is teaching Bio-Informatics(CS508) to sectionY MS(CS) ?\tDr.HammadNaveed\t1\n",
            "Who is teaching MSThesis-1(CS591) to section Y MS(CS) ?\tDr.WaseemShahzad\t1\n",
            "Who is teaching CyberandNetworkSecurity(CS630) to sectionZ MS(CNS) ?\tDr.MuhammadAsim\t1\n",
            "Who is teaching ComputationalIntelligence(CS549) to sectionZ MS(CNS) ?\tDr.WaseemShahzad\t1\n",
            "Who is teaching SocialNetworksAnalysis(CS5115) to sectionZ MS(CNS) ?\tDr.MuhammadArshadIslam\t2\n",
            "Who is teaching AdvancedQualityAssurance(SE501) to sectionX MS(SE) ?\tDr.UzairKhan\t2\n",
            "Who is teaching AdvancedSoftwareRequirementsEngineering(SE502) to sectionX MS(SE) ?\tDr.IrumInayat\t1\n",
            "Who is teaching SoftwareProcessModeling(CS516) to sectionX MS(SE) ?\tDr.NaveedAhmad\t1\n",
            "Who is teaching EvolutionaryComputations(CS566) to sectionX MS(SE) ?\tDr.HasanMujtaba\t1\n",
            "Who is teaching MSThesis-2(SE592) to sectionX MS(SE) ?\tDr.WaseemShahzad\t1\n",
            "Who is teaching MSThesis-1(SE591) to sectionX MS(SE) ?\tDr.WaseemShahzad\t2\n",
            "Who is teaching BigDataAnalytics(MiningBigDatasets)(DS502) to sectionU1 MS(DS) ?\tDr.KifayatUllahKhan\t2\n",
            "Who is teaching BigDataAnalytics(MiningBigDatasets)(DS502) to sectionU1 MS(DS) ?\tDr.KifayatUllahKhan\t1\n",
            "Who is teaching MachineLearningforDataScience(DS503) to sectionU1 MS(DS) ?\tDr.HammadMajeed\t1\n",
            "Who is teaching AppliedImageProcessing(CS553) to sectionU MS(DS) ?\tDr.OmerIshaq\t2\n",
            "Who is teaching SocialNetworksAnalysis(CS5115) to sectionU MS(DS) ?\tDr.MuhammadArshadIslam\t2\n",
            "Who is teaching SocialNetworksAnalysis(CS5115) to sectionU MS(DS) ?\tDr.MuhammadArshadIslam\t1\n",
            "Who is teaching TopicsinSoftwareEngineering(CS625) to sectionP PhD(SE) ?\tDr.ZohaibZafarIqbal\t1\n",
            "Who is teaching TopicsinSoftwareEngineering(CS625) to sectionP PhD(SE) ?\tDr.ZohaibZafarIqbal\t1\n",
            "Who is teaching Aspect-OrientedSoftwareEngineering(SE601) to sectionP PhD(SE) ?\tDr.UzairKhan\t1\n",
            "Who is teaching AdvancedTopicsinCS(CS628) to sectionP PhD(CS) ?\tDr.HammadNaveed\t2\n",
            "Who is teaching CloudComputing(CS579) to sectionP PhD(SE) ?\tDr.EhteshamZahoor\t1\n",
            "Who is teaching ObjectOrientedProgramming(CS217) to sectionB Batch2018 ?\tMr.HassanMustafa\t2\n",
            "Who is teaching ObjectOrientedProgramming(CS217) to sectionD Batch2018 ?\tMs.AtifaSarwar\t2\n",
            "Who is teaching ObjectOrientedProgramming(CS217) to sectionG Batch2018 ?\tDr.MuhammadArshadIslam\t1\n",
            "Who is teaching DataMining(CS429) to sectionB Batch2016 ?\tDr.OmerIshaq\t2\n",
            "Who is teaching ComputationalIntelligence(CS549) to sectionZ MS(CNS) ?\tDr.WaseemShahzad\t2\n",
            "Who is teaching OperatingSystems(CS205) to sectionB Batch2017 ?\tDr.HasanMujtaba\t2\n",
            "Who is teaching ProfessionalIssuesinIT(CS449) to sectionE Batch2015 ?\tMs.SidraKhalid\t1\n",
            "Who is teaching MultiagentSystems(CS545) to sectionA Batch2015 ?\tDr.OmerBeg\t1\n",
            "Who is teaching MSThesis-2(SE592) to sectionX MS(SE) ?\tDr.WaseemShahzad\t2\n",
            "Who is teaching ComputerOrganization&AssemblyLanguage(EE213) to sectionB Batch2017 Repeat ?\tMs.SaroshShahid\t2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
            "  return _compile(pattern, flags).split(string, maxsplit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qmQY1KCZlB5",
        "colab_type": "code",
        "outputId": "5f664a84-916d-4b52-eb29-a11556b5d187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_stories), len(test_stories)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(92, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "AL_9M4rDZlB9",
        "colab_type": "code",
        "outputId": "f9ce23a0-ac57-472f-8fb5-f8b0b97dba61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "print('Number of training stories:', len(train_stories))\n",
        "print('Number of test stories:', len(test_stories))\n",
        "train_stories[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training stories: 92\n",
            "Number of test stories: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mr',\n",
              "  '.',\n",
              "  'HassanMustafa',\n",
              "  'is',\n",
              "  'teaching',\n",
              "  'ObjectOrientedProgramming',\n",
              "  '(',\n",
              "  'CS217',\n",
              "  ')',\n",
              "  'to',\n",
              "  'sectionA',\n",
              "  'Batch2018',\n",
              "  'Mr',\n",
              "  '.',\n",
              "  'HassanMustafa',\n",
              "  'is',\n",
              "  'teaching',\n",
              "  'ObjectOrientedProgramming',\n",
              "  '(',\n",
              "  'CS217',\n",
              "  ')',\n",
              "  'to',\n",
              "  'sectionB',\n",
              "  'Batch',\n",
              "  '2018'],\n",
              " ['Who',\n",
              "  'is',\n",
              "  'teaching',\n",
              "  'ObjectOrientedProgramming',\n",
              "  '(',\n",
              "  'CS217',\n",
              "  ')',\n",
              "  'to',\n",
              "  'sectionA',\n",
              "  'Batch2018',\n",
              "  '?'],\n",
              " 'Mr.HassanMustafa')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rQcEWfrZlCB",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLgTS6AkZlCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set()\n",
        "for story, q, answer in train_stories + test_stories:\n",
        "    vocab |= set(story + q + [answer])\n",
        "vocab = sorted(vocab)\n",
        "\n",
        "# Reserve 0 for masking via pad_sequences\n",
        "vocab_size = len(vocab) + 1\n",
        "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
        "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
        "\n",
        "\n",
        "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
        "idx_word = dict((i+1, c) for i,c in enumerate(vocab))\n",
        "inputs_train, queries_train, answers_train = vectorize_stories(train_stories,\n",
        "                                                               word_idx,\n",
        "                                                               story_maxlen,\n",
        "                                                               query_maxlen)\n",
        "inputs_test, queries_test, answers_test = vectorize_stories(test_stories,\n",
        "                                                            word_idx,\n",
        "                                                            story_maxlen,\n",
        "                                                            query_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyiNdZXKZlCN",
        "colab_type": "code",
        "outputId": "090ec81b-2ac0-44f4-aa8d-82ea5b1fd43d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "print('-------------------------')\n",
        "print('Vocabulary:\\n',vocab,\"\\n\")\n",
        "print('Vocab size:', vocab_size, 'unique words')\n",
        "print('Story max length:', story_maxlen, 'words')\n",
        "print('Query max length:', query_maxlen, 'words')\n",
        "print('Number of training stories:', len(train_stories))\n",
        "print('Number of test stories:', len(test_stories))\n",
        "print('-------------------------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------\n",
            "Vocabulary:\n",
            " ['&', '(', ')', ') ?', ')(', '))', '-', '.', '1', '2', '2016', '2018', '?', 'A', 'AdnanSaeed', 'AdvancedAnalysisofAlgorithms', 'AdvancedDatabaseSystem', 'AdvancedMobileApplicationDevelopment', 'AdvancedQualityAssurance', 'AdvancedSoftwareRequirementsEngineering', 'AdvancedTopicsinCS', 'AmnaBasharat', 'AmnaIrum', 'AnalysisofAlgorithms', 'AppliedImageProcessing', 'ArshadAliShahid', 'AsmaAhmad', 'Aspect', 'AssemblyLanguage', 'AtifJilani', 'AtifMughees', 'AtifaSarwar', 'BasedSoftwareEngineering', 'Batch', 'Batch2015', 'Batch2016', 'Batch2017', 'Batch2018', 'BigDataAnalytics', 'Bio', 'CN501', 'CNS', 'CS', 'CS118', 'CS201', 'CS203', 'CS205', 'CS217', 'CS302', 'CS303', 'CS307', 'CS309', 'CS406', 'CS411', 'CS416', 'CS422', 'CS429', 'CS449', 'CS450', 'CS464', 'CS491', 'CS492', 'CS497', 'CS501', 'CS502', 'CS507', 'CS508', 'CS5107', 'CS5115', 'CS516', 'CS545', 'CS549', 'CS553', 'CS566', 'CS575', 'CS579', 'CS591', 'CS592', 'CS625', 'CS628', 'CS630', 'CloudComputing', 'ComputationalIntelligence', 'ComputerArchitecture', 'ComputerNetworks', 'ComputerOrganization', 'CyberandNetworkSecurity', 'DS', 'DS500', 'DS502', 'DS503', 'DataMining', 'DataScienceToolsandTechnique', 'DataStructures', 'DatabaseSystems', 'Design', 'DigitalLogicDesign', 'DistributedComputing', 'Dr', 'Dr.AmnaBasharat', 'Dr.ArshadAliShahid', 'Dr.AsmaAhmad', 'Dr.AtifJilani', 'Dr.AtifMughees', 'Dr.EhteshamZahoor', 'Dr.EjazAhmed', 'Dr.HammadMajeed', 'Dr.HammadNaveed', 'Dr.HasanMujtaba', 'Dr.IrumInayat', 'Dr.KifayatUllahKhan', 'Dr.LabibaFahad', 'Dr.MehwishHassan', 'Dr.MuhammadAdnanTariq', 'Dr.MuhammadArshadIslam', 'Dr.MuhammadAsim', 'Dr.NaveedAhmad', 'Dr.OmerBeg', 'Dr.OmerIshaq', 'Dr.UzairKhan', 'Dr.WaseemShahzad', 'Dr.ZohaibZafarIqbal', 'EE204', 'EE213', 'EE227', 'EhteshamZahoor', 'EjazAhmed', 'EvolutionaryComputations', 'HafizTayyebJaved', 'HammadMajeed', 'HammadNaveed', 'HasanMujtaba', 'HassanMustafa', 'HumanComputerInteraction', 'I', 'II', 'Informatics', 'InformaticsforDataScience', 'IntrotoSoftwareProjectManagement', 'IrumInayat', 'JawadHassan', 'KashifMunir', 'KifayatUllahKhan', 'LabibaFahad', 'MS', 'MSThesis', 'MachineLearningforDataScience', 'MehreenAlam', 'MehwishHassan', 'MiningBigDatasets', 'MobileComputing', 'Model', 'Mr', 'Mr.HafizTayyebJaved', 'Mr.HassanMustafa', 'Mr.JawadHassan', 'Mr.ShamsFarooq', 'Mr.ShujaatHussain', 'Ms', 'Ms.AmnaIrum', 'Ms.AtifaSarwar', 'Ms.MehreenAlam', 'Ms.NoorulAin', 'Ms.SabaRasheedMalik', 'Ms.SanaHassan', 'Ms.SaroshShahid', 'Ms.SidraKhalid', 'Ms.UzmaBibi', 'MuhamamdArshadIslam', 'MuhammadAdnanTariq', 'MuhammadArshadIslam', 'MuhammadAsim', 'MultiagentSystems', 'NaveedAhmad', 'NetworkSecurity', 'NoorulAin', 'ObjectOrientedAnalysis', 'ObjectOrientedProgramming', 'OmerBeg', 'OmerIshaq', 'OperatingSystems', 'OrientedSoftwareEngineering', 'Parallel', 'PerformanceofComputerNetworks', 'PhD', 'ProfessionalIssuesinIT', 'ProgrammingFundamentals', 'Project', 'Repeat', 'SE', 'SE501', 'SE502', 'SE506', 'SE507', 'SE591', 'SE592', 'SE601', 'SabaRasheedMalik', 'SanaHassan', 'SaroshShahid', 'Search', 'ShamsFarooq', 'ShujaatHussain', 'SidraKhalid', 'SocialNetworksAnalysis', 'SoftwareEngineering', 'SoftwareProcessModeling', 'SoftwareTesting', 'TheoryofProgrammingLanguages', 'TopicsinSoftwareEngineering', 'UserExperienceEngineering', 'UzairKhan', 'UzmaBibi', 'WaseemShahzad', 'WebProgramming', 'Who', 'Y', 'ZohaibZafarIqbal', 'drivenSoftwareEngineering', 'is', 'section', 'sectionA', 'sectionB', 'sectionC', 'sectionD', 'sectionE', 'sectionF', 'sectionG', 'sectionP', 'sectionU', 'sectionU1', 'sectionX', 'sectionY', 'sectionY1', 'sectionY2', 'sectionZ', 'teaching', 'to'] \n",
            "\n",
            "Vocab size: 239 unique words\n",
            "Story max length: 35 words\n",
            "Query max length: 16 words\n",
            "Number of training stories: 92\n",
            "Number of test stories: 10\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ4pj8rVZlCR",
        "colab_type": "code",
        "outputId": "11525f6c-527b-4a4c-e8a0-63e38827e6c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print('-------------------------')\n",
        "print('inputs: integer tensor of shape (samples, max_length)')\n",
        "print('inputs_train shape:', inputs_train.shape)\n",
        "print('inputs_test shape:', inputs_test.shape)\n",
        "print('input train sample', inputs_train[0,:])\n",
        "print('-------------------------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------\n",
            "inputs: integer tensor of shape (samples, max_length)\n",
            "inputs_train shape: (92, 35)\n",
            "inputs_test shape: (10, 35)\n",
            "input train sample [  0   0   0   0   0   0   0   0   0   0 153   8 133 220 237 178   2  48\n",
            "   3 238 222  38 153   8 133 220 237 178   2  48   3 238 223  34  12]\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD7DSbM-ZlCU",
        "colab_type": "code",
        "outputId": "41f63e02-3a99-4c6a-80b8-7fbd3fe50c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('-------------------------') \n",
        "print('queries: integer tensor of shape (samples, max_length)') \n",
        "print('queries_train shape:', queries_train.shape) \n",
        "print('queries_test shape:', queries_test.shape) \n",
        "print('query train sample', queries_train[0,:]) \n",
        "print('-------------------------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------\n",
            "queries: integer tensor of shape (samples, max_length)\n",
            "queries_train shape: (92, 16)\n",
            "queries_test shape: (10, 16)\n",
            "query train sample [  0   0   0   0   0 216 220 237 178   2  48   3 238 222  38  13]\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obr2rEZfZlCa",
        "colab_type": "code",
        "outputId": "bea43783-9a9b-4d98-b961-3bbd1411a499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print('-------------------------') \n",
        "print('answers: binary (1 or 0) tensor of shape (samples, vocab_size)') \n",
        "print('answers_train shape:', answers_train.shape) \n",
        "print('answers_test shape:', answers_test.shape) \n",
        "print('answer train sample', answers_train[0,:]) \n",
        "print('-------------------------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------\n",
            "answers: binary (1 or 0) tensor of shape (samples, vocab_size)\n",
            "answers_train shape: (92, 239)\n",
            "answers_test shape: (10, 239)\n",
            "answer train sample [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSetkDqHZlCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_epochs =500\n",
        "batch_size = 32\n",
        "lstm_size = 64\n",
        "embed_size = 50\n",
        "dropout_rate = 0.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09Jbve9YZlCg",
        "colab_type": "text"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHwLIr27ZlCh",
        "colab_type": "code",
        "outputId": "7e089b6e-a83a-46c5-d714-7f6e5b94b3f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "\n",
        "input_sequence = Input((story_maxlen,))\n",
        "question = Input((query_maxlen,))\n",
        "\n",
        "print('Input sequence:', input_sequence)\n",
        "print('Question:', question)\n",
        "\n",
        "\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=embed_size))\n",
        "input_encoder_m.add(Dropout(dropout_rate))\n",
        "\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=query_maxlen))\n",
        "input_encoder_c.add(Dropout(dropout_rate))\n",
        "\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=embed_size,\n",
        "                               input_length=query_maxlen))\n",
        "question_encoder.add(Dropout(dropout_rate))\n",
        "\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "print('Input encoded m', input_encoded_m)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "print('Input encoded c', input_encoded_c)\n",
        "question_encoded = question_encoder(question)\n",
        "print('Question encoded', question_encoded)\n",
        "\n",
        "\n",
        "\n",
        "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
        "print(match.shape)\n",
        "match = Activation('softmax')(match)\n",
        "print('Match shape', match.shape)\n",
        "\n",
        "\n",
        "response = add([match, input_encoded_c])\n",
        "response = Permute((2, 1))(response) \n",
        "print('Response shape', response)\n",
        "\n",
        "\n",
        "answer = concatenate([response, question_encoded])\n",
        "print('Answer shape', answer)\n",
        "\n",
        "answer = LSTM(lstm_size)(answer) \n",
        "answer = Dropout(dropout_rate)(answer)\n",
        "answer = Dense(vocab_size)(answer)\n",
        "\n",
        "answer = Activation('softmax')(answer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "Input sequence: Tensor(\"input_1:0\", shape=(?, 35), dtype=float32)\n",
            "Question: Tensor(\"input_2:0\", shape=(?, 16), dtype=float32)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Input encoded m Tensor(\"sequential_1/dropout_1/cond/Merge:0\", shape=(?, 35, 50), dtype=float32)\n",
            "Input encoded c Tensor(\"sequential_2/dropout_2/cond/Merge:0\", shape=(?, 35, 16), dtype=float32)\n",
            "Question encoded Tensor(\"sequential_3/dropout_3/cond/Merge:0\", shape=(?, 16, 50), dtype=float32)\n",
            "(?, 35, 16)\n",
            "Match shape (?, 35, 16)\n",
            "Response shape Tensor(\"permute_1/transpose:0\", shape=(?, 16, 35), dtype=float32)\n",
            "Answer shape Tensor(\"concatenate_1/concat:0\", shape=(?, 16, 85), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QAcjbJnZlCk",
        "colab_type": "code",
        "outputId": "7cf8bf5b-b263-4712-9fac-8a37d2020eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0rvLX0GZlCn",
        "colab_type": "text"
      },
      "source": [
        "## Model summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0YVM2ntZlCo",
        "colab_type": "code",
        "outputId": "c159832b-9a85-49c1-c125-72e1bb156397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 35)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 16)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       multiple             11950       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 16, 50)       11950       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 35, 16)       0           sequential_1[1][0]               \n",
            "                                                                 sequential_3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 35, 16)       0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       multiple             3824        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 35, 16)       0           activation_1[0][0]               \n",
            "                                                                 sequential_2[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 16, 35)       0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16, 85)       0           permute_1[0][0]                  \n",
            "                                                                 sequential_3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 64)           38400       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 64)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 239)          15535       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 239)          0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 81,659\n",
            "Trainable params: 81,659\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRKAwGWVZlCu",
        "colab_type": "text"
      },
      "source": [
        "## Training the model and using Keras Callbacks for Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "nCoXSgXyZlCv",
        "colab_type": "code",
        "outputId": "56258d33-10e2-4920-cdbf-83a3404c5d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "model.fit([inputs_train, queries_train], answers_train, batch_size, train_epochs, callbacks=[TrainingVisualizer()],\n",
        "          validation_data=([inputs_test, queries_test], answers_test))\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBUEQ+gki6IIgCP0EEXRBEIR+wv8Hrp/mq4jxP/AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GCtZl0wZlCz",
        "colab_type": "text"
      },
      "source": [
        "## Test Result Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0vQLuMLBx-u",
        "colab_type": "code",
        "outputId": "65fbf7e4-0566-46e9-fc8d-799e8a7a342f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('stopwords')\n",
        "#import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "stopwords = nltk.corpus.stopwords.words('english') \n",
        " \n",
        "def getKeywords(carr):\n",
        "  sentences = nltk.sent_tokenize(carr)  \n",
        "  keywords1 = []\n",
        "  for sentence in sentences:\n",
        "      for word,pos in nltk.pos_tag(nltk.word_tokenize(str(sentence))):\n",
        "          #print(word)\n",
        "          #print(pos)\n",
        "          if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS' or pos == 'JJ' or pos=='VB'):\n",
        "              keywords1.append(word)\n",
        "  return keywords1\n",
        "\n",
        "print(getKeywords(\"\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bid3LTXuB21-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def listToString(s):  \n",
        "    str1 = \"\"  \n",
        "    for ele in s:  \n",
        "        str1 += ' '+ele     \n",
        "    return str1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ8MmD8OZlC0",
        "colab_type": "code",
        "outputId": "5c676793-bc16-4a2e-b90f-2625aade96f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "'''for i in range(0,9):\n",
        "        current_inp = test_stories[i]\n",
        "        current_story, current_query, current_answer = vectorize_stories([current_inp], word_idx, story_maxlen, query_maxlen)\n",
        "        current_prediction = model.predict([current_story, current_query])\n",
        "        current_prediction = idx_word[np.argmax(current_prediction)]\n",
        "        print(current_inp[1], '| Prediction:', current_prediction, '| Ground Truth:', current_inp[2])\n",
        "        print(\"-----------------------------------------------------------------------------------------\")'''\n",
        "\n",
        "f=open(\"/content/gdrive/My Drive/keywordspassed.txt\",\"a+\")\n",
        "print(\"Test Questins: \")\n",
        "print()\n",
        "for i in range(0,5):\n",
        "        current_inp = test_stories[i]\n",
        "        current_story, current_query, current_answer = vectorize_stories([current_inp], word_idx, story_maxlen, query_maxlen)\n",
        "        current_prediction = model.predict([current_story, current_query])\n",
        "        current_prediction = idx_word[np.argmax(current_prediction)]\n",
        "        #print(getKeywords(current_inp[1]))\n",
        "        newlist=getKeywords(listToString(current_inp[1]))\n",
        "        newlist.insert(0, current_prediction)\n",
        "        f.write(str(newlist))\n",
        "        f.write('\\n')\n",
        "        print(current_inp[1], '| Prediction:', current_prediction, '| Ground Truth:', current_inp[2])\n",
        "        print(\"Keywords obtained: \"+str(newlist))\n",
        "        print(\"-----------------------------------------------------------------------------------------\")\n",
        "\n",
        "f.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Questins: \n",
            "\n",
            "['Who', 'is', 'teaching', 'ObjectOrientedProgramming', '(', 'CS217', ')', 'to', 'sectionB', 'Batch2018', '?'] | Prediction: Mr.HassanMustafa | Ground Truth: Mr.HassanMustafa\n",
            "Keywords obtained: ['Mr.HassanMustafa', 'ObjectOrientedProgramming', 'CS217', 'sectionB', 'Batch2018']\n",
            "-----------------------------------------------------------------------------------------\n",
            "['Who', 'is', 'teaching', 'ObjectOrientedProgramming', '(', 'CS217', ')', 'to', 'sectionD', 'Batch2018', '?'] | Prediction: Ms.AtifaSarwar | Ground Truth: Ms.AtifaSarwar\n",
            "Keywords obtained: ['Ms.AtifaSarwar', 'ObjectOrientedProgramming', 'CS217', 'sectionD', 'Batch2018']\n",
            "-----------------------------------------------------------------------------------------\n",
            "['Who', 'is', 'teaching', 'ObjectOrientedProgramming', '(', 'CS217', ')', 'to', 'sectionG', 'Batch2018', '?'] | Prediction: Mr.JawadHassan | Ground Truth: Dr.MuhammadArshadIslam\n",
            "Keywords obtained: ['Mr.JawadHassan', 'ObjectOrientedProgramming', 'CS217', 'sectionG', 'Batch2018']\n",
            "-----------------------------------------------------------------------------------------\n",
            "['Who', 'is', 'teaching', 'DataMining', '(', 'CS429', ')', 'to', 'sectionB', 'Batch2016', '?'] | Prediction: Dr.OmerIshaq | Ground Truth: Dr.OmerIshaq\n",
            "Keywords obtained: ['Dr.OmerIshaq', 'DataMining', 'CS429', 'sectionB', 'Batch2016']\n",
            "-----------------------------------------------------------------------------------------\n",
            "['Who', 'is', 'teaching', 'ComputationalIntelligence', '(', 'CS549', ')', 'to', 'sectionZ', 'MS', '(', 'CNS', ') ?'] | Prediction: Dr.WaseemShahzad | Ground Truth: Dr.WaseemShahzad\n",
            "Keywords obtained: ['Dr.WaseemShahzad', 'ComputationalIntelligence', 'CS549', 'sectionZ', 'MS', 'CNS']\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "kzQxoZv3ZlC5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD64qEmLZlC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd '/content/gdrive/My Drive/CourseAllocation_NLG'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOEzwYzoC3c1",
        "colab_type": "code",
        "outputId": "9014a15e-6477-4e82-ef55-b488a8c9df19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_dRqMCIC3mX",
        "colab_type": "code",
        "outputId": "5e2b834d-3d18-4029-a893-16ceac1aacde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python '/content/gdrive/My Drive/CourseAllocation_NLG/Preprocess.py'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading the trainingdata...\n",
            "word is:is\n",
            "vec is:[0.0029908565, -0.005611216, 0.001272913, 0.0057337815, 0.0022839126, -0.005716496, -0.0034416432, 0.0012908783, 0.0051878444, -0.0026399423, 0.0021479898, 0.003740401, 0.00070125837, 0.0015759674, -0.00541148, 0.0010610822, -0.0048944154, -0.0014093607, 0.0071510975, 0.006123376]\n",
            "word is:teaching\n",
            "vec is:[0.0017073717, -0.0063373107, 0.0014816516, -0.0027730253, -0.0015577088, -0.0010480471, -0.0039894646, 0.004920112, -0.0016645017, -0.006385385, 0.0019459097, 0.0007838716, 3.319858e-05, 0.0048840856, -0.002878282, 0.0033324722, -0.00065790414, -0.0039664265, 0.0027801935, 0.0048284098]\n",
            "word is:ObjectOrientedProgramming(CS217)\n",
            "vec is:[-0.0044510607, -0.0023137503, 0.0004056745, 0.00042450827, 0.0012427332, -0.0018964204, 0.0010213383, -0.0021397872, -0.0042437017, 0.0008233451, -0.0031324897, 0.0018407407, 0.0051926286, -0.0010638152, 0.0035242906, -0.0007377006, 0.0018892129, -0.0012923967, -0.0023077694, -0.0013333376]\n",
            "word is:to\n",
            "vec is:[-0.0018029141, 0.00024293827, -0.0031260883, 0.0079820715, 0.0017096772, -0.0045115273, -0.0014686425, 0.0043618395, 0.0044371174, -0.007255214, -0.00040082852, -0.0009057101, 0.0055377213, -0.0018956604, -0.007346879, 0.004605399, -0.0020394742, 0.00024843277, 0.007212782, 0.0033216558]\n",
            "word is:sectionA\n",
            "vec is:[-0.0044767456, 0.00030870465, 0.004122313, -0.00053065753, 0.0008483929, -0.0020026527, -0.00013393977, -0.0013828854, -0.0034486933, -0.0027124453, 0.000474829, -0.0010204919, 0.0051602228, 0.00061368407, -0.003473328, -0.00049007405, 0.004143898, 0.0016303459, -0.00019208525, 0.004678918]\n",
            "word is:Batch2018\n",
            "vec is:[-0.0041705817, -0.0023699694, 0.004042876, 0.004285322, -0.0015406023, 0.001752013, 0.0005885168, -0.0009846744, 0.0014332755, -0.000988376, 0.0046106684, -0.005076713, 0.004255779, -0.004644462, -0.0017957486, -0.0019935784, -0.0037611562, 0.0005714965, -0.00051370397, -0.004137268]\n",
            "word is:sectionB\n",
            "vec is:[-0.0031727236, -0.00013264762, 0.004533603, -0.0037494565, 0.0026395477, 0.0036748026, 0.00047007462, 0.0005380025, 0.004839706, -0.0037881886, -0.0034868503, -0.0015660125, -0.0038137864, -0.0026483177, 0.0012146968, -0.0029116145, 0.0022667958, -0.0008658543, 0.003970351, -0.0021621282]\n",
            "word is:Batch\n",
            "vec is:[0.00030027144, -0.0032552115, 2.3517763e-05, -0.002577102, 0.0033857264, -0.0011734708, 0.0017647585, 0.003532733, -0.0011902797, -0.0027886366, -0.0039460347, 0.004548888, -0.0045127664, -0.003688515, -0.0036589815, 0.0042599593, 0.0006251908, -0.00063345395, 0.0032585238, 0.0049140537]\n",
            "word is:2018\n",
            "vec is:[0.0046861963, -0.0047479384, 0.00080194004, 0.001706028, -0.00039228593, -0.0012950539, 0.0032904213, -0.0024284113, -0.0034709345, -0.0005895853, 0.0035230059, 0.0011830219, 0.004526853, -0.004441969, -0.0031571474, -0.0040006586, 0.0033219906, 0.0023510861, -0.0043871514, 0.003526531]\n",
            "word is:ObjectOrientedProgramming\n",
            "vec is:[-5.1385374e-05, -0.0011101793, -0.0033652545, -0.0038341628, -0.0036505437, 0.0014947281, -0.00031666827, -0.001806695, -0.0008067172, 0.004504002, -0.001502652, -0.0024432791, -0.0032330551, -0.0049322355, -0.0028786943, 0.0030812977, 0.0008187694, -0.003653775, -0.0020189842, 0.00077203644]\n",
            "word is:(CS217)\n",
            "vec is:[0.000995424, -0.0038603598, -0.002547616, -0.0012744416, 0.00015308392, -0.002429117, 0.0024430675, 0.00494798, -0.004037412, -0.0036746596, -0.0005802687, 0.002001776, 0.001643834, 0.0016978605, -0.004876947, -0.004884218, -0.0010027209, -0.0002180084, -0.0017797782, -0.00044023464]\n",
            "word is:sectionC\n",
            "vec is:[0.0013045017, 0.0033395423, -0.0001323444, 0.0040519326, -0.0027837674, 0.001140315, -0.0032585037, -0.0037596219, -0.0010830448, -0.0051412075, -0.0009574985, -0.0031947633, 0.0033122879, 0.0044174897, -0.00069428456, 0.002879903, 0.0002893179, 0.0003117935, -0.0025427132, 0.00057162426]\n",
            "word is:Ms.AtifaSarwar\n",
            "vec is:[-0.0015497231, 0.000768684, 0.004486949, -0.0015567653, -3.5347862e-06, 0.004721933, -0.0046513565, 0.00035581042, 0.0021222944, 0.0030858167, -0.00071327185, -0.0010833471, 0.004105108, -0.0035094945, -0.0036056163, -0.00092827715, 0.0003858673, -0.0019661617, -0.0015318531, -0.0012446176]\n",
            "word is:sectionD\n",
            "vec is:[0.0018974851, 0.0030762744, -0.0018598157, -0.003077411, -0.0021679462, -0.0019458277, 0.0027123035, 0.0018448536, 0.0048268754, -0.0051442278, 0.0050123497, 0.0032952956, -0.0017189992, 0.0046806377, -0.0026981519, -0.0034675756, -0.0039892844, 0.0014364402, 0.0047836145, 0.0033275697]\n",
            "word is:Dr.MuhammadArshadIslam\n",
            "vec is:[0.0031217278, 0.0036156222, 0.0011704266, -0.0041404334, -0.0027799, 0.0021968547, 0.0008298469, 0.0032326607, 0.0012793998, 0.002318513, 0.0038690632, 0.0010228199, 0.0028239153, -0.0039171483, 0.0045659994, 0.0028469674, 7.842822e-05, -0.0045575066, -0.0017710328, -0.0039281882]\n",
            "word is:sectionE\n",
            "vec is:[-0.0049883327, -0.0055436315, -0.003811171, 0.0041151736, 0.0010768392, -0.0014877053, 0.0036547268, -0.003213113, -0.0007830024, -0.00072047353, 0.0010610514, -0.00054797204, -0.0019618017, -0.00047169707, 0.0026244887, 0.00039646632, -0.0012298523, 0.0019815806, 0.0026803354, 0.0015376983]\n",
            "word is:Mr.JawadHassan\n",
            "vec is:[-0.0011164385, 0.0040623597, 0.004322765, 0.0016505443, -0.00058302784, 0.0043212334, -0.0009929722, 0.0044472474, -0.00056499615, 0.0022969367, 0.0009827997, 0.0012042576, 0.00066080794, 0.0035835553, 0.0026097032, 0.0011058371, -0.0025854572, -0.0044802628, -0.0014563863, -0.0024653475]\n",
            "word is:sectionF\n",
            "vec is:[-0.0045902347, 0.002174807, -0.0003898273, 0.003598679, 0.0036833428, -0.0047405977, -0.004230169, -0.0030464998, 0.0013190351, -0.0028313005, -2.8651095e-05, 0.0013674423, 0.0027659305, 0.0003262771, -0.0042103683, 0.0030304047, 0.0015799534, -0.0025757682, 0.0008608815, -0.004135857]\n",
            "word is:sectionG\n",
            "vec is:[0.0036551394, -0.0007184993, 0.0021025145, 0.0047946675, -0.004705455, -0.00033333994, 0.004088121, -0.00021828481, -0.001063326, -0.001771844, -0.0030737217, -0.0010853576, -0.002161751, -0.00017538687, -0.003822135, 0.002001945, -0.001017264, -0.0045977393, 0.004779513, 0.003649693]\n",
            "word is:Dr.MehwishHassan\n",
            "vec is:[-0.0048034373, -0.0029788653, -9.4241695e-05, 0.00028232113, 0.004496196, -0.0019094202, 0.004921445, 0.00047453237, -0.00086946134, 0.0045878375, -0.004792481, -0.002458879, -0.004017567, 0.004749997, 0.002202943, 0.0007354161, 0.0005331741, -0.0042037205, 0.0021088868, 0.003247197]\n",
            "word is:DigitalLogicDesign(EE227)\n",
            "vec is:[0.00011539832, -0.0028644444, 0.0017759693, 0.0033511682, 0.004086998, 0.0021373054, -0.0011999897, 0.0009555596, -0.004369039, 0.0034490922, 0.003370239, -0.003953749, 0.0036242432, 0.0036218064, -0.0024940702, 0.0005707272, 0.0007278257, 0.004644761, 0.0050290795, 0.00093944883]\n",
            "word is:Ms.MehreenAlam\n",
            "vec is:[0.00096817064, 0.003090795, 0.0024039673, 0.0010803523, 0.004041667, -0.0017067484, -0.00473083, 0.00147315, 0.0013398418, -0.0012346107, -0.0022822192, 0.002353907, 0.0016142306, -0.0033988592, -0.0026992075, 0.0033175861, 0.003358959, 0.004137502, 0.0029121223, -0.0038354662]\n",
            "word is:Ms.SanaHassan\n",
            "vec is:[0.0017623112, -0.0010675539, -0.002192089, 0.0022632165, 0.0037850465, 0.0035106372, -0.0037748036, 0.0030109906, 0.0042364, -0.0043763784, -0.0013972139, 0.004616937, 0.0041106697, 0.001592202, -0.00087412755, 0.0037957595, -0.002445762, 0.003016499, 0.004184561, 0.004617816]\n",
            "word is:Dr.AdnanSaeed\n",
            "vec is:[0.0033337253, -0.0037720408, 0.0023136353, 0.0050501856, -0.004288787, -0.0050592567, -0.0045187506, -0.0043901918, -0.0029033346, 0.0010546676, 0.0006699328, 0.0009385274, -0.0013717354, -0.0045862864, 0.00095994456, 0.00027734047, -0.004008965, 0.003085656, -0.0015621631, 0.0044224383]\n",
            "word is:ProgrammingFundamentals(CS118)\n",
            "vec is:[0.0036447803, 0.0011891235, -0.0009793385, 0.0036845405, -0.0027661324, 0.0018508416, 0.0018875129, -0.0017307381, -0.003599074, 0.004072192, 0.0049385284, 0.0010709992, 0.003712646, -0.0033003555, -0.00041414984, 0.004776803, 0.0015849931, -0.0007656111, 0.0017675224, -0.0002512756]\n",
            "word is:Repeat\n",
            "vec is:[-0.0014944967, -0.0052172597, -0.0044190185, 0.0010467767, 0.0040294486, 0.0027895537, 0.001041587, -0.0018266428, -0.00026098153, -0.0006574937, -0.0013581578, 0.0013184615, -0.00412602, -0.00037142893, -0.001796218, 0.0010591592, 0.0011499841, 0.0023645237, 0.0020756489, -0.0016009826]\n",
            "word is:Dr.EjazAhmed\n",
            "vec is:[-0.0037492716, -0.000965864, 0.0014935249, 0.0006795892, -0.0021564723, -0.0007060323, -0.002236886, -0.0044289185, 0.0006846628, -0.0024593656, 0.002447636, -0.0009683577, 0.004317978, -0.0021246448, 0.0033491598, -0.004916434, -0.003361447, -0.004683373, 0.0033327222, -0.0008298137]\n",
            "word is:DatabaseSystems(CS203)\n",
            "vec is:[-0.001747836, 0.0020055524, 0.0029676354, 0.0037658475, -0.0034299565, 0.0038954322, -0.00052265817, -0.0012140761, -0.0041649574, -0.0033782697, 0.0045359177, -0.0009820899, 0.0022699882, -0.0002672224, 0.0009345313, -0.002724291, 0.00078799174, -0.0034485166, 0.0025161244, 0.0037150993]\n",
            "word is:Batch2017\n",
            "vec is:[-0.0036879343, -0.000278422, -0.0018845204, -0.0011461013, -0.0041498686, -0.0031338613, -0.0021688105, -0.0037067542, 0.0034682094, 0.00080066524, 0.003934826, -0.0038941945, -0.0018847625, 0.00028041753, -0.0052094483, 0.0016943159, 0.0028107015, -0.0022057896, 0.004805269, -0.0009055886]\n",
            "word is:Dr.AsmaAhmad\n",
            "vec is:[-0.0032461747, -0.0013974656, -0.004843637, 0.003140143, 0.004240282, -0.004642312, -0.0021236923, -0.00092945585, 0.003833865, -0.0019197711, 0.00456891, -0.002431711, 0.0044748867, 0.0024826229, -0.005147195, 0.00051691575, 0.0026050117, 0.0037579713, -0.0043539866, 0.0007645275]\n",
            "word is:Dr.HasanMujtaba\n",
            "vec is:[-0.002566109, 0.0021949802, 0.0007735309, 0.0034623079, -0.0050421385, -0.0031606255, 0.003756972, 0.0043534352, -0.003812102, -0.0051490846, 0.003335668, -0.0033367965, -0.002034303, 0.004711079, -0.0048414273, -0.0028115476, -0.005076006, -0.0007926187, -0.004220125, -4.076982e-05]\n",
            "word is:OperatingSystems(CS205)\n",
            "vec is:[0.003777844, 0.0030320212, 0.0042072595, -0.004180283, -0.004159677, -0.0045752036, 0.0015922509, 0.00044995054, 0.0047705946, -0.0021220003, -0.0046892017, -0.0041768467, 0.0048080483, -0.0011666947, -0.005192804, 0.0005648212, 0.0043453104, 0.003963566, -0.0036096866, 0.004322979]\n",
            "word is:Dr.MuhammadAdnanTariq\n",
            "vec is:[0.004370885, 0.0024622579, -0.0048251958, 8.685867e-05, -0.0038151862, 0.0021749034, 0.0014278765, 0.0032927878, 0.001460815, 0.0018624503, 0.0047295014, -0.0043323264, 0.004563058, 0.002600268, -0.001987584, 0.0018063169, 0.0011387361, 0.0030446984, 0.0038243476, 0.00096018706]\n",
            "word is:Ms.SidraKhalid\n",
            "vec is:[-0.0029669162, 0.0015561915, -0.0022308044, -0.0033288815, -0.004460142, -0.0017586807, 0.0016089376, 0.0050714584, -0.004373173, 0.003154835, 0.0023415112, -0.0028378905, -0.0041916273, -0.003469931, 0.0009930356, 0.0006359026, 0.002085601, -0.0037879313, -0.0032441048, -0.003557676]\n",
            "word is:Dr.AtifMughees\n",
            "vec is:[0.0025115542, 0.0033164192, -0.0047807493, 0.002728433, 0.00302162, -0.0020677608, 0.0036737656, -0.001984072, -0.002904251, 0.0038513148, -0.0020735553, 0.0034195562, 3.628308e-05, 0.0049042874, -0.0042127576, 0.00082674983, -0.0037126674, 0.0021111523, 0.0014088321, 0.001267491]\n",
            "word is:ComputerArchitecture(EE204)\n",
            "vec is:[-0.004271466, -0.0024123809, -0.004970194, 0.0015470566, -0.0008906964, -0.00066186424, 0.0027810503, 0.00027244617, -0.00094897486, -0.0012570756, 0.0049114046, -0.0006309033, -0.004346462, -0.0014223317, -0.0036660647, -0.0021854697, -0.0038402835, 0.0032938411, -0.004138328, 0.00445891]\n",
            "word is:Dr.OmerBeg\n",
            "vec is:[-0.0033711267, 0.0046516364, 0.0013183844, 0.0004089863, -0.0020639221, -0.0019492562, 0.0013028489, -0.00031772157, -0.0013968822, -0.0006443595, -0.004208954, -0.0022720988, -0.0009843549, -0.000794876, -0.0017465841, -0.002958211, 0.0020347752, 0.0033696613, 0.00048696162, 0.004849331]\n",
            "word is:Mr.ShamsFarooq\n",
            "vec is:[0.0033929478, -0.0045556575, -0.0010857979, 0.001195005, -0.002597474, -0.0007875075, -0.0029138161, 0.0014278446, -0.00044546273, -0.004337935, 0.0027710348, 0.001978887, 0.002567452, 0.0016924104, -0.0034223087, 0.0007236744, 0.0016646266, -0.0005466558, -0.0039898637, -0.004162694]\n",
            "word is:Ms.SabaRasheedMalik\n",
            "vec is:[-0.0021845624, -0.0028009582, 0.0009137797, -0.0011888865, 0.004483225, -0.0020607377, -0.0008163065, 0.002630529, 0.004975039, 0.0013596491, 0.0017534923, 0.00022438863, 0.004574338, -0.0047740685, -0.0012932743, -0.0006323866, 0.0007460246, -3.346373e-05, 0.0022665102, -0.004279833]\n",
            "word is:ComputerOrganization&AssemblyLanguage(EE213)\n",
            "vec is:[-0.0026280642, -0.004653929, -0.00062370225, 0.0044002375, 0.0030317858, -0.003018123, -0.00020884575, 0.0040894905, -0.0031833579, -0.0007640937, -0.000987264, -0.0040340787, -0.0012043106, 0.004637607, 0.004550897, -0.0043244623, 0.0036914372, -0.0045739315, 0.0038250966, -0.00066518626]\n",
            "word is:Ms.SaroshShahid\n",
            "vec is:[0.0033197966, 0.0037762546, -0.001763607, 0.00351105, -0.0044264765, -0.0008302742, 0.0033576593, -0.0027943377, -0.0020684798, 0.00310736, 0.0048525305, 0.0047563314, 0.0013162117, 0.0018642968, 0.00085053366, -0.0045199376, -0.003436151, 0.0037611881, 0.0027879388, 0.0024593563]\n",
            "word is:Mr.HafizTayyebJaved\n",
            "vec is:[-0.00044387407, -0.0005373161, 0.0016570402, 0.0024430281, 0.004163166, -0.0046791486, -0.0021230197, -0.0018182404, -0.0022513012, 0.0012979769, 0.003930853, -0.0026435587, 0.00054118066, -0.004258166, -0.0041658147, -0.0010588184, -0.0031804517, -0.0038600967, 0.0009448794, 0.0046602855]\n",
            "word is:DataStructures(CS201)\n",
            "vec is:[-0.00480647, -0.0040737, -0.000934358, 0.0033378464, 0.003298447, 0.0017319305, -0.0030080313, -0.0029890966, -0.0019154866, -0.00034473857, -0.00073235406, 0.00042440012, 0.003138295, 0.0038823187, 0.0039025822, 0.004184502, -0.0023841648, -0.004338636, -0.0047686053, -0.003153546]\n",
            "word is:Mr.ShujaatHussain\n",
            "vec is:[0.0010521254, 1.1422719e-05, -0.00423691, 0.001083634, 0.003099075, 0.0011345925, -0.0046839244, 0.0032416056, -0.0011378262, 0.0029527843, 0.0035757548, 0.0019557113, -0.0037883236, 0.0026750157, -0.0010776921, 0.00092643016, -0.003668781, -0.0015492599, -0.0017013559, -0.0043705534]\n",
            "word is:Design&AnalysisofAlgorithms(CS302)\n",
            "vec is:[0.004539069, 0.0022264067, 0.0018721742, 0.003710106, 0.0019008414, -0.002027134, 0.0019966322, 0.004733425, -0.00020790602, -0.004269139, 0.0007854516, -0.004508997, 0.004120757, -9.610493e-05, -0.0015392359, -0.0033018366, 0.0021934262, 0.0034751522, 0.0044429856, -0.002299009]\n",
            "word is:Batch2016\n",
            "vec is:[-0.0027315798, -0.0051512113, 0.0023260927, -0.0009332385, 0.0013240054, -0.0018811544, -0.00012723646, 0.0047587226, 0.005479798, -0.0043340046, 0.00492216, -0.0036481263, -0.0030868275, 0.0041919383, -0.0060080625, -0.0021522809, -0.001835621, -0.0052062627, -0.0021521635, -0.001374328]\n",
            "word is:Ms.AmnaIrum\n",
            "vec is:[-0.0024613878, -0.001486492, 0.0016468653, -0.0023683968, -0.0035815157, 0.0011915652, 0.0035367084, -0.0029845287, -0.0002225692, -0.0014329497, -0.0027846985, 0.0010196371, 0.0025713798, -0.00080292503, 0.003351801, 0.00440487, 0.00088520517, -0.004910808, -0.0020736388, 0.002476351]\n",
            "word is:Dr.IrumInayat\n",
            "vec is:[0.004784465, -0.004548184, -0.004504382, 0.0027356842, 0.0012733262, 0.0041900766, 0.0028430705, 0.0050133932, 0.005016008, 0.00015924778, -0.0026854041, 0.0030939216, -0.004028478, -0.0015191566, -0.0031255954, -0.0048901113, -0.0017364357, 0.0017286222, -0.0014763494, 0.0034402134]\n",
            "word is:SoftwareEngineering(CS303)\n",
            "vec is:[-0.0040844055, -0.004874778, 0.003623881, 0.001829853, 0.0019072306, -0.003547371, -0.00087957573, -0.0016825113, 0.0032393616, -0.0014387752, 0.00377311, 0.00026069654, 0.0037018305, 0.0018415345, -0.00063605723, -0.00221553, 0.00056831795, 6.474336e-05, -0.001367113, -0.0018471975]\n",
            "word is:Dr.NaveedAhmad\n",
            "vec is:[-0.004672702, -0.004642098, -0.00020281837, -0.002030957, 0.00460823, 0.0040221447, -0.0019005226, -0.0022942512, -0.0024775886, 0.0006770182, 0.000755487, 0.00022426502, 0.0026673325, -0.004500165, -0.0019841846, -0.0015260004, -4.2626518e-05, -0.00027614282, 0.005129515, -0.004556526]\n",
            "word is:SoftwareEngineering(CS303))\n",
            "vec is:[-0.0010117337, -0.0033649579, 0.004775556, 0.0035395229, -0.0035432172, -0.00036090595, -0.0009450856, -0.0033849152, 0.004044481, 0.0003922823, -0.0013149596, 0.00091474666, -0.00013300245, 0.0041670133, 0.004482894, -0.0027165392, -0.0037128502, 0.00050029816, -0.0029661432, 0.004284836]\n",
            "word is:Dr.ArshadAliShahid\n",
            "vec is:[0.004901374, -0.004261173, 6.9086185e-05, 0.004677483, 0.00054655346, 0.0040693814, 0.0018554705, -0.0032632495, -0.00018376784, -0.0002932157, -0.0042419466, 0.0038548794, -0.00041357253, 0.0030482449, 0.00016161658, 0.002785043, -0.0011314675, 0.003337742, 0.000659597, 0.002946669]\n",
            "word is:Dr.LabibaFahad\n",
            "vec is:[0.0037908088, -0.0016737359, -0.002126414, -0.0014436347, -0.0029880696, 0.0028435367, 0.004964828, -0.00043548652, 0.004499369, 0.0047596414, -0.0047193985, 0.003663748, 0.0036405595, 0.0035205095, 0.003494813, 0.004156796, -0.0026769582, 0.003232905, 0.00019508385, 0.00088057487]\n",
            "word is:Dr.AtifJilani\n",
            "vec is:[0.0023121354, 0.004683389, -0.0028846473, -0.0016807655, -0.00036879058, -0.0038314015, 0.0012306855, -0.0003885037, 0.0030680276, -0.00294717, 0.004275564, 6.3460946e-05, 0.0030073319, 0.0011948734, -0.0017710131, 0.002961824, -0.0023795008, 0.00018625925, 0.0012345257, -0.00013287777]\n",
            "word is:WebProgramming(CS406)\n",
            "vec is:[0.002557366, -0.00039834843, -0.002727177, -0.0005410233, 0.0009068329, -0.004879875, -0.0036061853, 0.0041266354, 0.001433111, 0.0036694717, 0.004423769, -0.0045537874, -0.0017173527, -0.0013074751, -0.0048773177, -0.0010159247, -0.0007679522, 0.0020881898, 0.0015544768, 0.0006143541]\n",
            "word is:Dr.HammadNaveed\n",
            "vec is:[-0.0034911612, -0.0024434852, 0.0031133112, 0.0024375103, 0.0004110325, -0.0053071086, -0.0047462024, 0.0050894846, -0.0017500916, 0.00063083164, -0.004485012, 0.0009688192, -0.00030402603, 0.004422575, -0.00029468242, -0.00035277207, -0.0035424985, -0.0011628914, 0.0019615758, 0.0016248624]\n",
            "word is:Bio-Informatics(CS508)\n",
            "vec is:[0.0016725308, -0.0019272494, -0.00011652777, 0.0043919487, -0.0033533967, -0.0035499413, 0.002468136, 0.0052085444, 0.0024361354, -0.0026039528, 0.003389419, -0.0018035572, 0.0012761257, 0.002617122, -0.0040812185, -0.00093707565, -0.004430833, -0.0034482148, -0.0031215597, 4.8467304e-05]\n",
            "word is:section\n",
            "vec is:[0.004164065, 0.00086826866, -0.0035083483, 1.256729e-05, -0.0046111597, -0.002427747, -0.00014706349, 0.00047229184, 2.667191e-05, 0.002445469, -0.0041329814, 0.0004721647, -0.0025431758, 0.003130375, -0.0005820468, -0.0025241144, 0.0024337887, 0.00041826454, 0.0024936495, -0.0037211252]\n",
            "word is:A\n",
            "vec is:[-0.0003888677, 0.0044612526, 0.0010824301, -0.0039075743, -0.00014813303, -0.0006900853, -0.003913108, -0.0031289873, -0.004609673, -0.0025483882, 0.0017496821, -0.0029534257, 0.00071712554, -0.0026592806, -0.0030439924, -0.0013194552, -0.0026993249, -0.004564326, 0.003334346, 9.662426e-06]\n",
            "word is:2016\n",
            "vec is:[-0.0020838464, 0.004700958, -0.0009554166, -0.0047201733, -0.0027725727, -0.003107576, 0.0010918705, -0.0017612431, -0.0009384128, 0.003454835, -0.0015679685, -0.002169462, 0.002033082, 0.0031087424, -0.00017687457, -0.0013593703, 0.004778799, -0.0005516593, -0.00131489, -0.0038066446]\n",
            "word is:Dr.Muhammad\n",
            "vec is:[0.00069834245, 0.0014093206, 0.004238463, -0.004040775, 0.0015158963, 0.0005801084, 0.0019379271, 0.00399534, -0.0017747631, -0.0010805888, 0.0035831016, 0.0044384385, 0.0032534446, 0.0025854185, 0.0045594247, -0.0010911181, -0.0036654018, 0.0004332681, 0.003776312, -0.0011176061]\n",
            "word is:Adnan\n",
            "vec is:[-0.0043097856, -0.00053133804, -0.0038998693, -0.004026559, 0.0034376367, -0.0047353827, -0.0031121082, 0.0035372472, -0.0008590507, 0.0016145092, -0.0031536412, -0.00019683408, 0.00045445736, 0.0026966329, 0.0034702239, 0.0031393198, -0.0010543773, 0.0037362278, 0.0025770569, -0.00021647934]\n",
            "word is:Tariq\n",
            "vec is:[-0.0041996194, -0.0019373926, -0.00017722235, 0.004558982, -0.0014224015, 0.004833696, -0.0021033653, 0.00037234713, -0.00467646, -0.0045308745, 0.00054030865, 0.0037049511, 0.003181143, 0.0036394792, 0.0011481544, 0.0021237168, -0.0015859298, -0.0024698726, 0.0008001828, -0.0019139741]\n",
            "word is:MobileComputing(CS575)\n",
            "vec is:[-0.00408421, -0.0033332126, 0.0033833703, -0.0043846476, 0.0028061592, -0.0014530506, 0.0026653362, 0.0021018328, 0.0012963294, -0.00073484686, 0.0025306628, -0.0040025176, 0.00421326, 0.0014012606, -0.0029774464, -0.0013168034, -0.0039347745, -0.0012602266, 0.0020394984, 0.0019247179]\n",
            "word is:AdvancedDatabaseSystem(CS502)\n",
            "vec is:[-0.004793998, -0.0044247545, -0.004558541, -0.0029719577, 0.0028499148, -0.003231735, -0.004317798, -0.004593552, -0.0030452798, 0.0026989696, -0.0016853547, 0.0032588954, -0.00039648393, -0.0048924997, -0.0012002593, 0.0016539255, 0.0013761922, 0.004522652, 0.0031217914, 0.000776733]\n",
            "word is:Dr.OmerIshaq\n",
            "vec is:[-0.0045776875, -0.00472379, -0.00039739592, 0.0048204726, -0.0013949896, -0.0050856196, 0.0033192711, -0.0029868847, -0.0027525239, -0.0014086334, 0.0044748164, -0.0020188144, 0.0041221986, -0.004573085, -0.0037897492, 0.0014905405, -0.00046140834, -0.003194548, 0.0020178414, 0.0027488933]\n",
            "word is:DataMining(CS429)\n",
            "vec is:[0.0035652013, -0.0015429177, -0.003997945, 0.0025380102, -0.0030699465, -0.003190079, 0.0025987779, 0.0027386646, 0.0010504904, -0.0033368457, -0.0021222138, 0.004616658, 0.00079985417, -0.0018508446, 0.0042716833, 0.0038333002, 0.0039397846, -0.004753818, -0.0017794247, 0.0031649002]\n",
            "word is:SoftwareforMobileDevices(CS\n",
            "vec is:[0.0031799912, -0.003864398, -0.0034274107, 0.0010771262, -0.0036126026, 0.0033080305, -0.00043724928, 0.0040827626, -0.0038593393, 0.0035926297, -0.0017289427, -0.003515824, -0.0041560982, -0.0028176494, -0.0010099933, 0.0013200216, -0.0020672579, -0.0037560828, -0.002623607, 0.0035947843]\n",
            "word is:575)\n",
            "vec is:[0.0022361584, 0.0009153887, 0.00040635938, 0.0036531452, 0.0046463087, 0.00097057415, 0.0044327253, -0.003034548, 0.005017757, -0.004384861, 0.00048056268, -0.0040451474, -0.0038221127, -0.00317989, -0.0002704072, 0.00464222, -0.00196879, 0.00465629, -0.003669072, -0.0023045859]\n",
            "word is:offered\n",
            "vec is:[0.0044509857, -0.002324454, -0.00036125517, 0.0034763645, 0.0024537996, -0.0028695574, -0.0010494757, 0.001282423, 0.001064214, 0.00374351, -0.00085245824, -0.003083119, -0.0017769914, 0.0032399343, 0.00075157627, 0.0050487346, -0.0018119118, -0.0030088776, -0.0016217977, -0.004179307]\n",
            "word is:has\n",
            "vec is:[-0.00021655933, -0.00025001355, -0.0031050257, 0.0021060808, 0.0030081493, -0.00033924263, 0.0012477478, -0.0008073361, 0.005320165, -0.002840947, -0.00071147346, 0.0006487664, 0.0042191898, 0.005374982, -3.517936e-05, -0.004618654, -0.0056630257, -0.0054106363, 0.004944099, 0.0051245857]\n",
            "word is:no\n",
            "vec is:[-0.002231112, 0.00019680063, -0.00042550187, -0.0001230328, 0.0001493823, -0.00014282165, 0.00081677304, 0.0043725884, 0.0039890595, 0.00039374302, 0.00096002955, 0.0016038222, -0.0041081742, 0.0040497547, 0.0036909047, 0.0003214305, -0.0016847105, 2.3652192e-05, 0.0033184455, 0.0015809069]\n",
            "word is:instructor\n",
            "vec is:[-0.0003814808, -0.0036055807, 0.0043525705, 0.0026806805, 0.0028465462, 3.5798006e-05, -0.003293393, 0.0022299837, -0.0046124505, 0.0025216602, 0.002138265, 0.00074065174, -0.00025747443, -0.002042504, 0.0017321014, 0.00060700485, -0.0032378696, -0.003522934, 0.003327201, -0.002884398]\n",
            "word is:assigned\n",
            "vec is:[0.0031724419, -0.00052219, 0.0034466286, 0.00038403357, -0.002731884, 0.001157036, 0.0024252413, 0.002118877, -0.0033900265, -0.0028244965, 4.8613085e-05, -0.0007237803, -0.0019596186, 0.0036891054, 0.0017983568, 0.0035627056, -0.0027664173, -0.0039199325, -0.0003714973, 0.00015209976]\n",
            "word is:yet\n",
            "vec is:[-0.0012306644, 0.0013001437, 0.0042795395, 0.004083902, -0.0044520395, -0.004929655, 0.0007849097, -0.0028967727, 0.0002597653, 0.0013402106, 0.0047512166, -0.0012169784, 0.0050826804, -0.0024829467, 0.0013790351, -0.0016956971, 0.0034395852, 0.00435706, -0.004424058, -0.0016730783]\n",
            "word is:ObjectOrientedAnalysis&Design(CS309)\n",
            "vec is:[0.0025594428, 0.0024278222, 0.0038186905, 0.0037184067, 0.0030658233, -0.0038299586, -0.004696091, 0.0022658976, 0.0006343201, 0.000449655, 0.0049947286, 0.0025182534, 0.00056516664, 0.004550029, 0.0044488586, 0.0017115274, -0.00019910646, -0.00094082765, 0.0040510767, -0.0004737543]\n",
            "word is:Dr.KashifMunir\n",
            "vec is:[-0.0036317813, -0.00067688356, 0.003268475, 0.0022691642, 0.004097514, -0.001694376, -0.0028253952, -7.725497e-05, 0.0001940741, -0.0020640043, -0.0012110823, -0.0008809105, -0.0012856877, -0.0043359245, 0.0025175223, 0.0037857129, 0.0044512134, -0.0021164163, -0.0029172623, 0.00021839933]\n",
            "word is:ComputerNetworks(CS307)\n",
            "vec is:[-0.0012867635, 0.0030775038, -0.0049895775, 0.0022147044, -0.0010924084, -0.0004954032, -0.0031784966, -0.0048758015, -0.003768142, 0.0036240842, -0.0021461388, -0.004433202, 0.0012389694, 0.0033492423, -0.0034693005, -0.0039145127, 0.0004573637, 0.0024554639, 0.0011995813, 0.001028537]\n",
            "word is:Dr.AmnaBasharat\n",
            "vec is:[-0.0051134974, 0.00022813292, -0.004176766, 0.0017571199, -0.0047278716, 0.0006659599, 0.004512433, 0.0012907923, -0.0022976457, 0.004470219, 0.004744966, 0.00022960655, 0.00081575173, -0.003474668, -0.0016629667, -0.0029385574, 0.0024945748, 0.0044440283, 0.0025986063, -7.080904e-05]\n",
            "word is:Project-I(CS491)\n",
            "vec is:[-0.0029178953, -0.002881284, -0.004298879, 0.003924549, 0.004028503, -0.002523391, -0.0023039903, 0.0021103846, 0.00014921899, 0.004481265, 0.0005200752, -0.0014285616, 0.004796964, -0.0015165901, -0.0018133519, 0.00070788135, 0.0031793427, -0.0036438615, -0.0020985815, -0.0005565198]\n",
            "word is:Batch2015\n",
            "vec is:[-0.00089841394, -0.005367534, 0.00047767832, -0.0011275159, -0.00494613, -0.004898749, 0.005043823, 0.0007819824, -0.0019138954, -0.0011728879, 0.0032997483, 0.004370466, 0.0054690377, 0.00085059303, 0.0016241207, 0.002189792, 0.0033813566, 0.001958576, -0.0033016212, 0.0011856528]\n",
            "word is:Project-II(CS492)\n",
            "vec is:[-0.0035851994, -0.000183642, -0.0036336174, -0.0023235697, -0.0003894728, 0.004685405, 0.0010063929, -0.0011582017, -0.0037646482, 0.004297765, 0.002166335, -5.371394e-05, 0.0007505948, -0.0036599801, -0.0003565575, -0.0012893208, 0.0037651318, -0.00020589543, -0.0019461962, 0.004878096]\n",
            "word is:Ms.NoorulAin\n",
            "vec is:[-4.230996e-05, -0.0050402153, -0.0036244378, -1.1987086e-05, -0.0040239105, 0.001410014, -0.00036386444, 0.0034475273, 0.0011294138, 0.0045293965, -0.004845356, -0.0031410733, -0.0034670478, -0.0010418886, -0.0012098276, -0.004863498, 0.0025801114, -0.0012561296, -0.0041278144, -0.004445831]\n",
            "word is:ProfessionalIssuesinIT(CS449)\n",
            "vec is:[0.0026504016, 0.0038969608, 0.00054106745, 0.0006071337, -0.00030248042, 0.0041873124, 0.0015048906, 0.0035250268, 0.0041460823, 0.0034699887, -0.00015149823, 0.0024404023, -0.0034368471, 1.860176e-05, -0.0049789352, 0.003880947, 0.004703576, 0.0006418025, 0.0017915422, -0.0023546221]\n",
            "word is:Ms.UzmaBibi\n",
            "vec is:[-0.0037786209, -0.00157448, 0.0033309173, -0.0040667676, 0.0038825017, -0.0027857139, 0.003861222, -0.0026249024, -0.0003382962, -0.0049291705, -0.0046906895, 0.004074226, 0.004834939, 0.000732501, -0.0020620453, -6.084129e-05, -0.0024845258, -0.0018165095, 0.0013735173, -0.0031735813]\n",
            "word is:HumanComputerInteraction(CS422)\n",
            "vec is:[0.0034321458, 0.00026697814, -0.001472098, -0.003349319, -0.003528612, 0.0016435469, -0.0022090657, 0.0021546145, 0.0020673147, 0.0019838628, -0.0025298784, 0.004401725, 0.0040766993, 0.0004297252, -0.0019137096, -0.002548709, 0.0010658227, 0.000542997, 0.0023876142, -0.001520377]\n",
            "word is:Dr.MuhammadAsim\n",
            "vec is:[0.0046715993, -0.0011799152, -0.0020074146, 0.0042683473, 0.0024904208, 0.0009472926, -0.0019762162, 0.0033182774, -0.0032789416, -0.0035825428, -0.0030864116, -0.0034625942, 0.003383638, -0.003250994, -0.0031704959, 0.0044704704, -0.002655786, -0.0013134886, 0.0038888338, 0.002842633]\n",
            "word is:NetworkSecurity(CS411)\n",
            "vec is:[-0.0015149273, -0.003505528, 0.004340256, -0.0024868392, 0.002621615, 0.00036976577, -0.00048877054, 0.0008788584, -0.0026636526, -0.0038403112, 0.0036019478, 0.0023153576, 0.0023414984, -0.0022453952, 0.0036289888, -0.003242517, 0.0029691681, -0.0030495543, 0.0024425867, 0.00241424]\n",
            "word is:UserExperienceEngineering(CS5107)\n",
            "vec is:[-0.0038870422, 0.002664396, 0.004696499, -0.0013597799, 0.0023083966, -0.0024192764, 0.0011948774, 0.0029011166, -0.00059160474, -0.00140876, 0.00096750626, -0.0033769114, -6.4336375e-05, -0.001777709, 0.0031140747, -4.3183845e-06, 0.0036441048, -0.0015852494, 0.0004929863, -0.0014916474]\n",
            "word is:AdvancedMobileApplicationDevelopment(CS464)\n",
            "vec is:[-0.004509718, -0.0010612486, -0.0022123777, 0.00047410402, -0.0002074399, 0.0034382793, -0.0034307607, -0.004293815, -0.003954531, -0.00044509606, -0.0010165493, 0.0030320399, -0.0029134855, 0.003033922, -0.004310601, 0.0020302683, 0.00024810428, -0.0038663812, 0.004822915, 0.0014854257]\n",
            "word is:Dr.EhteshamZahoor\n",
            "vec is:[4.7833746e-05, 0.0036528115, -0.00016624123, 0.0032086133, -0.004355632, -0.0032522865, 7.583319e-05, 0.00038659334, 0.0012740857, -0.0015469985, 0.0011885789, -0.0049772635, 0.000920041, 0.0019471123, -0.0011281433, -0.0016804234, -0.00015387489, -0.001032861, 0.003961059, -0.00338799]\n",
            "word is:Parallel&DistributedComputing(CS416)\n",
            "vec is:[-0.0015351558, -0.0027994965, 0.0041421284, -0.0028046926, -0.0021448517, -0.0025265857, -0.0043812357, -0.0024640923, 0.0038824785, 0.0038865798, -0.0016851701, -0.004712916, -0.0034791657, 0.0023756952, -0.001378349, -0.0027724926, 0.00306188, 0.001466078, -0.0011934259, 0.0015043711]\n",
            "word is:SoftwareTesting(CS497)\n",
            "vec is:[-0.0006022885, -0.00331146, 0.0018218233, 0.0016414261, 0.0007719995, 0.0048198304, 0.0022120585, -0.004460882, 0.002724572, -0.0006437882, -0.000583146, -0.0032507903, -0.004666498, 0.0045314855, -0.0027036585, -0.0015277505, 0.0009777014, 0.0017043621, -0.003949459, -0.0042991634]\n",
            "word is:MultiagentSystems(CS545)\n",
            "vec is:[-0.0016976268, -0.003558708, 0.004758661, 0.0027138246, 0.001955839, -0.0026196814, 0.0026219336, -0.0031968502, 2.8413144e-05, -0.003606836, 0.003928911, -0.00042530408, -2.5358178e-05, -0.004720708, 0.0028942905, -0.003403817, -0.0020515092, 0.002536418, 0.0023582166, 0.0036799007]\n",
            "word is:SocialNetworksAnalysis(CS5115)\n",
            "vec is:[0.0018531715, 0.00042874747, -0.0017104152, 0.001889799, 0.002488879, 0.00043712114, -0.0012425691, -0.003130324, 0.0050057615, 0.002272218, 0.0008868348, 0.004231574, 0.0015886024, -0.0035766263, 0.0039042383, 0.00063686585, 0.0027266731, 0.0011150014, -0.0035803437, 0.0023486868]\n",
            "word is:Dr.WaseemShahzad\n",
            "vec is:[0.0035060344, 0.000688824, 0.0048527806, -0.0021955043, 0.0045391396, 0.0030345675, 0.0043166312, 0.0024124198, 0.0011179827, 0.0012580475, -0.004264341, -0.0023283826, 0.003600691, -0.00336216, 0.0027673827, 0.002401311, 0.0022596964, -0.0046112123, -0.0011464454, 0.00471814]\n",
            "word is:IntrotoSoftwareProjectManagement(CS450)\n",
            "vec is:[0.00073145604, -0.0019423774, 3.8559105e-05, 0.0032226455, -0.00065988296, -0.0044082208, 0.002759347, -0.00031990235, -0.0007988177, -0.0017261059, -0.0013425929, -0.001412963, -0.0041066594, -0.0021512667, -0.0039724233, 0.004182687, -0.0036849666, 0.0009881038, 0.0042105694, -0.004533197]\n",
            "word is:Dr.HammadMajeed\n",
            "vec is:[-0.005086751, -0.0012679353, -0.0023403112, 0.004855882, 0.0019318582, 0.00064761174, 0.0012071129, -0.0017345547, 0.0017902238, 0.0016205935, 0.0036546495, -0.0013587349, 0.00073866424, -0.0025027627, 0.0030300943, -0.003298098, 0.0024410815, -0.004324277, 0.0054610763, -0.0018795881]\n",
            "word is:AdvancedAnalysisofAlgorithms(CS501)\n",
            "vec is:[0.0022600733, -0.003655677, 0.004333911, 0.004841529, -0.004797095, -0.004459908, 0.004303331, -0.003243756, 0.0011784952, -8.949837e-05, 0.0035283677, 0.0046124933, 0.0020556382, -0.004251953, -0.00020417616, -0.0006993011, 0.0033529538, 0.0033674156, -0.004370601, -0.001484408]\n",
            "word is:sectionY1\n",
            "vec is:[0.00010413555, -0.0029559499, 0.002350316, 0.0022983686, -0.0019408395, 0.0035957608, -0.0018615471, -0.00375432, -0.0045652986, -0.00016790353, 0.002553287, 0.0015062275, -0.001824315, 0.0042497963, 0.0042424584, -0.0015129424, 0.0026011115, -0.0043902844, 0.0017112299, 0.0020508918]\n",
            "word is:MS(CS)\n",
            "vec is:[0.0032925576, 0.0040194597, 0.004542321, 0.004853732, -0.0050064228, 0.001786616, 0.0019427072, 0.0047578914, 0.004939278, -0.0022060766, 0.0025351373, 0.004136825, 0.002881811, -0.0005634758, 0.0033048629, -0.0010858682, -0.0026411677, -0.00064944284, 0.00012363638, -0.0024168799]\n",
            "word is:sectionY2\n",
            "vec is:[-0.0035224191, 0.004715695, 0.0045345016, -0.003193141, 0.0026060313, -0.004532969, 0.0036847417, -0.0006652505, -0.003505028, 0.001733644, 0.0032587377, 0.0031849763, -0.0017517111, -0.0023849197, 0.003351889, -0.0015035481, 0.0026776264, 0.0023363426, 0.004575499, -0.00050997233]\n",
            "word is:TheoryofProgrammingLanguages(CS507)\n",
            "vec is:[0.0030919127, 0.0009758581, 0.0011154427, 0.0013254619, 0.004753867, 0.001470988, -0.0046788016, 0.0044609397, 0.0028333652, 0.0023813425, 0.00197435, -0.0027665081, -0.0013890957, -0.0013565157, 0.001009111, -0.00025367268, 0.0035058844, -0.0022278142, 0.0008936895, -0.0016408742]\n",
            "word is:sectionY\n",
            "vec is:[0.0010540294, 0.002444624, 0.0027126553, -0.00029010404, 2.5342557e-05, -0.003179843, 0.003319262, -0.0017359245, -0.0040380484, -0.0008033198, 0.002751724, -0.003624403, -0.000380354, -0.0012238963, -0.00239498, 0.0014160605, -0.0030686397, 0.0025180383, 0.0027025254, 0.0018442663]\n",
            "word is:CyberandNetworkSecurity(CS630)\n",
            "vec is:[0.0047400366, 0.0007535717, -0.00051087665, 0.0005415505, 0.0016633328, -0.0001799082, -0.0039142715, -0.00024813224, -0.0015453172, -0.002571729, 0.00084338186, -0.0006270614, -0.004166881, 0.0041260994, 0.0009928877, -0.0029275415, -0.0005024505, 0.0028804548, -0.0042623538, -0.002413999]\n",
            "word is:PerformanceofComputerNetworks(CN501)\n",
            "vec is:[-0.00036726188, 0.0021295208, 0.00418003, -0.0019263298, -0.0015698216, -0.0034268457, 0.0017652037, 0.0044095386, 0.0031755823, 0.0021633618, -0.0022283013, -0.0023596738, -0.00116181, 0.0014213959, 0.00070364884, -0.0016544717, -0.0015464366, -0.0034730588, 0.0037386233, 0.000374352]\n",
            "word is:SoftwareProcessModeling(CS516)\n",
            "vec is:[0.0014954556, -0.0015358242, 0.003553631, 0.0052298806, -0.0049040723, -0.004666145, -0.0023696031, -0.0010212808, 0.004263907, -0.004616127, 0.00035855162, -0.0036198571, -0.003967125, 0.0025466187, -0.00413362, -0.0036043823, 0.004226773, 0.0020556091, -0.0019567886, 0.0018517778]\n",
            "word is:CloudComputing(CS579)\n",
            "vec is:[0.0022713693, 0.0038200812, 0.0022805831, 0.0019055577, -0.0006732384, -0.00028134018, 0.0039031487, -0.003669425, -0.0029896395, -0.0013481808, 0.0004014654, -0.0040269634, -0.0032910462, 0.00061293476, -0.0012041032, 0.00013248647, -0.0002676514, -0.002843023, -0.0011229392, -0.00038108596]\n",
            "word is:MachineLearningforDataScience(DS503)\n",
            "vec is:[0.0010840009, 0.0028114528, 0.0031495069, -0.0035925575, -0.003066047, 0.004021653, 0.00039165097, 0.0013124895, 3.8643662e-05, -0.0052437466, 0.004076431, 0.0043392032, -0.0021842532, -0.0039749695, 0.0024339347, 0.0039891615, 0.0025093325, -0.002700148, -0.0045656716, 0.0037292086]\n",
            "word is:ComputationalIntelligence(CS549)\n",
            "vec is:[0.003560632, 0.0025389702, 0.004269822, 0.0050928583, 0.0030134602, -0.0014105788, 0.0028021645, -0.003625479, 0.0010915071, -0.0045165555, 0.0025311913, -0.0004611312, 0.0044210865, 0.0027595402, -0.0037193028, -0.00012254718, 0.0012067272, 0.0008060085, 0.0029547892, -0.0016773994]\n",
            "word is:AppliedImageProcessing(CS553)\n",
            "vec is:[-0.001816657, 0.0006343241, -0.003357572, 0.0041458826, -0.003981253, 0.00045095177, -0.0039030355, -0.0027501015, -0.0047121183, -0.0020530506, -0.0033784162, 0.0024819744, 0.0045126053, -0.004780015, 0.0018451159, -0.0031947023, -0.0006304291, -0.001404559, 0.0015979772, 0.0010479235]\n",
            "word is:EvolutionaryComputations(CS566)\n",
            "vec is:[0.0032511277, 0.00060019334, 0.0005353363, 0.002353902, 0.0014168367, 0.0026114443, -0.0027130926, -0.0037447542, 0.0026015174, -0.003142683, 0.0024986365, -0.004112965, -0.0033410245, 0.004051416, 0.0021926684, -0.00047833918, 0.0015572488, -0.0041023605, 0.002183505, 0.003943286]\n",
            "word is:Dr.MuhamamdArshadIslam\n",
            "vec is:[0.0022514395, 0.0023584988, 0.0028051331, 0.0039644213, -0.0004246896, 0.0014884886, 0.0014030597, -0.0029536483, -0.0028876797, -0.003247537, -0.0036815659, -0.0035617698, 0.00025539022, 0.00019322654, -0.0043640677, 0.0047859447, 0.00063377596, -0.004183953, 0.00356572, -0.003088276]\n",
            "word is:MSThesis-1(CS591)\n",
            "vec is:[-0.0016699065, 0.003490966, 0.0019005255, 0.0023453736, -0.00347362, 0.0012275642, 0.0010427024, 0.0014834715, -0.0013205169, -0.0026917614, 0.0042740465, 0.00066551776, -0.0044176765, -0.0012049517, 0.0030810095, -0.0012697836, 0.0010059087, -0.0027060632, 0.001414873, 0.0016244899]\n",
            "word is:Y\n",
            "vec is:[-0.0005723659, 0.00056747475, 0.0019582165, 0.0021493987, 0.00020136802, 0.00047467757, -0.004145278, -0.003061699, -0.0015470836, -0.0010300797, -0.0041167703, -0.0021864164, -0.00095971744, 0.0044245673, 0.0033851701, 0.0012014185, -0.002295318, -0.004900569, 0.004648887, 0.0033519876]\n",
            "word is:MSThesis-2(CS592)\n",
            "vec is:[0.0027037892, -0.005088896, -0.0022287178, 0.004804849, 0.0022872586, -0.002641664, 0.0031586369, 0.00025501076, 0.002474241, -0.0033346328, -0.0044912067, 0.0025698878, -0.0006412974, -0.0022612573, 0.001973377, -0.0017708453, 0.0015593879, -0.00053905346, 0.0022526856, -4.0041883e-05]\n",
            "word is:sectionZ\n",
            "vec is:[-0.00250571, 7.208004e-05, -0.0049304725, 0.0007375322, 0.0012231873, 0.0013921224, -5.7928795e-05, 0.0028154994, 0.004761618, -0.0033636522, -0.0026186055, 0.001645772, 0.004803988, 0.0043688607, 0.0033942298, 0.003554039, -0.0006502226, 0.001318477, 0.0031922045, -0.0008025471]\n",
            "word is:MS(CNS)\n",
            "vec is:[0.001387637, -0.002202373, -0.0025764196, -0.0036919562, 0.00053717, 0.0018720271, 0.003753341, -0.0001315352, 0.00071500515, 0.0014431674, -0.0029831866, -0.0013260706, -0.0018418253, 0.0048188437, 0.0041776234, -0.0025643997, -0.0014450073, -0.0033511133, -0.0034331686, -6.1687e-05]\n",
            "word is:Dr.UzairKhan\n",
            "vec is:[0.0012232303, 0.0027267847, 0.00042815157, -0.0031396071, -0.0021431085, 0.0047066193, 0.00414473, 0.0035783274, -0.0005586975, 0.0030753843, 0.0017891238, 0.0013181714, -0.0038589304, -0.0022456816, 0.0044550695, -0.0018198855, 0.0038477164, -0.0019503881, -0.0035861407, 0.0009917609]\n",
            "word is:AdvancedQualityAssurance(SE501)\n",
            "vec is:[0.00297935, 0.0035862825, 0.0014574513, -0.0031940036, -0.004481946, -0.0024942812, 0.0047897766, 6.756225e-05, -0.0029479447, -0.004545271, -0.002709953, -0.0032949538, 0.002598879, -0.0013298094, 0.0041464427, -0.0012438673, 0.0030007812, -0.0013247465, 0.0050513595, -0.0035226338]\n",
            "word is:sectionX\n",
            "vec is:[-0.003700578, -0.0028204354, 0.00097395835, -0.0016198487, -0.002193618, 0.0016581025, 0.002939822, -0.0030185606, -0.00065022195, 0.0021460676, 0.00080773275, 0.0017748541, 0.004684021, 0.0025661292, 0.0014171926, -0.0011120358, -0.0041655083, -0.005179527, -0.0026743286, -0.00087246386]\n",
            "word is:MS(SE)\n",
            "vec is:[-0.003856807, -0.00342855, -0.0044425027, 0.0018029705, 0.0019932485, -0.0013896824, -0.003789219, 0.00337267, 0.0010330842, -0.003873481, -0.0029269827, 0.0014631331, 0.0029485615, 0.00074765, 0.003534148, -0.0037387703, 0.0036865033, -0.00060780166, -0.003269269, 0.0016828141]\n",
            "word is:AdvancedSoftwareRequirementsEngineering(SE502)\n",
            "vec is:[-0.004828409, 0.00057473243, -0.0013242239, 0.0044633225, -0.0012726625, 0.0028554033, 0.00021072217, 0.0003524548, 0.002272391, 0.00044596673, 0.0032156976, 0.0030347125, 0.0028866078, -0.0024733169, -0.004458991, -0.0021452734, 0.0034332555, 0.0035296248, -0.003644163, 0.0008355556]\n",
            "word is:Dr.ZohaibZafarIqbal\n",
            "vec is:[0.0029682429, 0.004738372, 0.0019958776, -0.00033439728, 0.0042853225, -0.0022977344, -0.002222091, 0.0027119254, 0.002026719, -0.0006535043, -0.001996326, -0.0009536254, -0.0043581016, 0.0013816775, -0.0018548233, 0.0033850865, -0.0014127637, -0.0035842245, -0.004586551, 0.0016076675]\n",
            "word is:Model-drivenSoftwareEngineering(SE506)\n",
            "vec is:[-0.0040575094, 0.0041780835, -0.0020925498, -0.0021639399, -0.0032520138, -0.0033016196, -0.0044641937, 0.0040800087, 0.0031899088, -0.003691891, 0.0045724013, 0.0037459945, 0.0014858074, -0.0017884509, 0.0022550798, -0.00088988635, 0.00036384744, 0.0019046161, 0.003635234, -0.0014998774]\n",
            "word is:MSThesis-1(SE591)\n",
            "vec is:[-0.0043647257, -0.0035588832, 0.0037033353, 0.0040568504, -0.0015760105, -0.00034117824, -0.0033687204, 0.0049241595, -0.004834756, 0.003027464, 0.002867074, 0.0039131786, 0.00081221556, -0.0040845047, -0.002475801, 0.0030951286, 0.00070568424, 0.0013977437, -0.0045381617, 0.0033590565]\n",
            "word is:MSThesis-2(SE592)\n",
            "vec is:[-0.00039298687, -0.0030214745, -0.0033486502, 0.0048778653, -0.0023413694, 0.0028146033, 0.0039504482, -0.0013619614, -0.0029553934, -0.0043706815, -0.0002673345, 6.7208544e-05, 0.0013071704, -0.0030431624, 0.0038556159, 0.00054198713, 0.0011790509, -0.0024617412, -0.00038151172, -0.0027874354]\n",
            "word is:Dr.KifayatUllahKhan\n",
            "vec is:[-0.0050942902, 0.0038201064, -0.0006280926, 0.002297674, 0.0027794878, 0.0017086612, -0.0013403413, -0.0041390415, 0.004599431, -0.004495465, 0.0023236794, 0.0026124765, 0.00074277294, 0.0037168781, -0.002450222, -0.0012573025, -2.1417312e-05, -0.0016610345, -0.001351371, 0.0025530548]\n",
            "word is:BigDataAnalytics(MiningBigDatasets)(DS502)\n",
            "vec is:[-0.0046976986, 0.000507766, -0.0013559479, 0.005377852, 4.7328915e-05, -0.00070373423, 0.00012096716, 0.0011056309, -0.0013099369, -0.0023186412, 0.0024204121, -0.0042780214, 0.0006682365, -0.0009821502, 0.0030578757, -0.0018488521, 0.0025744934, -0.004340299, 0.00093590247, 0.0019475074]\n",
            "word is:sectionU1\n",
            "vec is:[0.003395756, 0.0017916916, 0.0032190992, 0.005202149, -0.002824988, -0.00046888232, -0.0033979814, 0.00073777366, -0.0020468084, 0.0021991725, -0.0041784155, 0.0017084654, 0.0011079812, -0.0030305504, 0.00024819872, 0.0014256926, -0.0041950145, -0.0011691896, -0.001393716, -0.003255716]\n",
            "word is:MS(DS)\n",
            "vec is:[-0.005229384, -0.0051514865, -0.004614648, -0.0020742703, 0.0011693678, 0.00022798553, 0.004462582, 0.0045905826, 0.00029991617, -0.00030330406, 0.0047319448, -0.0034219904, 0.0039039692, 0.00075883575, -0.0027957007, -0.0012935287, 0.0012342677, 0.0018090027, -0.00076931756, 0.004366549]\n",
            "word is:Bio-Informatics(forDataScience)(CS508)\n",
            "vec is:[-0.0017310089, -0.0030876496, -0.0040122033, 0.0044580204, -0.0020009507, 0.0031571204, -0.00080510514, 0.0015140745, -0.0019062422, 0.0016867942, -0.004633988, -0.00091703393, 0.0024092454, -0.0043994226, -0.002228696, 0.004044138, 0.0016579818, 0.004711293, -0.004568213, 0.0026766653]\n",
            "word is:sectionU\n",
            "vec is:[0.0010984113, -0.0012577802, 0.0018214647, 0.0034284112, 0.004348025, -0.00044930557, -7.043312e-05, -0.0033617788, 0.0029944915, 0.004179428, -0.0029038836, -0.0048147505, -0.0005560408, 0.00204689, 0.0005347879, 0.00012823365, -0.0043281056, -0.00089581485, -0.003229363, -0.0018149457]\n",
            "word is:TopicsinSoftwareEngineering(CS625)\n",
            "vec is:[-0.0017541518, 0.0032038258, -0.0039886166, 0.0012674984, 0.00028328996, -0.0016856601, 0.00018666839, -0.0029400159, 0.004757877, -0.00069311104, -0.004442697, -0.0036996556, 0.00036592386, -0.0017570528, 0.0019348036, -0.0033285383, -0.0014622218, 0.00069733476, 0.003915634, -0.0019316373]\n",
            "word is:sectionP\n",
            "vec is:[0.0029616014, 0.0023238712, -0.0022909038, -0.0022431244, -0.0007546314, -0.00036819826, 0.0037435712, -0.0014034298, -0.0022535024, 3.9618528e-05, -0.0018290791, -0.0011670749, 0.0033178432, -0.00070965406, -0.003912084, -0.004926283, -0.0038795685, 0.0042648674, -0.0009234584, 0.0034401966]\n",
            "word is:PhD(SE)\n",
            "vec is:[-0.00026268122, 0.004349475, -0.0042916876, -0.0002712831, -0.0011841594, -0.0018123628, -0.002721047, -0.0021219284, -0.0013912175, -0.005505729, 0.0024459425, 0.0023304787, 0.0036138725, -0.002329102, -0.0050596795, -0.0002078594, -0.003186762, -0.0051092124, 0.002087543, -0.0042667]\n",
            "word is:Dr.\n",
            "vec is:[-0.001412938, 0.002963307, 0.0008225223, -0.0031479583, -0.004998432, 0.0018275066, 0.0021103336, -0.004067088, -0.0030737752, 0.0009229444, -0.0009929438, 0.0008838121, -0.0008023364, 0.0036302798, 0.001922068, -0.0022675532, 0.0023876608, 0.0039961184, -0.0004945063, -0.003380696]\n",
            "word is:Atif\n",
            "vec is:[0.0031496803, 0.00198805, -0.0038452996, -0.0005800154, -0.0036364568, -0.0048041283, 0.0039836457, -0.0047146804, -0.0014560308, 0.0003372033, 0.00059302564, 0.0037480737, 0.0029073518, 0.0037166094, -0.002249218, 0.0027548156, -0.0009206142, -0.0044667367, -0.0041635614, 0.0007910003]\n",
            "word is:Jilani\n",
            "vec is:[-0.0009592703, -0.0047031087, -0.002417938, 0.00521212, -0.004975091, -0.00063256855, -0.0035505372, 0.00022591645, -0.00043289948, -0.0034632527, -0.0025247908, -0.0014250998, 0.0028917748, -7.115637e-05, -0.001834543, 0.00097265514, -0.0049352543, 0.0019604166, 0.004944293, -0.001606756]\n",
            "word is:Search-BasedSoftwareEngineering(SE507)\n",
            "vec is:[-0.0011929398, 0.00133175, -0.0022833624, -0.0016932723, -0.00023312257, -0.0031302476, 0.0014731066, -0.0041192085, 0.0034140197, 0.0009930022, 0.0009264151, -0.004982946, -0.0027301635, -0.00030032778, -0.0046938485, 0.000685237, -0.004015218, 0.0035625922, 0.0015867222, -0.00014320665]\n",
            "word is:Uzair\n",
            "vec is:[-0.00070804835, -0.0023993258, -0.00012231199, -0.0038795327, 0.0036627597, 0.00029446228, -0.00051617, 0.0009343498, -0.00017194073, -0.0033576165, 0.0028423304, -0.001938891, 0.0020706982, 0.0010781187, 0.0032050079, -0.0031215022, -0.00030912092, -0.0014853886, 0.0039477646, -0.004612364]\n",
            "word is:Khan\n",
            "vec is:[0.0012419939, -0.0041950513, 0.0011639469, 0.003286747, -0.0031509036, 0.00420211, 0.0021670824, 0.002437285, -0.004489696, -0.00028737, 0.0021371488, 0.0044182674, -0.0006342797, -0.00020607263, 0.0022351828, -0.003917308, -8.762316e-05, 0.0022199298, -0.003095027, 0.0033730224]\n",
            "word is:Aspect-OrientedSoftwareEngineering(SE601)\n",
            "vec is:[-0.004307385, -0.0034239287, -0.0016477152, 0.0033260998, -0.002422108, 0.003589913, -0.0019676152, 0.003044359, 0.001470857, 0.00015901441, -0.001150843, 0.00095307303, -0.0011922703, 0.0019852815, 0.0025376705, -0.0025719085, -0.0013082648, 0.00089006877, -0.0032873373, 0.0001253179]\n",
            "word is:DataScienceToolsandTechnique(DS500)\n",
            "vec is:[0.0048233634, -0.0023282391, 0.0025616316, -0.00052381144, 0.000299794, 0.00094706955, -0.0020171765, -0.0005297664, 0.00089472946, -0.001242837, 0.0047166958, 0.003381945, -0.0033642193, -0.0014025221, 0.0030721081, 0.0035643815, -0.002738578, 0.004339832, 0.0033689097, -0.003518822]\n",
            "word is:AdvancedTopicsinCS(CS628)\n",
            "vec is:[0.0032472364, 0.0029731377, -0.0025112957, 0.0043243794, -0.0049325195, 0.004032867, 0.004477126, 0.0013701768, 0.0046136435, 0.00057086046, -0.0042979065, 0.0044807955, 0.0039423457, -0.0047073727, -0.003422455, 0.0014433275, 0.0019196956, -0.0010741596, 0.003830372, 0.0008856888]\n",
            "word is:PhD(CS)\n",
            "vec is:[0.0027000788, 0.0036354421, -0.0015838325, 0.0035064945, -0.0010551162, 0.0012430275, 0.0017813102, 0.004066644, -0.0037631989, 0.0026355013, 0.003894991, -0.0009691614, 0.00014756763, -0.0040189694, 0.003377357, 0.0043504364, -0.0024916513, 0.0021812662, 0.0020048795, 0.0009864796]\n",
            "word is:coursecode\n",
            "vec is:[-0.0038357053, -0.0008794952, -0.0006605265, 0.0041836463, -0.004422558, 0.004010398, 0.0043106335, -0.00047065676, -0.003954503, -0.004791657, -0.0025477936, -0.00086911616, -0.003760588, 2.2401899e-05, -0.00038190198, 0.0003279902, -0.0007939254, 0.001840223, -0.001293425, -0.0009878039]\n",
            "word is:CS217\n",
            "vec is:[-0.0047409628, 0.003372292, -0.0019290127, -0.0011195474, -0.0037372047, 0.004235295, 0.0044156723, -0.00033793188, 0.00485783, 0.0040495773, 0.0017611107, 0.0006153264, 0.0037082622, 0.0043313596, 0.0043893745, -0.0030392148, -0.005052968, 1.5186901e-05, 0.00020350212, -0.0021169158]\n",
            "word is:DigitalLogicDesign\n",
            "vec is:[0.0044123298, -0.0005138709, -0.0018395343, 0.00066982256, -0.00047969352, -7.188506e-05, 0.0027824512, 0.0027522123, -0.0028629366, -0.0036307427, 0.002020286, 0.0044025662, -0.00202492, 0.0049698623, -0.0025258067, 0.0018303008, -0.003454291, -0.0034787313, -0.00277712, -0.0008809228]\n",
            "word is:EE227\n",
            "vec is:[-0.0020934197, -0.00017702144, 0.003289769, -0.00037051237, -0.0021727397, -0.00022627195, -0.0013447638, -0.003204038, -0.0032796115, 0.0035673187, -0.0025599443, -0.00055468525, 0.0008608682, 0.0020440905, 5.9029197e-05, -0.0003815655, -0.00058243296, 0.0027183753, 0.0020101457, 0.0037264302]\n",
            "word is:Programming\n",
            "vec is:[0.0033061928, 0.00397882, 0.0009076117, 0.0020935242, -0.0016365417, 0.0029694769, 0.00160719, -0.004396075, -0.0024460547, -0.0036520164, -0.0047163167, -0.0034415422, -6.799929e-05, 0.0027401242, -0.0028314306, 3.6313788e-05, 0.0048674014, 0.0019511459, 0.001941807, 0.003343305]\n",
            "word is:Fundamentals\n",
            "vec is:[0.004124168, -0.0016507893, -0.004482601, 0.002999295, -0.0027654541, 0.0013721933, -0.0008801165, 0.002575016, -0.002905559, -0.0029234386, 0.00042811135, -0.0022687973, -0.0042342623, -0.0048593706, -0.0035994553, -0.00309611, -0.0006710349, 0.0015812607, -1.042058e-05, 0.0015880062]\n",
            "word is:course\n",
            "vec is:[-0.003918853, 0.0034107522, -0.0026743086, -0.0011797968, 0.0012203868, -0.0014174192, -0.0041509164, -0.0017489452, 0.0022713435, -0.0004621903, -0.0022816532, 0.0014546727, -0.00010160552, -0.0042068125, 0.0030402213, 0.0026321805, -0.0047671427, 0.00033618096, 0.0026084709, -0.0028534806]\n",
            "word is:code\n",
            "vec is:[-0.0008197671, -0.0022214444, -0.0034230812, -0.0012222193, -0.0050049885, -0.005160991, -0.0003890186, 0.00068628613, 0.0028175653, 0.00038320012, -0.0013143647, -0.0002986595, 0.0029646473, -0.0028650537, 0.0018399452, 9.379165e-05, -0.0021608148, 0.0043296875, 0.0018669495, 0.0021782545]\n",
            "word is:CS118\n",
            "vec is:[0.0039701588, 0.004004886, -0.00023417937, -0.004241825, -0.0044114953, 0.000861173, -0.0011535864, -0.0023372998, 0.0042449352, -0.0015242377, -0.004382558, -0.003949538, -0.0028364444, 0.0029656275, -0.0014997286, 0.0046343436, -0.0025393767, 0.0048464844, 0.0014056646, 0.0019199636]\n",
            "word is:DatabaseSystems\n",
            "vec is:[-4.5929202e-05, -0.00035398264, 0.0034534212, 0.0007673231, 0.0032566853, -0.0022358282, 0.0025524728, 0.00075039454, -0.0010117214, -0.0026765892, 0.0050127646, -0.0026369295, 0.001606926, -0.00274082, -0.0045575495, -0.0009283182, -0.0021858923, -0.0037839788, -0.0031029684, -0.001164948]\n",
            "word is:CS203\n",
            "vec is:[0.0026478143, -0.00039620508, 0.0045778775, 0.0030513485, -0.003434165, 0.003209705, 0.0010619671, 0.004645577, 0.0009958044, -0.00316456, -0.00046643257, -0.0011418344, 0.004669494, -0.000663493, -0.00047023376, 0.00055331585, 0.004952068, -0.00325635, 1.4490797e-07, 0.0032220143]\n",
            "word is:OperatingSystems\n",
            "vec is:[0.0034848507, 0.0019868913, 0.0017513246, 0.0017364599, 0.0011248584, -0.00030934607, 0.0049954485, 0.0036797326, 0.0035969848, -0.0009188119, -0.0018676063, 0.004052345, 0.0030609574, 0.0004722887, 0.00010461347, -0.00026704496, -0.003906695, -0.0013196039, 0.002401474, -0.0038874382]\n",
            "word is:CS205\n",
            "vec is:[-0.00040303046, -0.00017844631, -0.0035587763, 0.0015556831, -0.001495542, 0.0038598578, -0.0047847256, -0.0031753434, -0.0030981111, 9.881714e-06, 0.003634873, 0.0038738986, -0.004699542, -0.0042267214, 0.0020577544, -0.0038955258, -0.00084514805, 0.00041713793, 0.00054841506, 0.000571074]\n",
            "word is:ComputerArchitecture\n",
            "vec is:[-0.0046853176, -0.001118049, 0.00069884356, -0.0024240075, -0.0017832868, 0.0017868102, -0.0022577315, -0.0005159307, -0.0048870738, -0.0012050646, 0.0021963252, -0.0031666118, -0.0027404886, -0.0043119383, 0.0017429386, 0.0007019645, 0.0011268329, 0.0009110623, -0.0044549447, 0.0036665306]\n",
            "word is:EE204\n",
            "vec is:[0.002987598, 0.0017687965, -0.0017821164, 0.00041501733, 0.00019326688, -0.00077495293, -0.0041316384, -0.0031406356, 0.0006770573, 0.0012815731, -0.004159105, 0.0006748955, -0.0048737465, 0.000611555, 0.001942714, 0.00012484378, -0.0046025543, 0.00480531, 0.0035087916, 0.002027772]\n",
            "word is:ComputerOrganization&AssemblyLanguage\n",
            "vec is:[0.001340455, 0.00161597, 0.004517498, -0.0030702227, -0.0023687158, -0.0011776898, 0.0035339762, 0.0030661325, -0.001826385, 0.001440211, -0.0021011615, -0.0036573976, -0.0036351532, -0.0011099793, 0.002164819, -0.002994292, 0.0016921331, -0.0026601993, 0.0003268155, -0.00020925919]\n",
            "word is:EE213\n",
            "vec is:[0.003183109, 0.0035816815, 0.0018858882, -0.00019170194, 0.0007291814, -0.0019492649, -6.9218727e-06, 0.0029015744, -0.0014765885, -0.0010857368, 0.0045532854, 0.00030715397, -0.0024750032, 0.00043556234, -0.0044278414, -0.004765067, -0.0042531416, 0.0033382042, -7.523851e-05, 0.0019493334]\n",
            "word is:DataStructures\n",
            "vec is:[0.0033903136, 0.0013937294, -0.0010414539, 0.002158096, 0.00015491075, -0.0028616844, 0.0047974405, 0.0013621277, -0.0046910574, 0.0022281224, -0.0012064883, 0.00436512, 0.0012988329, -0.0039755185, -0.0042635286, 0.0034499008, -7.551009e-05, -0.00039962205, 0.00483751, -0.003704302]\n",
            "word is:CS201\n",
            "vec is:[0.0047946335, 0.0009725169, 0.003408783, -0.002971756, -0.0005799431, -0.004829011, 0.0026500137, 0.0045630634, -0.0005171512, 0.0019950864, 0.0046963217, 0.0011700391, -0.004105475, 0.0003440207, 0.004834704, -0.0033895473, -0.0022754471, 0.001872716, -0.0008449481, -0.00018733041]\n",
            "word is:Design&AnalysisofAlgorithms\n",
            "vec is:[0.00010349035, 0.0019868247, -0.0026780583, 0.0014127285, -0.0036031273, 0.004895519, 0.0018999346, -0.0009364712, -0.004606983, -0.0014649808, -0.0027686094, 0.00462529, 0.001084208, 0.0030668457, -0.0011883028, -0.0015096362, 0.0011160608, 0.0035339447, -0.0011119271, -0.003327889]\n",
            "word is:CS302\n",
            "vec is:[-0.0026468125, -0.0012745066, 0.0035707976, -9.481905e-06, -0.004250085, 0.002179707, -0.004485494, 0.002098689, -0.0014010746, 0.0017749843, 0.0036535559, -0.0022549035, -0.0026102846, -0.003996125, -0.0008719701, -0.0017236725, -0.00254009, -0.0014080651, 7.7264616e-05, 0.0011700303]\n",
            "word is:SoftwareEngineering\n",
            "vec is:[-0.0046821856, -0.0031616143, 0.0023436053, 0.0026177552, 0.00054220686, -0.00090263353, 0.0030105223, -0.0036307105, 0.003915538, 0.003268076, 0.0032897524, 0.0040989425, -0.0036179717, -0.0046537234, 0.0010272199, -0.0033841487, -0.0018737726, -0.00464399, -0.0035338837, -0.0008468865]\n",
            "word is:CS303\n",
            "vec is:[-0.0036178203, 0.0009087772, 0.0047801156, 0.0014674668, 9.4508956e-05, 0.00482942, -0.004169536, -6.3428684e-05, -0.0022134057, 0.0021807833, -0.004672445, -0.0014101941, 0.0035904332, 0.0047323923, 0.0015289009, -0.0017703576, 0.0014483166, 0.0044246856, -0.0033283315, 0.0017808779]\n",
            "word is:WebProgramming\n",
            "vec is:[-0.00031333417, -0.0003353405, -0.0047331336, -0.0019861753, -0.0028619485, -0.0020822121, -2.9538514e-05, 0.0028755737, -0.001385997, 0.0012211073, 0.00048448445, 0.004279183, -0.0027580226, -0.0017667939, 0.0038314618, 0.0028848208, 0.0015392115, 0.002038987, -0.0044050463, 0.00090535055]\n",
            "word is:CS406\n",
            "vec is:[-0.0015620522, 0.00057767134, -0.0031741208, -0.00055408524, -0.002390134, -0.00027972204, 0.0027784472, -0.0036469384, 0.001064839, -0.004784067, 0.0036507624, -9.242175e-05, -0.0023822293, 0.0031263991, 0.0034405633, -0.004000293, -0.003756971, -0.0048326985, -0.00032374868, -0.0028835086]\n",
            "word is:Bio-Informatics\n",
            "vec is:[-0.003619241, -0.0014133306, 0.0015821367, 0.0012878993, -0.0025979832, -2.0006119e-05, -0.0026054885, -0.0034644173, -0.0045164474, -0.003540729, -0.0024438908, -0.004116794, -0.00088676205, 0.00074131973, 0.00012576935, 0.001928548, -0.0028511118, 0.003646174, -0.0029603275, 0.00015596066]\n",
            "word is:CS508\n",
            "vec is:[0.0018343711, -0.0014400412, -0.0041471594, -0.001295932, -0.00030130052, 0.0032883289, 0.0018540674, 0.004641028, 0.0020982497, 0.004692097, -0.0016333687, 0.0012899754, 0.0036788983, -0.004946309, 0.0039656684, -0.00095759257, -0.002914272, 0.00465177, 0.004214949, 0.0010679938]\n",
            "word is:MobileComputing\n",
            "vec is:[-0.00033244808, 0.0026472043, -0.000226081, 0.00010703314, -0.004768265, 0.0024853447, -0.001222344, -0.0036834264, 0.0021377562, -0.0011425358, 0.0010730188, -0.0047988216, 0.0007202206, -0.004590515, -0.004537468, 0.0033921252, -0.0036623017, -0.0034663358, -0.0047261086, 0.0038545239]\n",
            "word is:CS575\n",
            "vec is:[-0.0023816924, -0.00014245468, -0.003234705, 0.0036460077, 0.0020501094, -0.0011152505, 0.0002373403, 0.0021292903, -0.0012535763, -0.0027670248, 0.0049022217, 0.00010968507, 0.00034773882, -0.0016453272, 0.0002823674, 0.0013000739, -0.0031666197, -0.0029700764, -0.0017703687, 0.0024929536]\n",
            "word is:AdvancedDatabaseSystem\n",
            "vec is:[-0.005037096, -0.0041637644, 0.002273936, -0.0009283999, -0.003342121, -0.0021812548, 0.0028569899, -0.0027964874, 0.002708603, 0.00072902214, -0.002111703, -0.0049079293, 0.004566874, 0.003907483, 0.0015061027, 0.0010928959, 0.004146908, -0.0030673128, 0.005000413, 0.0022659872]\n",
            "word is:CS502\n",
            "vec is:[-0.0017703129, -0.0038271893, 0.0030742236, -0.0010370928, -0.0035735134, 0.004059106, 0.0005976464, 0.005013545, 0.003987114, 0.0037984173, -0.002936268, -0.0026454222, -0.00020973873, 0.0014440109, 0.001314008, 0.0019931837, 0.00073941995, -0.0022128911, -0.0036064265, -0.0045639984]\n",
            "word is:DataMining\n",
            "vec is:[-0.0010660496, -0.004641963, -0.00413712, 0.0048973016, 0.0013522021, -0.0026398415, -0.0044983258, -0.0023214282, 0.0040021166, 0.003755229, 0.00023263127, 0.0016216127, -0.0013313582, -0.004032916, -0.0019142586, 0.0025252395, -0.0014863651, -0.0024802624, -0.0040921043, 0.004350776]\n",
            "word is:CS429\n",
            "vec is:[0.0009447392, 0.0022424825, 0.00022270804, 0.0014560571, 0.001427143, -0.003362762, 0.0039036972, -0.001999415, -0.003340703, 0.0026744993, -2.5173676e-05, 0.0017524178, -0.0039160517, 0.0044652056, 0.002494572, -0.002393878, 0.0040791202, -0.0025734738, 0.002697295, 0.0016901435]\n",
            "word is:SoftwareforMobileDevices\n",
            "vec is:[-0.0041043316, -0.0029098147, -0.0032998463, -0.0015276157, -0.0034208791, -0.0025262071, -0.0012189527, 0.0037618282, 0.0025580262, -0.003997683, -0.0034233788, 0.0025226928, 0.0029449018, 0.0017082093, 0.0021821312, 0.0015184219, -0.0021317597, 0.0044620163, -0.0011070109, -0.0026180076]\n",
            "word is:ObjectOrientedAnalysis&Design\n",
            "vec is:[0.000614401, -0.003326803, -0.004695334, -0.003411529, -0.0026332075, 0.004427867, 0.004352011, 0.001078029, -0.00017435038, 0.0024282557, 0.0040908465, -0.00058104895, 0.0042928266, -0.0039333426, 0.0041333726, -0.000631932, -0.0014291708, 0.0031845062, 0.0015522939, -0.0040595024]\n",
            "word is:CS309\n",
            "vec is:[-0.00023084354, -0.001763179, -0.0029019252, 0.0037646925, -0.0026232474, 0.002401422, -0.004663503, 0.0049926043, 0.00044542935, 0.004505537, -0.0038559965, 0.003001894, 0.0014223355, -0.004896062, -0.0030865625, 0.0049080444, -0.00063978427, 0.0006871883, 0.0043480196, 0.0026646475]\n",
            "word is:ComputerNetworks\n",
            "vec is:[0.004540961, 0.0026422483, -0.0013579153, 0.0019074124, -0.0035481194, 0.0045980522, 0.0014022866, 0.0036849428, 0.0036981888, 0.00087143603, 0.004896814, 0.00080887484, -0.00012917366, 6.574966e-05, 0.00083435903, 0.004054515, -0.0036586677, -0.0034723892, -0.0046154256, 0.0027071254]\n",
            "word is:CS307\n",
            "vec is:[0.0038873495, 0.004646572, 0.002698611, 0.0016103603, -0.0037847515, -0.0014111202, -0.0002837335, 0.0024049224, -0.001178497, -3.879981e-05, -0.0011806381, 0.004791384, 0.002813849, -0.002382913, 0.0015975431, 0.00015125764, -0.0007365011, -0.004678799, 0.0029479966, 0.004371805]\n",
            "word is:Project-I\n",
            "vec is:[-0.001596908, -0.002350759, 0.0027236408, 0.002870615, 0.0025163202, 0.00088365097, 0.0046595116, 0.0031158687, 9.369553e-05, -0.0011326813, -0.0007986915, 6.030882e-05, -0.00045455396, 0.004204476, -0.0045438926, -0.001457696, 0.0046466314, -0.001794079, -0.0043086116, -0.0016914164]\n",
            "word is:CS491\n",
            "vec is:[-0.0023371992, 0.0025644356, 0.0012207207, -0.0041588256, 0.001335848, -0.0040063267, 0.00011617721, 0.0014101061, 0.004279447, -0.0014878948, 0.004631768, 0.0008255238, 0.0014267695, 0.001579422, 0.001882439, -0.0044092145, -0.0031682285, 0.0020705156, 0.0030527029, -0.001003912]\n",
            "word is:Project-II\n",
            "vec is:[0.0036309478, -0.0015606458, -0.0029220183, 0.0004634886, 0.00049464137, 0.00226288, 0.004772384, -0.002689661, -0.0015278064, -0.00045796527, 0.00045801993, 0.004278132, -0.0022514788, 0.002115185, -0.0021744517, 0.0040488294, -0.00012309672, -0.0009222318, -0.004748582, 0.0005983085]\n",
            "word is:CS492\n",
            "vec is:[-0.0033056778, 0.003021328, 0.0032339902, -0.0036050337, -0.0049569192, -0.0035437392, -0.0010224741, -0.0034846931, -0.003380762, 0.003665477, 0.0032549803, -0.0021342873, -0.002564425, 0.002031905, -0.0022920263, 0.0012332476, -0.0018741554, 0.0048428555, 0.00021205955, -0.0046395073]\n",
            "word is:ProfessionalIssuesinIT\n",
            "vec is:[0.0035514329, 0.003775022, 0.0041155624, -0.0024374642, -0.0019140355, 0.0046034534, 0.0032190597, 0.00071173685, -0.0027598308, -0.0013299114, 0.003227977, 0.002074484, -0.0039842026, 0.0041114725, -0.0035663703, 0.0017292773, 0.0024416184, 0.004498999, -0.0036089013, -0.0016548659]\n",
            "word is:CS449\n",
            "vec is:[-0.0026888165, 0.0047388785, 0.0016726943, 0.0024772268, -0.0018086053, 0.0007531896, -0.004288649, 0.0012279674, 0.0037043097, -0.0035275696, 0.00480007, -0.004442477, 0.0029796408, -0.00054976036, 0.001941856, 0.0047983536, -0.0025701262, -0.0016388537, 0.0007231736, 0.00024141223]\n",
            "word is:HumanComputerInteraction\n",
            "vec is:[0.00036730905, 0.0042518554, 0.00032832366, -0.000642398, -0.0040842514, -0.00364147, 0.0039538424, 0.0013619177, 0.004836752, 0.0042193085, -0.002967894, 0.0019121291, -0.0015212857, -0.0014505204, 0.0044066366, 0.004662285, -0.0043105637, 0.0031798824, 0.0030762996, 0.0012676304]\n",
            "word is:CS422\n",
            "vec is:[0.0004414069, -0.0012979499, -0.0018686382, 0.004965938, 0.0006382052, 0.004299743, -0.0038355533, 0.0029081714, -0.0014771951, -0.0037721375, -0.0014556573, -0.0009760825, -0.00025760807, -0.0029086429, -0.0036458063, 0.0013100422, 0.000581361, -0.00071674475, 0.0041822777, -0.0008939432]\n",
            "word is:NetworkSecurity\n",
            "vec is:[-0.0012340858, 0.0015447872, 0.00026739005, -0.0020598697, -0.004603038, 0.0037521739, 0.004647245, 0.0020148372, 0.0009965048, 0.004122461, 0.0019658925, -0.00063667615, -0.00307288, 0.0034966785, 1.345853e-05, 0.0026878433, 0.0041874596, 0.0039779535, -0.0012131176, -0.0020648239]\n",
            "word is:CS411\n",
            "vec is:[0.0049271015, -0.00248288, -0.0018894743, 0.0038373647, -0.0037877918, -0.0012730913, 0.0046645394, 0.003712626, 0.0039564623, 0.0033012624, 0.0014785172, 0.0038865942, 0.00013908034, 0.004874767, 0.0041343514, 0.0027127624, 0.00056417496, 3.598894e-05, -0.0022838088, 8.71623e-05]\n",
            "word is:UserExperienceEngineering\n",
            "vec is:[-0.00088433566, -0.0038699196, 0.0005655385, 0.0014232735, 0.0015501706, -0.00025234764, -0.0023731363, -0.0031968784, -0.0015396313, -0.0033198944, 0.00405048, 0.0045279823, 0.0050078034, -0.0038040543, -0.0033546223, 0.0049148337, -0.002400083, -0.00015993223, -0.00028827562, 0.0025418487]\n",
            "word is:CS5107\n",
            "vec is:[0.0024428503, -0.0007041626, -0.0023160917, 0.0050390624, 0.003810372, 0.0021757341, 0.003628127, -0.0022814027, -0.0017108169, -0.0044977195, -0.00078648987, 0.0041728457, 0.00092116586, -0.00093040394, -0.0035390393, 0.004159079, -0.0004874266, -0.003070386, 0.0006539553, -0.0007687322]\n",
            "word is:AdvancedMobileApplicationDevelopment\n",
            "vec is:[-0.0007179845, 0.0009830403, 0.0046361974, 0.0014487854, 0.0032703253, 0.001650429, 0.003723132, 0.00046862793, 0.0016815095, -0.003993824, -0.00031404587, -0.0012766327, -0.0015878903, -0.0040320107, -0.0010020798, -0.00013774284, -0.0010917404, -0.004867204, -0.004084904, 0.0015346135]\n",
            "word is:CS464\n",
            "vec is:[-0.0036210918, 4.905904e-05, 0.0007568845, -0.0012542298, 7.9475605e-05, -0.0043870923, 0.001908669, -0.0011537197, 0.00077836163, -0.0029361139, -8.5971624e-05, -0.004717754, -0.002286489, 0.0010674886, 0.002350058, 0.00032258287, 0.0023464211, 0.0017478444, 0.0001301773, 0.004864051]\n",
            "word is:Parallel&DistributedComputing\n",
            "vec is:[0.0024199346, -0.0024769076, 0.0039343913, 0.0011703909, 0.0024191465, -0.004171654, 0.0049345507, 0.0041363016, 0.00095321226, 0.0041144765, -0.003426629, -0.00092286075, -0.00057440816, 0.003098889, 0.004296986, -0.0028374374, 0.0028454044, -0.004559566, 0.0032147248, -0.001604465]\n",
            "word is:CS416\n",
            "vec is:[0.00024570344, 0.0029203885, -0.002908921, -0.0028221244, -0.0026357442, 0.0029061295, -0.0001279996, -0.0048360387, 0.00014528737, -0.0024865195, -0.0012732772, -0.0004010477, -0.0031694572, 0.0035951766, 0.0012602684, -1.6675607e-05, 0.004192231, -0.0045870338, -0.0038380828, 0.0025299587]\n",
            "word is:SoftwareTesting\n",
            "vec is:[-0.004050816, 0.0009086975, -0.004665528, -0.00014705886, -0.0037748916, -0.0015789644, -0.0005094626, -0.0034467904, 0.0004922388, 0.0039181733, -0.0045281784, -0.004452896, -0.0004493901, -0.0014640725, 0.0041819415, 0.0010513266, 0.0008713353, 1.8528674e-05, 0.0039092707, -0.0019475687]\n",
            "word is:CS497\n",
            "vec is:[-0.0045890734, -0.0025694673, -0.0043853484, -0.001293889, -0.0035239477, 0.0012790592, 0.0008057148, 0.0016042417, -0.0017472196, 0.0038804647, -0.004882387, -0.004190165, 0.0020313384, 0.0042202394, 0.003836824, -0.0038363528, 0.0020306185, -0.0005814668, 0.0023334525, 0.004759873]\n",
            "word is:MultiagentSystems\n",
            "vec is:[0.0015292285, 0.0032206054, 0.0023133876, -0.0047533414, 0.0025395988, -0.00087931665, 0.0011894545, -0.0018259276, 0.0012181127, 0.00068803265, -0.0017104052, 0.0020523837, -0.003447449, 0.0032274495, 0.002524623, 0.0034253553, 0.001536895, -0.0014902635, -0.003238824, -0.00055651076]\n",
            "word is:CS545\n",
            "vec is:[0.0033443545, 0.0006133014, 0.0002580477, -0.004504587, 0.004882434, 0.00029801606, -0.004829977, 0.003695578, 0.003183728, -0.0016845163, 0.0011030883, 0.004074099, -0.0029103032, 0.0032856197, 0.0036021238, -0.0030502083, -0.0007674313, -0.002229016, 0.0044446583, -0.00093635655]\n",
            "word is:SocialNetworksAnalysis\n",
            "vec is:[-0.0046006157, 0.004294851, 0.0040501147, -0.004749959, 0.0022396825, 0.004660736, 0.003171531, -0.0040495596, 0.0020567148, 0.0025005254, -0.000658017, -0.0021435122, -0.0020409506, 0.0029425249, 0.00049699465, 0.0011965029, 0.0047951792, -0.0038098411, 0.0011275152, 0.0029107712]\n",
            "word is:CS5115\n",
            "vec is:[-0.0015738339, 0.0012570589, -0.0046191956, -0.0024294518, -0.0013978834, 0.0028226378, 0.0026184607, 0.0034031775, 0.004408337, -0.00029473516, 0.0037703775, -0.0022905625, -0.00070254394, -0.00020884692, 0.002421339, 0.00251048, 0.0031542587, -0.0012515564, 0.003671393, 0.00033648065]\n",
            "word is:IntrotoSoftwareProjectManagement\n",
            "vec is:[-0.00097337255, -0.0033015863, -0.001103574, 0.00047896983, 0.0020929906, 0.00038091332, 0.00035976496, -0.0010984923, -0.00119172, 0.00062896067, 0.00047868575, 0.000775712, 0.0029528479, 0.004012882, -0.0012603642, 0.0044112527, -0.0041461852, 0.0028278194, -0.003227093, -0.0015124432]\n",
            "word is:CS450\n",
            "vec is:[-0.0034732472, 0.0018664092, 0.0045326245, -0.00047416982, 0.004524102, -0.0008060609, -0.0039046856, -0.003232165, -0.0014808564, -0.002168827, -0.0008665632, 0.0027730947, 0.0025711905, 0.0019276642, 0.0010164947, -0.0049747657, 0.0010173734, -0.0030565844, 0.004993686, -0.00031699915]\n",
            "word is:AdvancedAnalysisofAlgorithms\n",
            "vec is:[0.004741555, -0.00090432493, -0.0018289869, 0.0011959943, -0.0006778075, 0.004036249, -0.003099066, 0.00054853555, 0.004884136, -0.00014400495, 0.0019250361, 0.00396938, 0.0044406275, 0.0030021304, 0.0010520932, 0.0015279722, -0.0007479618, 0.0034267385, -0.0017920021, 0.0042868196]\n",
            "word is:CS501\n",
            "vec is:[-0.0023732614, -0.0003512966, -0.0022859897, -0.0015053189, -0.0020671936, -0.004041539, 0.0013217566, -0.0023170311, -0.0014400829, 0.0028409297, -0.0045460593, -0.00036712227, -0.0045483033, 0.00069176854, 0.0005406059, 0.0032514348, 0.0048760762, -0.0016914534, -7.793314e-06, -0.002523132]\n",
            "word is:TheoryofProgrammingLanguages\n",
            "vec is:[-0.0020864594, 0.0018107789, -0.0043306, -3.0137264e-05, 0.0005175615, 0.0030873485, 0.0015048743, 0.003518429, 0.0014042502, -0.0018113371, -0.0011744187, -0.0039952807, -0.0038811006, -0.00040445276, -0.0026835187, -0.0019715994, -0.0048709824, 0.00077416084, -0.00034645575, 0.001348004]\n",
            "word is:CS507\n",
            "vec is:[0.00060663704, 0.0041046636, -0.00033470837, 0.004266639, 0.0027396171, 0.0026379612, 0.0035260024, -0.00079092616, 0.003555633, 0.0011956358, 0.0014205098, 0.0039541437, 0.002142078, -5.2501542e-05, 0.004049424, -0.0019071439, 0.0031795288, 0.0031231386, -0.0027262, -0.0001590243]\n",
            "word is:CyberandNetworkSecurity\n",
            "vec is:[0.0028776366, -0.0022743759, 0.0016775078, 0.003890531, 0.00493778, 0.0047589657, -0.003002349, 0.003937176, -0.0010919435, -0.001079765, 0.0049382863, -0.0048045306, 0.004128638, -0.0012203542, 0.0015082192, 2.9925382e-05, 0.004876283, -0.001981611, 0.0013230555, -0.0037139426]\n",
            "word is:CS630\n",
            "vec is:[0.0033257254, -0.0023872869, 0.004438778, -0.0015534973, -0.00028087664, 0.0041287984, -0.0016538013, -0.0035169893, 0.0031330665, 0.0024414868, -0.0031825285, -0.0009059644, -0.0035679836, -0.0027909093, 0.001712195, -0.0040499303, -0.0027791932, -0.0022410632, -0.0037871834, -4.1894364e-05]\n",
            "word is:PerformanceofComputerNetworks\n",
            "vec is:[0.0006192057, -0.002178901, 0.004342547, 0.0036781386, -4.9572165e-05, -0.0015941621, -0.0029621976, -0.0044320365, 0.0008783242, 0.0038339908, 0.00020475085, 0.0019148098, -0.0003705266, 0.0011042792, -0.0011994272, 0.00093172974, 0.0018479166, 0.0005004337, 0.0032779535, -0.0025934298]\n",
            "word is:CN501\n",
            "vec is:[0.0045334375, 0.0011303235, 0.0011196242, 0.005148669, 0.0036613028, 0.0038903619, -0.0007561124, -0.0039680307, 0.0041847266, 0.0024571316, 0.0038007132, 0.003979712, 0.0019044569, 0.0017527047, -0.004318892, -0.0012657447, -0.0006116015, 0.002165138, -0.0022100827, 0.0012247094]\n",
            "word is:SoftwareProcessModeling\n",
            "vec is:[0.0031709948, 0.0033233273, 0.0026753857, 0.00070630223, -0.0046515814, -0.0005839515, -0.0031441248, 0.0032500299, -0.0036486788, -0.0033797072, 0.0039716805, -0.0044436213, 0.001561296, -0.002537254, 0.0031900695, 0.0031528794, 0.0020278748, -0.0024258231, -0.0011409213, 0.0036224278]\n",
            "word is:CS516\n",
            "vec is:[-0.0031288362, 0.00102586, -0.0011628143, 0.0028773977, 0.0032531058, 0.0014695197, -0.0042787995, -0.0010434616, 0.001378684, 0.0041593853, -0.0033579688, -0.0012030065, -0.0037728194, 0.0027084183, 0.0036065711, -0.0011076529, 0.0031480237, -0.0001313402, 0.00030435334, -0.0016340628]\n",
            "word is:CloudComputing\n",
            "vec is:[0.0010916753, -0.0015886315, -0.003299611, 0.0038622455, 0.0029820935, 0.00033272264, 0.0040775924, 0.0032637392, -0.0015553703, 0.003736447, -0.0025291273, -0.00046058244, 0.0012247922, 0.0045806756, -0.0042079086, 0.001866541, 0.0015094738, -0.0026981856, 0.0021570558, -0.003763942]\n",
            "word is:CS579\n",
            "vec is:[-0.0016341726, 0.0035275223, 0.0047985436, 0.0037186895, -0.00039853418, -0.004782486, -0.00011372046, -0.0026096737, 0.00088662206, 0.0031307586, -0.0034956248, -0.0012367148, -0.0048290016, 0.0028797465, 0.0036795752, -0.0014457199, 0.002826203, -0.0019591257, 0.0036896067, -0.0007777182]\n",
            "word is:MachineLearningforDataScience\n",
            "vec is:[0.0023564326, 0.0011710121, 0.004284974, 0.00026500228, -0.0018151853, 0.0036165507, 0.0037347227, 0.0011645802, -0.0030050334, 0.000111905836, -0.0049758763, -0.0021271366, -0.0038775317, 0.0026401875, 0.0028193768, 0.0048439, 0.0009644618, -0.0006213129, 0.004013891, -0.0036246374]\n",
            "word is:DS503\n",
            "vec is:[0.001660462, 0.0028560716, -0.0034181764, 0.0012701998, 0.000495985, -0.0038847562, -0.00030435534, 0.0033153833, -0.0037450094, -0.0027576739, -0.0009614504, -0.0039097746, 0.0024430277, 0.0033968305, 0.00040433696, -0.0024392018, -0.002574673, 0.0030581774, 0.00068312365, -0.00057262566]\n",
            "word is:ComputationalIntelligence\n",
            "vec is:[-0.0015835558, -0.004281125, 0.0003118692, -0.0009947381, 0.002298452, -0.00067870674, 0.0045889434, 0.0045724064, 0.0016892209, -0.0040350063, 0.00056368683, -0.001985221, 0.00397425, -0.004314189, 0.0041301697, -0.0040446264, 0.0006376324, -0.0030077535, -9.2765986e-05, 0.0022684745]\n",
            "word is:CS549\n",
            "vec is:[-0.0003911633, -0.0021754855, -0.003459493, 0.0025292113, 0.0042943195, 0.0025276907, -0.0010355796, 0.00025246272, -0.0039524455, -5.3543252e-05, 0.00079632114, 0.0010709577, 0.004303203, -0.00085100817, 0.0038701522, -0.0022533673, 0.00042105225, -0.0008710057, -0.001234935, 0.0033330403]\n",
            "word is:AppliedImageProcessing\n",
            "vec is:[-0.0021399457, -0.0009923766, -0.0034727668, 0.002556139, 0.0031153576, -0.004459042, 0.0014323889, -0.0048718867, 0.0029928065, -0.004516076, -0.0029054834, -0.0042179157, 0.0005100125, -0.0031904746, 0.0011438183, 0.0033078492, -0.004472951, 0.00097115553, 0.0025393069, -0.0012462605]\n",
            "word is:CS553\n",
            "vec is:[0.0044844057, -0.004076009, 0.0044342615, -0.0026128397, -0.0008508046, 0.0022204015, 0.0028728417, 0.0033671912, -0.0022181226, -0.00051705324, -0.0021764815, -0.002401581, -0.0047553424, 0.00045732956, -0.0031316914, 0.0030034569, -0.0043723504, -0.003190794, -0.0022515, -0.0032700207]\n",
            "word is:EvolutionaryComputations\n",
            "vec is:[-0.0024120854, 0.0028757134, 0.00086713256, 0.0017078945, -0.0012809584, 0.002913476, 0.0042801374, -0.0045527266, -0.0041854125, 0.0008663971, 0.0028153956, -0.005010474, 0.00097076915, 0.0016949676, 2.137742e-05, -0.0004119143, -8.8098954e-05, 0.002888579, -0.001371135, 0.0029827196]\n",
            "word is:CS566\n",
            "vec is:[-0.00093101495, -0.0035774717, 0.002208394, -0.00082926976, -0.004825582, -0.003878127, 0.0008967128, -0.00083295745, 0.0014307981, 0.00402027, -0.003042504, -0.0034007905, 0.0035867083, 0.0029865808, 0.0026041416, 0.0048963977, 0.0013263316, 0.0013147295, -0.00062196126, 0.00236461]\n",
            "word is:MSThesis-1\n",
            "vec is:[-0.0034854987, 0.00030130925, -0.0018812896, 0.0017767214, 0.0031399264, -0.0006726207, -0.002804446, -0.004769085, -0.0016246665, -0.0045485226, 0.00051521196, -0.0016378463, -0.004353934, 0.002992287, 0.0014560978, -0.0040230947, 0.0037889928, 0.0020051291, 0.004757182, -0.0017181011]\n",
            "word is:CS591\n",
            "vec is:[-0.0020257449, 0.002653085, -0.0015874563, -0.002001417, -0.0016457553, 0.0037200027, -0.004650248, -4.2104443e-06, 0.0028716116, -0.0010905376, 3.496733e-05, -0.004361791, -0.0030683666, -0.0049540563, 0.0017004465, 0.0020687825, 0.0015498765, -0.0013956496, -0.002262598, 0.0011042954]\n",
            "word is:MSThesis-2\n",
            "vec is:[0.0009767539, -0.0037294023, -0.0020658807, 0.0049454123, -0.0047850255, -0.0036337092, 0.00012395957, -0.0030577693, 0.0018019613, 0.0034367251, 0.0005459646, 0.0034239911, -0.00056897826, -0.0005504845, -0.003550504, 0.0028965813, -0.0011114994, 0.0049002897, 0.0047339513, 0.0041201594]\n",
            "word is:CS592\n",
            "vec is:[-0.004201128, -0.0024669752, 0.0024607559, -0.0040868446, 0.003519589, -0.003961212, -4.799008e-05, -0.0024877049, 0.0025176897, 0.002792339, -0.0031625065, -0.0018873833, -0.004645369, 0.00084358227, -0.002934822, 0.004850899, -0.0028223968, 0.0022459421, 0.004580331, 0.0006459656]\n",
            "word is:AdvancedQualityAssurance\n",
            "vec is:[0.0048059784, -0.0014387522, 0.00443374, -0.0043333787, 0.0015209692, 0.00013500675, -9.379936e-05, 0.0012080811, -0.0006579914, 0.0036266255, -0.004939162, -0.000112812195, -0.0023869965, -0.002369148, -0.0012761278, -0.0017443931, -0.0011711934, -0.00403249, 0.002592042, -0.00029624457]\n",
            "word is:SE501\n",
            "vec is:[-0.0030375284, -0.002269275, 0.0019376676, -0.002074657, -0.0041482174, 0.0041266056, 0.0025882432, 0.002187305, -0.0041892496, 0.0027594208, 0.0040490306, 0.0023630273, 0.0041410355, -0.0048039625, 0.0036254255, 0.0026530442, -0.002507442, -0.001441711, 0.0006377491, -2.0468988e-06]\n",
            "word is:AdvancedSoftwareRequirementsEngineering\n",
            "vec is:[0.0046573025, 0.004049503, 0.0028698796, 0.0035128284, 0.004540365, -0.0031263072, -0.004598056, 0.0033026966, -0.001578434, -0.0010416971, -0.00056777603, 0.002670347, -0.00483409, 0.0040652845, -0.00033972284, -0.0006705927, -0.004378406, -0.0023696856, 0.0024215134, 0.004804695]\n",
            "word is:SE502\n",
            "vec is:[0.00031432815, 0.00351261, -0.0033545694, 0.0017480869, -0.0024868587, -0.0020232017, -0.002404032, -0.002346876, -0.00328261, -0.0032104682, 0.0027460176, 0.0039114556, 0.003762111, 0.004151626, -0.001007796, 0.0010843562, -4.9616257e-05, 0.0025012814, 0.0046166666, 0.0007590963]\n",
            "word is:Model-drivenSoftwareEngineering\n",
            "vec is:[0.00088113244, 0.0015127378, 0.0009445007, 0.0052012806, 0.003874402, 0.0048970026, -0.0025071406, 0.0014174149, 0.0034777634, 0.004825075, 0.00095043104, -0.00014806974, -0.002228122, 0.0027301272, 0.0032412107, -0.0019745135, -0.0006799422, -0.004362158, -0.0024012052, 0.0018939425]\n",
            "word is:SE506\n",
            "vec is:[-0.00034132137, 0.0035479951, 0.0018341675, 0.004921135, 0.0005272645, -0.0008163415, 0.0024502426, 0.0015760778, 0.0044863243, 0.0043348363, 0.0022238502, 0.0036106042, 0.004815902, 0.0029192257, 0.004310756, 0.0048334, 0.00048566025, -0.003294362, -0.0023399757, 0.002431477]\n",
            "word is:SE591\n",
            "vec is:[-0.001080939, 0.004362033, 0.004556259, 0.00016898444, -0.0050126803, -0.0025871415, 0.004905484, -0.0032607028, -0.004258852, 0.0016326546, -0.0025865543, -0.0024267482, -0.0021259629, 0.0033864593, -0.0026757477, -0.0030978958, -0.00018949063, 0.00047412788, -2.3647583e-05, 0.0036375523]\n",
            "word is:SE592\n",
            "vec is:[-0.0034305416, -0.0016425769, -0.004267405, 0.0025835002, -0.0042859158, -0.0038361042, -0.0034394395, 0.0013379536, 0.0021865265, 0.0030738204, 0.0024128642, 0.0036509489, -0.001288785, 6.6241395e-05, 0.004704221, 0.0045876373, -0.0039219256, -0.0033337192, 0.00035333514, -0.0017417753]\n",
            "word is:BigDataAnalytics(MiningBigDatasets)\n",
            "vec is:[0.0049323235, -0.000442729, -0.0046376553, 0.0039067226, 0.00047389505, -0.0024637226, -0.0004877012, 0.002568046, -0.00011647509, -0.0012283102, 0.0012117318, 0.0016495963, -0.0019842277, -0.0004747388, 0.00455544, 0.0014231317, 0.0029540663, 0.0044228877, 1.7204771e-05, 0.002028649]\n",
            "word is:DS502\n",
            "vec is:[0.0024581533, -0.0031630683, 0.0023065985, 0.0023021407, -0.0011271898, -0.0027018776, 0.0022297772, 0.0018770277, -0.001201479, 0.00051404064, 0.0004970253, 0.0034406737, -0.0038814342, -0.0034448225, 0.0011111872, 0.0025683744, -4.734103e-06, 0.002788866, -0.0002078025, -0.00016983539]\n",
            "word is:Bio-Informatics(forDataScience)\n",
            "vec is:[1.6539543e-06, -0.0011269939, -0.0016455967, 0.002131028, -0.0043201055, 0.0034494346, -0.0048501203, -0.0005155407, 0.004961661, 0.0018400124, -0.0016084027, -0.0019975144, -0.0025922526, -0.0017660484, 0.0019696546, -0.0019298624, 7.333262e-05, -0.0049333596, 0.004335621, 0.00058735884]\n",
            "word is:TopicsinSoftwareEngineering\n",
            "vec is:[-0.0024120146, -0.0037988788, 0.0045826384, -0.004141104, -0.0033102483, -0.002413942, -0.00024776312, -0.0013801112, -0.0005722214, -0.00266053, 0.0033669476, -0.004993211, -0.0006169658, -0.003511176, -0.0034178006, -0.0039813435, 0.0036222595, -0.0029827496, 2.431179e-05, 0.0022943958]\n",
            "word is:CS625\n",
            "vec is:[0.004275475, -0.0031333086, -0.0006547212, 0.00093329285, 0.0016097431, -0.0044708643, -0.0042309137, 0.0025242115, 0.0050159018, -0.0033210262, 0.0030348704, 0.000709934, -0.0019414524, 0.0019652692, -0.0046888557, -0.00024925885, -0.0017392811, 0.0004140173, 0.004650586, -0.0014025468]\n",
            "word is:Search-BasedSoftwareEngineering\n",
            "vec is:[0.0033709728, 0.0025713365, -0.0032688796, 0.00051184447, 0.0027284804, -0.004657575, -0.00030182805, 0.00089976174, 0.0013277011, -0.0030198577, 0.004292632, 3.64983e-05, -0.004757602, 0.0036603701, -0.0010962673, 0.0030057218, -0.001183628, 0.00031595517, -0.0044742217, 0.0047159544]\n",
            "word is:SE507\n",
            "vec is:[6.47456e-05, 0.003613852, -0.00026954018, -0.0033002566, 0.0018535196, -0.0039470727, -0.003890699, 0.004032663, 0.0016171853, 0.00023418029, 0.0029609194, -4.2402193e-05, -0.00221216, 0.0023380734, -0.0035381282, 0.0023451447, 8.1846534e-05, 0.0043727616, 0.0024359764, -0.0004640101]\n",
            "word is:Aspect-OrientedSoftwareEngineering\n",
            "vec is:[-0.004065321, -0.003978581, -0.00402056, -0.00084535405, -0.0012182205, -0.00457295, -0.0022201824, 0.0046990053, -0.0031308134, 0.00059977814, 0.0011327149, -0.00078620785, 0.0043709516, 0.0022411337, 0.003056266, 0.0021728936, 0.0008443827, -0.0015250447, 0.0024757306, -0.004251787]\n",
            "word is:SE601\n",
            "vec is:[-0.0029128273, 0.00025717303, 0.004829864, -0.0024038996, -0.0023011551, -0.0048980974, 0.0008624046, 0.00059824, -0.0028540676, 0.0044461363, 0.0031927796, -0.0018268275, 0.00022492709, 0.0015943075, 0.0011831267, -0.0017593651, -0.0004945919, -0.0036029909, -0.0009171546, 0.002838896]\n",
            "word is:DataScienceToolsandTechnique\n",
            "vec is:[0.004086995, 0.0021390675, -0.0035783038, 0.0047826, -0.0042326427, 0.0044331723, -0.0017721845, -0.0022508444, -0.0031387287, 0.0034821962, -6.150726e-05, -0.003874624, 0.001462743, 0.0017009176, -0.003678213, -0.0048584086, -0.002847247, -0.004487354, -0.0036775598, 0.0004375331]\n",
            "word is:DS500\n",
            "vec is:[-0.00021116639, 0.0027342495, -0.0011883251, -0.004052359, -0.0016561295, -0.0014913115, -0.0040398915, 0.00027595833, -0.0019409478, -0.0034261337, -0.0047737355, 0.00033437545, -0.0017876182, 0.0015073175, -0.0041132206, 0.0029486662, -0.0021031757, 0.004155316, -0.00067748636, 0.004134976]\n",
            "255\n",
            "2427\n",
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " ...\n",
            " [-0.00291283  0.00025717  0.00482986 ... -0.00360299 -0.00091715\n",
            "   0.0028389 ]\n",
            " [ 0.004087    0.00213907 -0.0035783  ... -0.00448735 -0.00367756\n",
            "   0.00043753]\n",
            " [-0.00021117  0.00273425 -0.00118833 ...  0.00415532 -0.00067749\n",
            "   0.00413498]]\n",
            "size of keyword vocabulary: 191\n",
            "size of keyword list kwd_ls: 880\n",
            "this is kwd_voc:['Mr.HassanMustafa', 'ObjectOrientedProgramming', 'CS217', 'sectionA', 'Batch2018', 'sectionB', 'Batch', '2018', 'sectionC', 'Ms.AtifaSarwar', 'sectionD', 'Dr.MuhammadArshadIslam', 'sectionE', 'Mr.JawadHassan', 'sectionF', 'sectionG', 'Dr.MehwishHassan', 'DigitalLogicDesign', 'EE227', 'Ms.MehreenAlam', 'Ms.SanaHassan', 'Dr.AdnanSaeed', 'ProgrammingFundamentals', 'CS118', 'Repeat', 'Dr.EjazAhmed', 'DatabaseSystems', 'CS203', 'Batch2017', 'Dr.AsmaAhmad', 'Dr.HasanMujtaba', 'OperatingSystems', 'CS205', 'Dr.MuhammadAdnanTariq', 'Ms.SidraKhalid', 'Dr.AtifMughees', 'ComputerArchitecture', 'EE204', 'Dr.OmerBeg', 'Mr.ShamsFarooq', 'Ms.SabaRasheedMalik', 'ComputerOrganization', 'AssemblyLanguage', 'EE213', 'Ms.SaroshShahid', 'Mr.HafizTayyebJaved', 'DataStructures', 'CS201', 'Mr.ShujaatHussain', 'Design', 'AnalysisofAlgorithms', 'CS302', 'Batch2016', 'Ms.AmnaIrum', 'Dr.IrumInayat', 'CS303', 'Dr.NaveedAhmad', 'Dr.ArshadAliShahid', 'Dr.LabibaFahad', 'Dr.AtifJilani', 'WebProgramming', 'CS406', 'Dr.HammadNaveed', 'Bio-Informatics', 'CS508', 'section', 'A', '2016', 'Dr.Muhammad', 'Adnan', 'Tariq', 'MobileComputing', 'CS575', 'AdvancedDatabaseSystem', 'CS502', 'Dr.OmerIshaq', 'DataMining', 'CS429', 'SoftwareforMobileDevices', 'CS', '575', 'instructor', 'ObjectOrientedAnalysis', 'CS309', 'Dr.KashifMunir', 'ComputerNetworks', 'CS307', 'Dr.AmnaBasharat', 'Project-I', 'CS491', 'Batch2015', 'Project-II', 'CS492', 'Ms.NoorulAin', 'ProfessionalIssuesinIT', 'CS449', 'Ms.UzmaBibi', 'HumanComputerInteraction', 'CS422', 'Dr.MuhammadAsim', 'NetworkSecurity', 'CS411', 'UserExperienceEngineering', 'CS5107', 'AdvancedMobileApplicationDevelopment', 'CS464', 'Dr.EhteshamZahoor', 'Parallel', 'DistributedComputing', 'CS416', 'CS497', 'MultiagentSystems', 'CS545', 'SocialNetworksAnalysis', 'CS5115', 'Dr.WaseemShahzad', 'IntrotoSoftwareProjectManagement', 'CS450', 'Dr.HammadMajeed', 'AdvancedAnalysisofAlgorithms', 'CS501', 'sectionY1', 'MS', 'sectionY2', 'TheoryofProgrammingLanguages', 'CS507', 'sectionY', 'CyberandNetworkSecurity', 'CS630', 'PerformanceofComputerNetworks', 'CN501', 'CS516', 'CloudComputing', 'CS579', 'MachineLearningforDataScience', 'DS503', 'ComputationalIntelligence', 'CS549', 'AppliedImageProcessing', 'CS553', 'EvolutionaryComputations', 'CS566', 'Dr.MuhamamdArshadIslam', 'MSThesis-1', 'CS591', 'Y', 'MSThesis-2', 'CS592', 'sectionZ', 'CNS', 'Dr.UzairKhan', 'AdvancedQualityAssurance', 'SE501', 'sectionX', 'SE', 'AdvancedSoftwareRequirementsEngineering', 'SE502', 'Dr.ZohaibZafarIqbal', 'Model-drivenSoftwareEngineering', 'SE506', 'SE591', 'SE592', 'Dr.KifayatUllahKhan', 'BigDataAnalytics', 'MiningBigDatasets', 'DS502', 'sectionU1', 'DS', 'forDataScience', 'sectionU', 'TopicsinSoftwareEngineering', 'CS625', 'sectionP', 'PhD', 'Dr.', 'Atif', 'Jilani', 'Search-BasedSoftwareEngineering', 'SE507', 'Uzair', 'Khan', 'Aspect-OrientedSoftwareEngineering', 'SE601', 'DataScienceToolsandTechnique', 'DS500', 'AdvancedTopicsinCS', 'CS628', 'Fundamentals', 'course', 'code', 'coursecode']\n",
            "data has 204 document, size of word vocabular: 255.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/CourseAllocation_NLG/Preprocess.py:134: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "total step:  11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uliGSYIC3sp",
        "colab_type": "code",
        "outputId": "a1a97d97-ef31-4b7c-e77c-9117fc91df2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "!pip install tensorflow==1.10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/e6/a6d371306c23c2b01cd2cb38909673d17ddd388d9e4b3c0f6602bfd972c8/tensorflow-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (58.4MB)\n",
            "\u001b[K     |████████████████████████████████| 58.4MB 50kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.11.0,>=1.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 60.5MB/s \n",
            "\u001b[?25hCollecting numpy<=1.14.5,>=1.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2MB 50.4MB/s \n",
            "\u001b[?25hCollecting setuptools<=39.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 55.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (1.27.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (0.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (0.34.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10) (1.0.0)\n",
            "\u001b[31mERROR: spacy 2.1.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-auth 1.7.2 has requirement setuptools>=40.3.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.60 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.25 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: blis 0.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.0 has requirement numpy>=1.16, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, tensorboard, setuptools, tensorflow\n",
            "  Found existing installation: numpy 1.17.5\n",
            "    Uninstalling numpy-1.17.5:\n",
            "      Successfully uninstalled numpy-1.17.5\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: setuptools 45.2.0\n",
            "    Uninstalling setuptools-45.2.0:\n",
            "      Successfully uninstalled setuptools-45.2.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed numpy-1.14.5 setuptools-39.1.0 tensorboard-1.10.0 tensorflow-1.10.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pkg_resources",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm-6_8_bDT0t",
        "colab_type": "code",
        "outputId": "996b9074-faf4-4300-fdd5-c70ee718b242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python '/content/gdrive/My Drive/CourseAllocation_NLG/train.py'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 307 Learning rate: 0.0010\n",
            "5-step perplexity: 1.103 cost-time: 0.09 s\n",
            "10-step perplexity: 1.085 cost-time: 0.08 s\n",
            "15-step perplexity: 1.086 cost-time: 0.07 s\n",
            "20-step perplexity: 1.084 cost-time: 0.08 s\n",
            "25-step perplexity: 1.080 cost-time: 0.07 s\n",
            "Epoch: 307 Train Perplexity: 1.083\n",
            "Epoch: 308 Learning rate: 0.0010\n",
            "5-step perplexity: 1.054 cost-time: 0.10 s\n",
            "10-step perplexity: 1.074 cost-time: 0.08 s\n",
            "15-step perplexity: 1.072 cost-time: 0.07 s\n",
            "20-step perplexity: 1.073 cost-time: 0.07 s\n",
            "25-step perplexity: 1.077 cost-time: 0.08 s\n",
            "Epoch: 308 Train Perplexity: 1.074\n",
            "Epoch: 309 Learning rate: 0.0010\n",
            "5-step perplexity: 1.105 cost-time: 0.09 s\n",
            "10-step perplexity: 1.086 cost-time: 0.07 s\n",
            "15-step perplexity: 1.089 cost-time: 0.08 s\n",
            "20-step perplexity: 1.089 cost-time: 0.08 s\n",
            "25-step perplexity: 1.084 cost-time: 0.08 s\n",
            "Epoch: 309 Train Perplexity: 1.087\n",
            "Epoch: 310 Learning rate: 0.0010\n",
            "5-step perplexity: 1.060 cost-time: 0.09 s\n",
            "10-step perplexity: 1.080 cost-time: 0.08 s\n",
            "15-step perplexity: 1.076 cost-time: 0.08 s\n",
            "20-step perplexity: 1.077 cost-time: 0.08 s\n",
            "25-step perplexity: 1.078 cost-time: 0.07 s\n",
            "Epoch: 310 Train Perplexity: 1.074\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 311 Learning rate: 0.0010\n",
            "5-step perplexity: 1.101 cost-time: 0.10 s\n",
            "10-step perplexity: 1.079 cost-time: 0.08 s\n",
            "15-step perplexity: 1.081 cost-time: 0.07 s\n",
            "20-step perplexity: 1.079 cost-time: 0.07 s\n",
            "25-step perplexity: 1.078 cost-time: 0.08 s\n",
            "Epoch: 311 Train Perplexity: 1.083\n",
            "Epoch: 312 Learning rate: 0.0010\n",
            "5-step perplexity: 1.065 cost-time: 0.11 s\n",
            "10-step perplexity: 1.084 cost-time: 0.08 s\n",
            "15-step perplexity: 1.078 cost-time: 0.08 s\n",
            "20-step perplexity: 1.078 cost-time: 0.08 s\n",
            "25-step perplexity: 1.078 cost-time: 0.07 s\n",
            "Epoch: 312 Train Perplexity: 1.074\n",
            "Epoch: 313 Learning rate: 0.0010\n",
            "5-step perplexity: 1.098 cost-time: 0.10 s\n",
            "10-step perplexity: 1.079 cost-time: 0.07 s\n",
            "15-step perplexity: 1.088 cost-time: 0.07 s\n",
            "20-step perplexity: 1.085 cost-time: 0.08 s\n",
            "25-step perplexity: 1.083 cost-time: 0.08 s\n",
            "Epoch: 313 Train Perplexity: 1.086\n",
            "Epoch: 314 Learning rate: 0.0010\n",
            "5-step perplexity: 1.057 cost-time: 0.09 s\n",
            "10-step perplexity: 1.076 cost-time: 0.08 s\n",
            "15-step perplexity: 1.072 cost-time: 0.07 s\n",
            "20-step perplexity: 1.072 cost-time: 0.08 s\n",
            "25-step perplexity: 1.074 cost-time: 0.08 s\n",
            "Epoch: 314 Train Perplexity: 1.071\n",
            "Epoch: 315 Learning rate: 0.0010\n",
            "5-step perplexity: 1.087 cost-time: 0.09 s\n",
            "10-step perplexity: 1.074 cost-time: 0.08 s\n",
            "15-step perplexity: 1.079 cost-time: 0.08 s\n",
            "20-step perplexity: 1.078 cost-time: 0.08 s\n",
            "25-step perplexity: 1.075 cost-time: 0.08 s\n",
            "Epoch: 315 Train Perplexity: 1.077\n",
            "Epoch: 316 Learning rate: 0.0010\n",
            "5-step perplexity: 1.056 cost-time: 0.09 s\n",
            "10-step perplexity: 1.075 cost-time: 0.07 s\n",
            "15-step perplexity: 1.072 cost-time: 0.08 s\n",
            "20-step perplexity: 1.072 cost-time: 0.08 s\n",
            "25-step perplexity: 1.075 cost-time: 0.07 s\n",
            "Epoch: 316 Train Perplexity: 1.071\n",
            "Epoch: 317 Learning rate: 0.0010\n",
            "5-step perplexity: 1.096 cost-time: 0.09 s\n",
            "10-step perplexity: 1.080 cost-time: 0.08 s\n",
            "15-step perplexity: 1.083 cost-time: 0.07 s\n",
            "20-step perplexity: 1.082 cost-time: 0.08 s\n",
            "25-step perplexity: 1.078 cost-time: 0.07 s\n",
            "Epoch: 317 Train Perplexity: 1.079\n",
            "Epoch: 318 Learning rate: 0.0010\n",
            "5-step perplexity: 1.051 cost-time: 0.09 s\n",
            "10-step perplexity: 1.074 cost-time: 0.07 s\n",
            "15-step perplexity: 1.068 cost-time: 0.08 s\n",
            "20-step perplexity: 1.070 cost-time: 0.08 s\n",
            "25-step perplexity: 1.073 cost-time: 0.08 s\n",
            "Epoch: 318 Train Perplexity: 1.070\n",
            "Epoch: 319 Learning rate: 0.0010\n",
            "5-step perplexity: 1.097 cost-time: 0.10 s\n",
            "10-step perplexity: 1.081 cost-time: 0.07 s\n",
            "15-step perplexity: 1.084 cost-time: 0.07 s\n",
            "20-step perplexity: 1.081 cost-time: 0.08 s\n",
            "25-step perplexity: 1.078 cost-time: 0.08 s\n",
            "Epoch: 319 Train Perplexity: 1.081\n",
            "Epoch: 320 Learning rate: 0.0010\n",
            "5-step perplexity: 1.051 cost-time: 0.10 s\n",
            "10-step perplexity: 1.074 cost-time: 0.08 s\n",
            "15-step perplexity: 1.072 cost-time: 0.08 s\n",
            "20-step perplexity: 1.070 cost-time: 0.08 s\n",
            "25-step perplexity: 1.072 cost-time: 0.07 s\n",
            "Epoch: 320 Train Perplexity: 1.069\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 321 Learning rate: 0.0010\n",
            "5-step perplexity: 1.093 cost-time: 0.10 s\n",
            "10-step perplexity: 1.077 cost-time: 0.08 s\n",
            "15-step perplexity: 1.080 cost-time: 0.08 s\n",
            "20-step perplexity: 1.079 cost-time: 0.08 s\n",
            "25-step perplexity: 1.076 cost-time: 0.08 s\n",
            "Epoch: 321 Train Perplexity: 1.079\n",
            "Epoch: 322 Learning rate: 0.0010\n",
            "5-step perplexity: 1.061 cost-time: 0.09 s\n",
            "10-step perplexity: 1.081 cost-time: 0.07 s\n",
            "15-step perplexity: 1.075 cost-time: 0.08 s\n",
            "20-step perplexity: 1.073 cost-time: 0.08 s\n",
            "25-step perplexity: 1.075 cost-time: 0.08 s\n",
            "Epoch: 322 Train Perplexity: 1.072\n",
            "Epoch: 323 Learning rate: 0.0010\n",
            "5-step perplexity: 1.098 cost-time: 0.09 s\n",
            "10-step perplexity: 1.081 cost-time: 0.08 s\n",
            "15-step perplexity: 1.085 cost-time: 0.08 s\n",
            "20-step perplexity: 1.082 cost-time: 0.08 s\n",
            "25-step perplexity: 1.080 cost-time: 0.07 s\n",
            "Epoch: 323 Train Perplexity: 1.082\n",
            "Epoch: 324 Learning rate: 0.0010\n",
            "5-step perplexity: 1.052 cost-time: 0.10 s\n",
            "10-step perplexity: 1.075 cost-time: 0.08 s\n",
            "15-step perplexity: 1.070 cost-time: 0.09 s\n",
            "20-step perplexity: 1.070 cost-time: 0.07 s\n",
            "25-step perplexity: 1.071 cost-time: 0.08 s\n",
            "Epoch: 324 Train Perplexity: 1.068\n",
            "Epoch: 325 Learning rate: 0.0010\n",
            "5-step perplexity: 1.098 cost-time: 0.10 s\n",
            "10-step perplexity: 1.074 cost-time: 0.08 s\n",
            "15-step perplexity: 1.078 cost-time: 0.08 s\n",
            "20-step perplexity: 1.076 cost-time: 0.08 s\n",
            "25-step perplexity: 1.074 cost-time: 0.07 s\n",
            "Epoch: 325 Train Perplexity: 1.075\n",
            "Epoch: 326 Learning rate: 0.0010\n",
            "5-step perplexity: 1.057 cost-time: 0.09 s\n",
            "10-step perplexity: 1.074 cost-time: 0.08 s\n",
            "15-step perplexity: 1.069 cost-time: 0.08 s\n",
            "20-step perplexity: 1.069 cost-time: 0.07 s\n",
            "25-step perplexity: 1.072 cost-time: 0.07 s\n",
            "Epoch: 326 Train Perplexity: 1.068\n",
            "Epoch: 327 Learning rate: 0.0010\n",
            "5-step perplexity: 1.091 cost-time: 0.10 s\n",
            "10-step perplexity: 1.072 cost-time: 0.08 s\n",
            "15-step perplexity: 1.079 cost-time: 0.08 s\n",
            "20-step perplexity: 1.077 cost-time: 0.08 s\n",
            "25-step perplexity: 1.076 cost-time: 0.08 s\n",
            "Epoch: 327 Train Perplexity: 1.079\n",
            "Epoch: 328 Learning rate: 0.0010\n",
            "5-step perplexity: 1.061 cost-time: 0.10 s\n",
            "10-step perplexity: 1.077 cost-time: 0.07 s\n",
            "15-step perplexity: 1.072 cost-time: 0.08 s\n",
            "20-step perplexity: 1.072 cost-time: 0.08 s\n",
            "25-step perplexity: 1.073 cost-time: 0.07 s\n",
            "Epoch: 328 Train Perplexity: 1.070\n",
            "Epoch: 329 Learning rate: 0.0010\n",
            "5-step perplexity: 1.089 cost-time: 0.10 s\n",
            "10-step perplexity: 1.073 cost-time: 0.07 s\n",
            "15-step perplexity: 1.075 cost-time: 0.08 s\n",
            "20-step perplexity: 1.075 cost-time: 0.08 s\n",
            "25-step perplexity: 1.071 cost-time: 0.07 s\n",
            "Epoch: 329 Train Perplexity: 1.075\n",
            "Epoch: 330 Learning rate: 0.0010\n",
            "5-step perplexity: 1.056 cost-time: 0.09 s\n",
            "10-step perplexity: 1.072 cost-time: 0.08 s\n",
            "15-step perplexity: 1.069 cost-time: 0.08 s\n",
            "20-step perplexity: 1.069 cost-time: 0.07 s\n",
            "25-step perplexity: 1.071 cost-time: 0.07 s\n",
            "Epoch: 330 Train Perplexity: 1.068\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 331 Learning rate: 0.0010\n",
            "5-step perplexity: 1.085 cost-time: 0.10 s\n",
            "10-step perplexity: 1.073 cost-time: 0.07 s\n",
            "15-step perplexity: 1.077 cost-time: 0.08 s\n",
            "20-step perplexity: 1.076 cost-time: 0.08 s\n",
            "25-step perplexity: 1.073 cost-time: 0.09 s\n",
            "Epoch: 331 Train Perplexity: 1.075\n",
            "Epoch: 332 Learning rate: 0.0010\n",
            "5-step perplexity: 1.048 cost-time: 0.09 s\n",
            "10-step perplexity: 1.069 cost-time: 0.08 s\n",
            "15-step perplexity: 1.065 cost-time: 0.08 s\n",
            "20-step perplexity: 1.066 cost-time: 0.07 s\n",
            "25-step perplexity: 1.069 cost-time: 0.07 s\n",
            "Epoch: 332 Train Perplexity: 1.066\n",
            "Epoch: 333 Learning rate: 0.0010\n",
            "5-step perplexity: 1.089 cost-time: 0.10 s\n",
            "10-step perplexity: 1.068 cost-time: 0.08 s\n",
            "15-step perplexity: 1.073 cost-time: 0.07 s\n",
            "20-step perplexity: 1.072 cost-time: 0.08 s\n",
            "25-step perplexity: 1.070 cost-time: 0.08 s\n",
            "Epoch: 333 Train Perplexity: 1.073\n",
            "Epoch: 334 Learning rate: 0.0010\n",
            "5-step perplexity: 1.054 cost-time: 0.09 s\n",
            "10-step perplexity: 1.072 cost-time: 0.07 s\n",
            "15-step perplexity: 1.067 cost-time: 0.07 s\n",
            "20-step perplexity: 1.066 cost-time: 0.08 s\n",
            "25-step perplexity: 1.070 cost-time: 0.08 s\n",
            "Epoch: 334 Train Perplexity: 1.067\n",
            "Epoch: 335 Learning rate: 0.0010\n",
            "5-step perplexity: 1.087 cost-time: 0.09 s\n",
            "10-step perplexity: 1.069 cost-time: 0.08 s\n",
            "15-step perplexity: 1.076 cost-time: 0.08 s\n",
            "20-step perplexity: 1.073 cost-time: 0.08 s\n",
            "25-step perplexity: 1.071 cost-time: 0.07 s\n",
            "Epoch: 335 Train Perplexity: 1.073\n",
            "Epoch: 336 Learning rate: 0.0010\n",
            "5-step perplexity: 1.053 cost-time: 0.09 s\n",
            "10-step perplexity: 1.071 cost-time: 0.08 s\n",
            "15-step perplexity: 1.068 cost-time: 0.08 s\n",
            "20-step perplexity: 1.067 cost-time: 0.08 s\n",
            "25-step perplexity: 1.069 cost-time: 0.09 s\n",
            "Epoch: 336 Train Perplexity: 1.066\n",
            "Epoch: 337 Learning rate: 0.0010\n",
            "5-step perplexity: 1.087 cost-time: 0.10 s\n",
            "10-step perplexity: 1.072 cost-time: 0.07 s\n",
            "15-step perplexity: 1.073 cost-time: 0.07 s\n",
            "20-step perplexity: 1.073 cost-time: 0.08 s\n",
            "25-step perplexity: 1.070 cost-time: 0.08 s\n",
            "Epoch: 337 Train Perplexity: 1.073\n",
            "Epoch: 338 Learning rate: 0.0010\n",
            "5-step perplexity: 1.048 cost-time: 0.10 s\n",
            "10-step perplexity: 1.068 cost-time: 0.07 s\n",
            "15-step perplexity: 1.067 cost-time: 0.07 s\n",
            "20-step perplexity: 1.066 cost-time: 0.08 s\n",
            "25-step perplexity: 1.070 cost-time: 0.08 s\n",
            "Epoch: 338 Train Perplexity: 1.067\n",
            "Epoch: 339 Learning rate: 0.0010\n",
            "5-step perplexity: 1.089 cost-time: 0.09 s\n",
            "10-step perplexity: 1.077 cost-time: 0.08 s\n",
            "15-step perplexity: 1.077 cost-time: 0.08 s\n",
            "20-step perplexity: 1.077 cost-time: 0.08 s\n",
            "25-step perplexity: 1.072 cost-time: 0.08 s\n",
            "Epoch: 339 Train Perplexity: 1.074\n",
            "Epoch: 340 Learning rate: 0.0010\n",
            "5-step perplexity: 1.049 cost-time: 0.10 s\n",
            "10-step perplexity: 1.068 cost-time: 0.08 s\n",
            "15-step perplexity: 1.064 cost-time: 0.08 s\n",
            "20-step perplexity: 1.066 cost-time: 0.08 s\n",
            "25-step perplexity: 1.066 cost-time: 0.08 s\n",
            "Epoch: 340 Train Perplexity: 1.063\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 341 Learning rate: 0.0010\n",
            "5-step perplexity: 1.082 cost-time: 0.09 s\n",
            "10-step perplexity: 1.067 cost-time: 0.08 s\n",
            "15-step perplexity: 1.070 cost-time: 0.08 s\n",
            "20-step perplexity: 1.070 cost-time: 0.08 s\n",
            "25-step perplexity: 1.070 cost-time: 0.08 s\n",
            "Epoch: 341 Train Perplexity: 1.072\n",
            "Epoch: 342 Learning rate: 0.0010\n",
            "5-step perplexity: 1.048 cost-time: 0.10 s\n",
            "10-step perplexity: 1.066 cost-time: 0.08 s\n",
            "15-step perplexity: 1.062 cost-time: 0.08 s\n",
            "20-step perplexity: 1.064 cost-time: 0.08 s\n",
            "25-step perplexity: 1.066 cost-time: 0.08 s\n",
            "Epoch: 342 Train Perplexity: 1.064\n",
            "Epoch: 343 Learning rate: 0.0010\n",
            "5-step perplexity: 1.082 cost-time: 0.09 s\n",
            "10-step perplexity: 1.066 cost-time: 0.08 s\n",
            "15-step perplexity: 1.071 cost-time: 0.08 s\n",
            "20-step perplexity: 1.071 cost-time: 0.08 s\n",
            "25-step perplexity: 1.067 cost-time: 0.07 s\n",
            "Epoch: 343 Train Perplexity: 1.070\n",
            "Epoch: 344 Learning rate: 0.0010\n",
            "5-step perplexity: 1.046 cost-time: 0.09 s\n",
            "10-step perplexity: 1.062 cost-time: 0.07 s\n",
            "15-step perplexity: 1.060 cost-time: 0.07 s\n",
            "20-step perplexity: 1.063 cost-time: 0.08 s\n",
            "25-step perplexity: 1.066 cost-time: 0.08 s\n",
            "Epoch: 344 Train Perplexity: 1.063\n",
            "Epoch: 345 Learning rate: 0.0010\n",
            "5-step perplexity: 1.083 cost-time: 0.10 s\n",
            "10-step perplexity: 1.068 cost-time: 0.07 s\n",
            "15-step perplexity: 1.072 cost-time: 0.08 s\n",
            "20-step perplexity: 1.069 cost-time: 0.08 s\n",
            "25-step perplexity: 1.065 cost-time: 0.08 s\n",
            "Epoch: 345 Train Perplexity: 1.068\n",
            "Epoch: 346 Learning rate: 0.0010\n",
            "5-step perplexity: 1.048 cost-time: 0.09 s\n",
            "10-step perplexity: 1.069 cost-time: 0.08 s\n",
            "15-step perplexity: 1.068 cost-time: 0.07 s\n",
            "20-step perplexity: 1.067 cost-time: 0.08 s\n",
            "25-step perplexity: 1.067 cost-time: 0.07 s\n",
            "Epoch: 346 Train Perplexity: 1.065\n",
            "Epoch: 347 Learning rate: 0.0010\n",
            "5-step perplexity: 1.082 cost-time: 0.10 s\n",
            "10-step perplexity: 1.068 cost-time: 0.08 s\n",
            "15-step perplexity: 1.068 cost-time: 0.08 s\n",
            "20-step perplexity: 1.066 cost-time: 0.08 s\n",
            "25-step perplexity: 1.063 cost-time: 0.08 s\n",
            "Epoch: 347 Train Perplexity: 1.066\n",
            "Epoch: 348 Learning rate: 0.0010\n",
            "5-step perplexity: 1.052 cost-time: 0.10 s\n",
            "10-step perplexity: 1.064 cost-time: 0.07 s\n",
            "15-step perplexity: 1.059 cost-time: 0.07 s\n",
            "20-step perplexity: 1.059 cost-time: 0.08 s\n",
            "25-step perplexity: 1.063 cost-time: 0.08 s\n",
            "Epoch: 348 Train Perplexity: 1.060\n",
            "Epoch: 349 Learning rate: 0.0010\n",
            "5-step perplexity: 1.081 cost-time: 0.09 s\n",
            "10-step perplexity: 1.066 cost-time: 0.07 s\n",
            "15-step perplexity: 1.069 cost-time: 0.07 s\n",
            "20-step perplexity: 1.064 cost-time: 0.08 s\n",
            "25-step perplexity: 1.063 cost-time: 0.07 s\n",
            "Epoch: 349 Train Perplexity: 1.066\n",
            "Epoch: 350 Learning rate: 0.0010\n",
            "5-step perplexity: 1.045 cost-time: 0.09 s\n",
            "10-step perplexity: 1.066 cost-time: 0.08 s\n",
            "15-step perplexity: 1.068 cost-time: 0.08 s\n",
            "20-step perplexity: 1.066 cost-time: 0.08 s\n",
            "25-step perplexity: 1.067 cost-time: 0.07 s\n",
            "Epoch: 350 Train Perplexity: 1.063\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 351 Learning rate: 0.0010\n",
            "5-step perplexity: 1.084 cost-time: 0.11 s\n",
            "10-step perplexity: 1.070 cost-time: 0.09 s\n",
            "15-step perplexity: 1.072 cost-time: 0.08 s\n",
            "20-step perplexity: 1.069 cost-time: 0.09 s\n",
            "25-step perplexity: 1.066 cost-time: 0.08 s\n",
            "Epoch: 351 Train Perplexity: 1.069\n",
            "Epoch: 352 Learning rate: 0.0010\n",
            "5-step perplexity: 1.046 cost-time: 0.09 s\n",
            "10-step perplexity: 1.058 cost-time: 0.07 s\n",
            "15-step perplexity: 1.056 cost-time: 0.08 s\n",
            "20-step perplexity: 1.059 cost-time: 0.07 s\n",
            "25-step perplexity: 1.062 cost-time: 0.07 s\n",
            "Epoch: 352 Train Perplexity: 1.058\n",
            "Epoch: 353 Learning rate: 0.0010\n",
            "5-step perplexity: 1.082 cost-time: 0.09 s\n",
            "10-step perplexity: 1.066 cost-time: 0.08 s\n",
            "15-step perplexity: 1.068 cost-time: 0.08 s\n",
            "20-step perplexity: 1.068 cost-time: 0.07 s\n",
            "25-step perplexity: 1.065 cost-time: 0.07 s\n",
            "Epoch: 353 Train Perplexity: 1.067\n",
            "Epoch: 354 Learning rate: 0.0010\n",
            "5-step perplexity: 1.050 cost-time: 0.10 s\n",
            "10-step perplexity: 1.061 cost-time: 0.07 s\n",
            "15-step perplexity: 1.058 cost-time: 0.08 s\n",
            "20-step perplexity: 1.058 cost-time: 0.08 s\n",
            "25-step perplexity: 1.061 cost-time: 0.08 s\n",
            "Epoch: 354 Train Perplexity: 1.059\n",
            "Epoch: 355 Learning rate: 0.0010\n",
            "5-step perplexity: 1.072 cost-time: 0.09 s\n",
            "10-step perplexity: 1.059 cost-time: 0.08 s\n",
            "15-step perplexity: 1.064 cost-time: 0.08 s\n",
            "20-step perplexity: 1.064 cost-time: 0.07 s\n",
            "25-step perplexity: 1.061 cost-time: 0.08 s\n",
            "Epoch: 355 Train Perplexity: 1.066\n",
            "Epoch: 356 Learning rate: 0.0010\n",
            "5-step perplexity: 1.041 cost-time: 0.10 s\n",
            "10-step perplexity: 1.063 cost-time: 0.08 s\n",
            "15-step perplexity: 1.059 cost-time: 0.08 s\n",
            "20-step perplexity: 1.060 cost-time: 0.07 s\n",
            "25-step perplexity: 1.063 cost-time: 0.08 s\n",
            "Epoch: 356 Train Perplexity: 1.060\n",
            "Epoch: 357 Learning rate: 0.0010\n",
            "5-step perplexity: 1.082 cost-time: 0.09 s\n",
            "10-step perplexity: 1.063 cost-time: 0.08 s\n",
            "15-step perplexity: 1.064 cost-time: 0.08 s\n",
            "20-step perplexity: 1.064 cost-time: 0.08 s\n",
            "25-step perplexity: 1.061 cost-time: 0.08 s\n",
            "Epoch: 357 Train Perplexity: 1.062\n",
            "Epoch: 358 Learning rate: 0.0010\n",
            "5-step perplexity: 1.048 cost-time: 0.09 s\n",
            "10-step perplexity: 1.059 cost-time: 0.07 s\n",
            "15-step perplexity: 1.058 cost-time: 0.08 s\n",
            "20-step perplexity: 1.058 cost-time: 0.08 s\n",
            "25-step perplexity: 1.058 cost-time: 0.07 s\n",
            "Epoch: 358 Train Perplexity: 1.056\n",
            "Epoch: 359 Learning rate: 0.0010\n",
            "5-step perplexity: 1.078 cost-time: 0.11 s\n",
            "10-step perplexity: 1.065 cost-time: 0.08 s\n",
            "15-step perplexity: 1.068 cost-time: 0.08 s\n",
            "20-step perplexity: 1.068 cost-time: 0.08 s\n",
            "25-step perplexity: 1.063 cost-time: 0.07 s\n",
            "Epoch: 359 Train Perplexity: 1.065\n",
            "Epoch: 360 Learning rate: 0.0010\n",
            "5-step perplexity: 1.043 cost-time: 0.10 s\n",
            "10-step perplexity: 1.061 cost-time: 0.08 s\n",
            "15-step perplexity: 1.057 cost-time: 0.07 s\n",
            "20-step perplexity: 1.057 cost-time: 0.08 s\n",
            "25-step perplexity: 1.060 cost-time: 0.07 s\n",
            "Epoch: 360 Train Perplexity: 1.058\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 361 Learning rate: 0.0010\n",
            "5-step perplexity: 1.078 cost-time: 0.09 s\n",
            "10-step perplexity: 1.063 cost-time: 0.08 s\n",
            "15-step perplexity: 1.065 cost-time: 0.08 s\n",
            "20-step perplexity: 1.063 cost-time: 0.08 s\n",
            "25-step perplexity: 1.062 cost-time: 0.08 s\n",
            "Epoch: 361 Train Perplexity: 1.063\n",
            "Epoch: 362 Learning rate: 0.0010\n",
            "5-step perplexity: 1.055 cost-time: 0.09 s\n",
            "10-step perplexity: 1.063 cost-time: 0.07 s\n",
            "15-step perplexity: 1.060 cost-time: 0.07 s\n",
            "20-step perplexity: 1.059 cost-time: 0.08 s\n",
            "25-step perplexity: 1.061 cost-time: 0.08 s\n",
            "Epoch: 362 Train Perplexity: 1.059\n",
            "Epoch: 363 Learning rate: 0.0010\n",
            "5-step perplexity: 1.086 cost-time: 0.09 s\n",
            "10-step perplexity: 1.070 cost-time: 0.08 s\n",
            "15-step perplexity: 1.068 cost-time: 0.07 s\n",
            "20-step perplexity: 1.066 cost-time: 0.08 s\n",
            "25-step perplexity: 1.063 cost-time: 0.07 s\n",
            "Epoch: 363 Train Perplexity: 1.064\n",
            "Epoch: 364 Learning rate: 0.0010\n",
            "5-step perplexity: 1.046 cost-time: 0.09 s\n",
            "10-step perplexity: 1.063 cost-time: 0.07 s\n",
            "15-step perplexity: 1.062 cost-time: 0.07 s\n",
            "20-step perplexity: 1.060 cost-time: 0.08 s\n",
            "25-step perplexity: 1.062 cost-time: 0.07 s\n",
            "Epoch: 364 Train Perplexity: 1.058\n",
            "Epoch: 365 Learning rate: 0.0010\n",
            "5-step perplexity: 1.073 cost-time: 0.09 s\n",
            "10-step perplexity: 1.061 cost-time: 0.07 s\n",
            "15-step perplexity: 1.061 cost-time: 0.07 s\n",
            "20-step perplexity: 1.060 cost-time: 0.07 s\n",
            "25-step perplexity: 1.058 cost-time: 0.07 s\n",
            "Epoch: 365 Train Perplexity: 1.062\n",
            "Epoch: 366 Learning rate: 0.0010\n",
            "5-step perplexity: 1.044 cost-time: 0.09 s\n",
            "10-step perplexity: 1.059 cost-time: 0.07 s\n",
            "15-step perplexity: 1.057 cost-time: 0.07 s\n",
            "20-step perplexity: 1.057 cost-time: 0.08 s\n",
            "25-step perplexity: 1.060 cost-time: 0.07 s\n",
            "Epoch: 366 Train Perplexity: 1.057\n",
            "Epoch: 367 Learning rate: 0.0010\n",
            "5-step perplexity: 1.076 cost-time: 0.09 s\n",
            "10-step perplexity: 1.066 cost-time: 0.07 s\n",
            "15-step perplexity: 1.068 cost-time: 0.07 s\n",
            "20-step perplexity: 1.066 cost-time: 0.08 s\n",
            "25-step perplexity: 1.063 cost-time: 0.07 s\n",
            "Epoch: 367 Train Perplexity: 1.064\n",
            "Epoch: 368 Learning rate: 0.0010\n",
            "5-step perplexity: 1.047 cost-time: 0.10 s\n",
            "10-step perplexity: 1.059 cost-time: 0.08 s\n",
            "15-step perplexity: 1.056 cost-time: 0.08 s\n",
            "20-step perplexity: 1.054 cost-time: 0.08 s\n",
            "25-step perplexity: 1.056 cost-time: 0.07 s\n",
            "Epoch: 368 Train Perplexity: 1.054\n",
            "Epoch: 369 Learning rate: 0.0010\n",
            "5-step perplexity: 1.073 cost-time: 0.09 s\n",
            "10-step perplexity: 1.058 cost-time: 0.07 s\n",
            "15-step perplexity: 1.057 cost-time: 0.07 s\n",
            "20-step perplexity: 1.056 cost-time: 0.08 s\n",
            "25-step perplexity: 1.055 cost-time: 0.07 s\n",
            "Epoch: 369 Train Perplexity: 1.057\n",
            "Epoch: 370 Learning rate: 0.0010\n",
            "5-step perplexity: 1.040 cost-time: 0.09 s\n",
            "10-step perplexity: 1.054 cost-time: 0.08 s\n",
            "15-step perplexity: 1.051 cost-time: 0.08 s\n",
            "20-step perplexity: 1.051 cost-time: 0.08 s\n",
            "25-step perplexity: 1.055 cost-time: 0.07 s\n",
            "Epoch: 370 Train Perplexity: 1.054\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 371 Learning rate: 0.0010\n",
            "5-step perplexity: 1.069 cost-time: 0.09 s\n",
            "10-step perplexity: 1.059 cost-time: 0.08 s\n",
            "15-step perplexity: 1.064 cost-time: 0.08 s\n",
            "20-step perplexity: 1.065 cost-time: 0.08 s\n",
            "25-step perplexity: 1.062 cost-time: 0.08 s\n",
            "Epoch: 371 Train Perplexity: 1.064\n",
            "Epoch: 372 Learning rate: 0.0010\n",
            "5-step perplexity: 1.048 cost-time: 0.10 s\n",
            "10-step perplexity: 1.058 cost-time: 0.08 s\n",
            "15-step perplexity: 1.055 cost-time: 0.08 s\n",
            "20-step perplexity: 1.056 cost-time: 0.08 s\n",
            "25-step perplexity: 1.058 cost-time: 0.08 s\n",
            "Epoch: 372 Train Perplexity: 1.055\n",
            "Epoch: 373 Learning rate: 0.0010\n",
            "5-step perplexity: 1.073 cost-time: 0.09 s\n",
            "10-step perplexity: 1.060 cost-time: 0.08 s\n",
            "15-step perplexity: 1.063 cost-time: 0.07 s\n",
            "20-step perplexity: 1.063 cost-time: 0.08 s\n",
            "25-step perplexity: 1.059 cost-time: 0.07 s\n",
            "Epoch: 373 Train Perplexity: 1.062\n",
            "Epoch: 374 Learning rate: 0.0010\n",
            "5-step perplexity: 1.035 cost-time: 0.09 s\n",
            "10-step perplexity: 1.053 cost-time: 0.07 s\n",
            "15-step perplexity: 1.054 cost-time: 0.08 s\n",
            "20-step perplexity: 1.055 cost-time: 0.08 s\n",
            "25-step perplexity: 1.057 cost-time: 0.07 s\n",
            "Epoch: 374 Train Perplexity: 1.054\n",
            "Epoch: 375 Learning rate: 0.0010\n",
            "5-step perplexity: 1.071 cost-time: 0.10 s\n",
            "10-step perplexity: 1.058 cost-time: 0.08 s\n",
            "15-step perplexity: 1.061 cost-time: 0.08 s\n",
            "20-step perplexity: 1.060 cost-time: 0.08 s\n",
            "25-step perplexity: 1.058 cost-time: 0.07 s\n",
            "Epoch: 375 Train Perplexity: 1.060\n",
            "Epoch: 376 Learning rate: 0.0010\n",
            "5-step perplexity: 1.038 cost-time: 0.09 s\n",
            "10-step perplexity: 1.055 cost-time: 0.08 s\n",
            "15-step perplexity: 1.053 cost-time: 0.08 s\n",
            "20-step perplexity: 1.051 cost-time: 0.08 s\n",
            "25-step perplexity: 1.054 cost-time: 0.07 s\n",
            "Epoch: 376 Train Perplexity: 1.051\n",
            "Epoch: 377 Learning rate: 0.0010\n",
            "5-step perplexity: 1.078 cost-time: 0.10 s\n",
            "10-step perplexity: 1.063 cost-time: 0.08 s\n",
            "15-step perplexity: 1.066 cost-time: 0.08 s\n",
            "20-step perplexity: 1.062 cost-time: 0.08 s\n",
            "25-step perplexity: 1.060 cost-time: 0.08 s\n",
            "Epoch: 377 Train Perplexity: 1.062\n",
            "Epoch: 378 Learning rate: 0.0010\n",
            "5-step perplexity: 1.042 cost-time: 0.09 s\n",
            "10-step perplexity: 1.055 cost-time: 0.08 s\n",
            "15-step perplexity: 1.053 cost-time: 0.07 s\n",
            "20-step perplexity: 1.053 cost-time: 0.07 s\n",
            "25-step perplexity: 1.055 cost-time: 0.08 s\n",
            "Epoch: 378 Train Perplexity: 1.053\n",
            "Epoch: 379 Learning rate: 0.0010\n",
            "5-step perplexity: 1.071 cost-time: 0.10 s\n",
            "10-step perplexity: 1.057 cost-time: 0.08 s\n",
            "15-step perplexity: 1.059 cost-time: 0.08 s\n",
            "20-step perplexity: 1.058 cost-time: 0.07 s\n",
            "25-step perplexity: 1.057 cost-time: 0.07 s\n",
            "Epoch: 379 Train Perplexity: 1.058\n",
            "Epoch: 380 Learning rate: 0.0010\n",
            "5-step perplexity: 1.044 cost-time: 0.09 s\n",
            "10-step perplexity: 1.058 cost-time: 0.07 s\n",
            "15-step perplexity: 1.053 cost-time: 0.08 s\n",
            "20-step perplexity: 1.054 cost-time: 0.08 s\n",
            "25-step perplexity: 1.057 cost-time: 0.08 s\n",
            "Epoch: 380 Train Perplexity: 1.054\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 381 Learning rate: 0.0010\n",
            "5-step perplexity: 1.071 cost-time: 0.09 s\n",
            "10-step perplexity: 1.062 cost-time: 0.08 s\n",
            "15-step perplexity: 1.065 cost-time: 0.08 s\n",
            "20-step perplexity: 1.062 cost-time: 0.08 s\n",
            "25-step perplexity: 1.060 cost-time: 0.07 s\n",
            "Epoch: 381 Train Perplexity: 1.061\n",
            "Epoch: 382 Learning rate: 0.0010\n",
            "5-step perplexity: 1.041 cost-time: 0.09 s\n",
            "10-step perplexity: 1.058 cost-time: 0.08 s\n",
            "15-step perplexity: 1.056 cost-time: 0.08 s\n",
            "20-step perplexity: 1.057 cost-time: 0.08 s\n",
            "25-step perplexity: 1.060 cost-time: 0.08 s\n",
            "Epoch: 382 Train Perplexity: 1.058\n",
            "Epoch: 383 Learning rate: 0.0010\n",
            "5-step perplexity: 1.080 cost-time: 0.09 s\n",
            "10-step perplexity: 1.064 cost-time: 0.07 s\n",
            "15-step perplexity: 1.061 cost-time: 0.07 s\n",
            "20-step perplexity: 1.059 cost-time: 0.08 s\n",
            "25-step perplexity: 1.056 cost-time: 0.09 s\n",
            "Epoch: 383 Train Perplexity: 1.058\n",
            "Epoch: 384 Learning rate: 0.0010\n",
            "5-step perplexity: 1.037 cost-time: 0.10 s\n",
            "10-step perplexity: 1.053 cost-time: 0.08 s\n",
            "15-step perplexity: 1.054 cost-time: 0.08 s\n",
            "20-step perplexity: 1.057 cost-time: 0.08 s\n",
            "25-step perplexity: 1.056 cost-time: 0.08 s\n",
            "Epoch: 384 Train Perplexity: 1.054\n",
            "Epoch: 385 Learning rate: 0.0010\n",
            "5-step perplexity: 1.065 cost-time: 0.10 s\n",
            "10-step perplexity: 1.055 cost-time: 0.08 s\n",
            "15-step perplexity: 1.058 cost-time: 0.08 s\n",
            "20-step perplexity: 1.058 cost-time: 0.08 s\n",
            "25-step perplexity: 1.055 cost-time: 0.08 s\n",
            "Epoch: 385 Train Perplexity: 1.055\n",
            "Epoch: 386 Learning rate: 0.0010\n",
            "5-step perplexity: 1.043 cost-time: 0.10 s\n",
            "10-step perplexity: 1.052 cost-time: 0.09 s\n",
            "15-step perplexity: 1.051 cost-time: 0.08 s\n",
            "20-step perplexity: 1.052 cost-time: 0.07 s\n",
            "25-step perplexity: 1.054 cost-time: 0.08 s\n",
            "Epoch: 386 Train Perplexity: 1.052\n",
            "Epoch: 387 Learning rate: 0.0010\n",
            "5-step perplexity: 1.071 cost-time: 0.10 s\n",
            "10-step perplexity: 1.055 cost-time: 0.08 s\n",
            "15-step perplexity: 1.058 cost-time: 0.08 s\n",
            "20-step perplexity: 1.058 cost-time: 0.08 s\n",
            "25-step perplexity: 1.055 cost-time: 0.09 s\n",
            "Epoch: 387 Train Perplexity: 1.057\n",
            "Epoch: 388 Learning rate: 0.0010\n",
            "5-step perplexity: 1.039 cost-time: 0.10 s\n",
            "10-step perplexity: 1.057 cost-time: 0.07 s\n",
            "15-step perplexity: 1.053 cost-time: 0.08 s\n",
            "20-step perplexity: 1.054 cost-time: 0.08 s\n",
            "25-step perplexity: 1.054 cost-time: 0.07 s\n",
            "Epoch: 388 Train Perplexity: 1.051\n",
            "Epoch: 389 Learning rate: 0.0010\n",
            "5-step perplexity: 1.074 cost-time: 0.10 s\n",
            "10-step perplexity: 1.060 cost-time: 0.08 s\n",
            "15-step perplexity: 1.061 cost-time: 0.08 s\n",
            "20-step perplexity: 1.058 cost-time: 0.07 s\n",
            "25-step perplexity: 1.054 cost-time: 0.08 s\n",
            "Epoch: 389 Train Perplexity: 1.056\n",
            "Epoch: 390 Learning rate: 0.0010\n",
            "5-step perplexity: 1.043 cost-time: 0.09 s\n",
            "10-step perplexity: 1.059 cost-time: 0.08 s\n",
            "15-step perplexity: 1.055 cost-time: 0.08 s\n",
            "20-step perplexity: 1.054 cost-time: 0.08 s\n",
            "25-step perplexity: 1.054 cost-time: 0.07 s\n",
            "Epoch: 390 Train Perplexity: 1.051\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 391 Learning rate: 0.0010\n",
            "5-step perplexity: 1.067 cost-time: 0.10 s\n",
            "10-step perplexity: 1.053 cost-time: 0.08 s\n",
            "15-step perplexity: 1.059 cost-time: 0.07 s\n",
            "20-step perplexity: 1.056 cost-time: 0.08 s\n",
            "25-step perplexity: 1.055 cost-time: 0.07 s\n",
            "Epoch: 391 Train Perplexity: 1.058\n",
            "Epoch: 392 Learning rate: 0.0010\n",
            "5-step perplexity: 1.041 cost-time: 0.10 s\n",
            "10-step perplexity: 1.054 cost-time: 0.08 s\n",
            "15-step perplexity: 1.051 cost-time: 0.07 s\n",
            "20-step perplexity: 1.051 cost-time: 0.08 s\n",
            "25-step perplexity: 1.052 cost-time: 0.08 s\n",
            "Epoch: 392 Train Perplexity: 1.049\n",
            "Epoch: 393 Learning rate: 0.0010\n",
            "5-step perplexity: 1.064 cost-time: 0.09 s\n",
            "10-step perplexity: 1.053 cost-time: 0.08 s\n",
            "15-step perplexity: 1.055 cost-time: 0.08 s\n",
            "20-step perplexity: 1.053 cost-time: 0.08 s\n",
            "25-step perplexity: 1.053 cost-time: 0.07 s\n",
            "Epoch: 393 Train Perplexity: 1.056\n",
            "Epoch: 394 Learning rate: 0.0010\n",
            "5-step perplexity: 1.040 cost-time: 0.10 s\n",
            "10-step perplexity: 1.057 cost-time: 0.08 s\n",
            "15-step perplexity: 1.052 cost-time: 0.08 s\n",
            "20-step perplexity: 1.051 cost-time: 0.07 s\n",
            "25-step perplexity: 1.051 cost-time: 0.08 s\n",
            "Epoch: 394 Train Perplexity: 1.049\n",
            "Epoch: 395 Learning rate: 0.0010\n",
            "5-step perplexity: 1.071 cost-time: 0.10 s\n",
            "10-step perplexity: 1.057 cost-time: 0.08 s\n",
            "15-step perplexity: 1.060 cost-time: 0.07 s\n",
            "20-step perplexity: 1.058 cost-time: 0.07 s\n",
            "25-step perplexity: 1.055 cost-time: 0.07 s\n",
            "Epoch: 395 Train Perplexity: 1.058\n",
            "Epoch: 396 Learning rate: 0.0010\n",
            "5-step perplexity: 1.036 cost-time: 0.09 s\n",
            "10-step perplexity: 1.049 cost-time: 0.08 s\n",
            "15-step perplexity: 1.048 cost-time: 0.08 s\n",
            "20-step perplexity: 1.050 cost-time: 0.09 s\n",
            "25-step perplexity: 1.051 cost-time: 0.07 s\n",
            "Epoch: 396 Train Perplexity: 1.050\n",
            "Epoch: 397 Learning rate: 0.0010\n",
            "5-step perplexity: 1.065 cost-time: 0.10 s\n",
            "10-step perplexity: 1.053 cost-time: 0.07 s\n",
            "15-step perplexity: 1.059 cost-time: 0.08 s\n",
            "20-step perplexity: 1.057 cost-time: 0.08 s\n",
            "25-step perplexity: 1.054 cost-time: 0.08 s\n",
            "Epoch: 397 Train Perplexity: 1.056\n",
            "Epoch: 398 Learning rate: 0.0010\n",
            "5-step perplexity: 1.043 cost-time: 0.10 s\n",
            "10-step perplexity: 1.054 cost-time: 0.08 s\n",
            "15-step perplexity: 1.049 cost-time: 0.08 s\n",
            "20-step perplexity: 1.049 cost-time: 0.07 s\n",
            "25-step perplexity: 1.052 cost-time: 0.07 s\n",
            "Epoch: 398 Train Perplexity: 1.049\n",
            "Epoch: 399 Learning rate: 0.0010\n",
            "5-step perplexity: 1.061 cost-time: 0.10 s\n",
            "10-step perplexity: 1.054 cost-time: 0.08 s\n",
            "15-step perplexity: 1.052 cost-time: 0.07 s\n",
            "20-step perplexity: 1.052 cost-time: 0.08 s\n",
            "25-step perplexity: 1.051 cost-time: 0.08 s\n",
            "Epoch: 399 Train Perplexity: 1.053\n",
            "Epoch: 400 Learning rate: 0.0010\n",
            "5-step perplexity: 1.041 cost-time: 0.10 s\n",
            "10-step perplexity: 1.050 cost-time: 0.08 s\n",
            "15-step perplexity: 1.048 cost-time: 0.08 s\n",
            "20-step perplexity: 1.047 cost-time: 0.07 s\n",
            "25-step perplexity: 1.049 cost-time: 0.07 s\n",
            "Epoch: 400 Train Perplexity: 1.046\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 401 Learning rate: 0.0010\n",
            "5-step perplexity: 1.062 cost-time: 0.09 s\n",
            "10-step perplexity: 1.054 cost-time: 0.07 s\n",
            "15-step perplexity: 1.054 cost-time: 0.07 s\n",
            "20-step perplexity: 1.051 cost-time: 0.08 s\n",
            "25-step perplexity: 1.047 cost-time: 0.08 s\n",
            "Epoch: 401 Train Perplexity: 1.051\n",
            "Epoch: 402 Learning rate: 0.0010\n",
            "5-step perplexity: 1.037 cost-time: 0.10 s\n",
            "10-step perplexity: 1.054 cost-time: 0.08 s\n",
            "15-step perplexity: 1.050 cost-time: 0.08 s\n",
            "20-step perplexity: 1.051 cost-time: 0.08 s\n",
            "25-step perplexity: 1.053 cost-time: 0.07 s\n",
            "Epoch: 402 Train Perplexity: 1.050\n",
            "Epoch: 403 Learning rate: 0.0010\n",
            "5-step perplexity: 1.064 cost-time: 0.09 s\n",
            "10-step perplexity: 1.054 cost-time: 0.08 s\n",
            "15-step perplexity: 1.057 cost-time: 0.08 s\n",
            "20-step perplexity: 1.054 cost-time: 0.08 s\n",
            "25-step perplexity: 1.051 cost-time: 0.07 s\n",
            "Epoch: 403 Train Perplexity: 1.053\n",
            "Epoch: 404 Learning rate: 0.0010\n",
            "5-step perplexity: 1.040 cost-time: 0.09 s\n",
            "10-step perplexity: 1.051 cost-time: 0.07 s\n",
            "15-step perplexity: 1.047 cost-time: 0.07 s\n",
            "20-step perplexity: 1.048 cost-time: 0.07 s\n",
            "25-step perplexity: 1.050 cost-time: 0.07 s\n",
            "Epoch: 404 Train Perplexity: 1.048\n",
            "Epoch: 405 Learning rate: 0.0010\n",
            "5-step perplexity: 1.061 cost-time: 0.09 s\n",
            "10-step perplexity: 1.051 cost-time: 0.07 s\n",
            "15-step perplexity: 1.055 cost-time: 0.07 s\n",
            "20-step perplexity: 1.053 cost-time: 0.08 s\n",
            "25-step perplexity: 1.052 cost-time: 0.07 s\n",
            "Epoch: 405 Train Perplexity: 1.054\n",
            "Epoch: 406 Learning rate: 0.0010\n",
            "5-step perplexity: 1.036 cost-time: 0.09 s\n",
            "10-step perplexity: 1.051 cost-time: 0.07 s\n",
            "15-step perplexity: 1.050 cost-time: 0.08 s\n",
            "20-step perplexity: 1.049 cost-time: 0.08 s\n",
            "25-step perplexity: 1.049 cost-time: 0.07 s\n",
            "Epoch: 406 Train Perplexity: 1.047\n",
            "Epoch: 407 Learning rate: 0.0010\n",
            "5-step perplexity: 1.061 cost-time: 0.10 s\n",
            "10-step perplexity: 1.051 cost-time: 0.08 s\n",
            "15-step perplexity: 1.054 cost-time: 0.07 s\n",
            "20-step perplexity: 1.053 cost-time: 0.09 s\n",
            "25-step perplexity: 1.052 cost-time: 0.07 s\n",
            "Epoch: 407 Train Perplexity: 1.053\n",
            "Epoch: 408 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.09 s\n",
            "10-step perplexity: 1.045 cost-time: 0.08 s\n",
            "15-step perplexity: 1.048 cost-time: 0.08 s\n",
            "20-step perplexity: 1.047 cost-time: 0.08 s\n",
            "25-step perplexity: 1.049 cost-time: 0.08 s\n",
            "Epoch: 408 Train Perplexity: 1.046\n",
            "Epoch: 409 Learning rate: 0.0010\n",
            "5-step perplexity: 1.067 cost-time: 0.09 s\n",
            "10-step perplexity: 1.053 cost-time: 0.08 s\n",
            "15-step perplexity: 1.055 cost-time: 0.09 s\n",
            "20-step perplexity: 1.053 cost-time: 0.08 s\n",
            "25-step perplexity: 1.052 cost-time: 0.07 s\n",
            "Epoch: 409 Train Perplexity: 1.054\n",
            "Epoch: 410 Learning rate: 0.0010\n",
            "5-step perplexity: 1.038 cost-time: 0.09 s\n",
            "10-step perplexity: 1.051 cost-time: 0.08 s\n",
            "15-step perplexity: 1.048 cost-time: 0.08 s\n",
            "20-step perplexity: 1.048 cost-time: 0.07 s\n",
            "25-step perplexity: 1.050 cost-time: 0.07 s\n",
            "Epoch: 410 Train Perplexity: 1.048\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 411 Learning rate: 0.0010\n",
            "5-step perplexity: 1.062 cost-time: 0.10 s\n",
            "10-step perplexity: 1.049 cost-time: 0.09 s\n",
            "15-step perplexity: 1.051 cost-time: 0.07 s\n",
            "20-step perplexity: 1.049 cost-time: 0.08 s\n",
            "25-step perplexity: 1.048 cost-time: 0.07 s\n",
            "Epoch: 411 Train Perplexity: 1.050\n",
            "Epoch: 412 Learning rate: 0.0010\n",
            "5-step perplexity: 1.035 cost-time: 0.09 s\n",
            "10-step perplexity: 1.049 cost-time: 0.07 s\n",
            "15-step perplexity: 1.047 cost-time: 0.08 s\n",
            "20-step perplexity: 1.046 cost-time: 0.08 s\n",
            "25-step perplexity: 1.047 cost-time: 0.07 s\n",
            "Epoch: 412 Train Perplexity: 1.046\n",
            "Epoch: 413 Learning rate: 0.0010\n",
            "5-step perplexity: 1.054 cost-time: 0.10 s\n",
            "10-step perplexity: 1.046 cost-time: 0.07 s\n",
            "15-step perplexity: 1.050 cost-time: 0.07 s\n",
            "20-step perplexity: 1.048 cost-time: 0.08 s\n",
            "25-step perplexity: 1.047 cost-time: 0.08 s\n",
            "Epoch: 413 Train Perplexity: 1.050\n",
            "Epoch: 414 Learning rate: 0.0010\n",
            "5-step perplexity: 1.031 cost-time: 0.09 s\n",
            "10-step perplexity: 1.042 cost-time: 0.07 s\n",
            "15-step perplexity: 1.043 cost-time: 0.07 s\n",
            "20-step perplexity: 1.046 cost-time: 0.08 s\n",
            "25-step perplexity: 1.048 cost-time: 0.08 s\n",
            "Epoch: 414 Train Perplexity: 1.046\n",
            "Epoch: 415 Learning rate: 0.0010\n",
            "5-step perplexity: 1.058 cost-time: 0.09 s\n",
            "10-step perplexity: 1.054 cost-time: 0.07 s\n",
            "15-step perplexity: 1.055 cost-time: 0.08 s\n",
            "20-step perplexity: 1.054 cost-time: 0.07 s\n",
            "25-step perplexity: 1.052 cost-time: 0.08 s\n",
            "Epoch: 415 Train Perplexity: 1.053\n",
            "Epoch: 416 Learning rate: 0.0010\n",
            "5-step perplexity: 1.028 cost-time: 0.10 s\n",
            "10-step perplexity: 1.045 cost-time: 0.08 s\n",
            "15-step perplexity: 1.046 cost-time: 0.08 s\n",
            "20-step perplexity: 1.045 cost-time: 0.07 s\n",
            "25-step perplexity: 1.047 cost-time: 0.07 s\n",
            "Epoch: 416 Train Perplexity: 1.045\n",
            "Epoch: 417 Learning rate: 0.0010\n",
            "5-step perplexity: 1.062 cost-time: 0.10 s\n",
            "10-step perplexity: 1.051 cost-time: 0.07 s\n",
            "15-step perplexity: 1.055 cost-time: 0.07 s\n",
            "20-step perplexity: 1.054 cost-time: 0.08 s\n",
            "25-step perplexity: 1.050 cost-time: 0.08 s\n",
            "Epoch: 417 Train Perplexity: 1.051\n",
            "Epoch: 418 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.09 s\n",
            "10-step perplexity: 1.050 cost-time: 0.08 s\n",
            "15-step perplexity: 1.046 cost-time: 0.08 s\n",
            "20-step perplexity: 1.047 cost-time: 0.07 s\n",
            "25-step perplexity: 1.046 cost-time: 0.07 s\n",
            "Epoch: 418 Train Perplexity: 1.044\n",
            "Epoch: 419 Learning rate: 0.0010\n",
            "5-step perplexity: 1.064 cost-time: 0.09 s\n",
            "10-step perplexity: 1.051 cost-time: 0.08 s\n",
            "15-step perplexity: 1.053 cost-time: 0.08 s\n",
            "20-step perplexity: 1.051 cost-time: 0.07 s\n",
            "25-step perplexity: 1.049 cost-time: 0.08 s\n",
            "Epoch: 419 Train Perplexity: 1.051\n",
            "Epoch: 420 Learning rate: 0.0010\n",
            "5-step perplexity: 1.037 cost-time: 0.09 s\n",
            "10-step perplexity: 1.046 cost-time: 0.08 s\n",
            "15-step perplexity: 1.046 cost-time: 0.07 s\n",
            "20-step perplexity: 1.048 cost-time: 0.07 s\n",
            "25-step perplexity: 1.050 cost-time: 0.08 s\n",
            "Epoch: 420 Train Perplexity: 1.047\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 421 Learning rate: 0.0010\n",
            "5-step perplexity: 1.051 cost-time: 0.10 s\n",
            "10-step perplexity: 1.045 cost-time: 0.08 s\n",
            "15-step perplexity: 1.050 cost-time: 0.07 s\n",
            "20-step perplexity: 1.049 cost-time: 0.07 s\n",
            "25-step perplexity: 1.048 cost-time: 0.07 s\n",
            "Epoch: 421 Train Perplexity: 1.048\n",
            "Epoch: 422 Learning rate: 0.0010\n",
            "5-step perplexity: 1.036 cost-time: 0.09 s\n",
            "10-step perplexity: 1.050 cost-time: 0.07 s\n",
            "15-step perplexity: 1.050 cost-time: 0.08 s\n",
            "20-step perplexity: 1.049 cost-time: 0.07 s\n",
            "25-step perplexity: 1.049 cost-time: 0.07 s\n",
            "Epoch: 422 Train Perplexity: 1.047\n",
            "Epoch: 423 Learning rate: 0.0010\n",
            "5-step perplexity: 1.055 cost-time: 0.10 s\n",
            "10-step perplexity: 1.047 cost-time: 0.08 s\n",
            "15-step perplexity: 1.049 cost-time: 0.07 s\n",
            "20-step perplexity: 1.048 cost-time: 0.09 s\n",
            "25-step perplexity: 1.046 cost-time: 0.09 s\n",
            "Epoch: 423 Train Perplexity: 1.047\n",
            "Epoch: 424 Learning rate: 0.0010\n",
            "5-step perplexity: 1.036 cost-time: 0.09 s\n",
            "10-step perplexity: 1.048 cost-time: 0.09 s\n",
            "15-step perplexity: 1.046 cost-time: 0.07 s\n",
            "20-step perplexity: 1.046 cost-time: 0.08 s\n",
            "25-step perplexity: 1.046 cost-time: 0.07 s\n",
            "Epoch: 424 Train Perplexity: 1.044\n",
            "Epoch: 425 Learning rate: 0.0010\n",
            "5-step perplexity: 1.062 cost-time: 0.10 s\n",
            "10-step perplexity: 1.047 cost-time: 0.07 s\n",
            "15-step perplexity: 1.047 cost-time: 0.07 s\n",
            "20-step perplexity: 1.048 cost-time: 0.08 s\n",
            "25-step perplexity: 1.047 cost-time: 0.07 s\n",
            "Epoch: 425 Train Perplexity: 1.048\n",
            "Epoch: 426 Learning rate: 0.0010\n",
            "5-step perplexity: 1.034 cost-time: 0.09 s\n",
            "10-step perplexity: 1.046 cost-time: 0.07 s\n",
            "15-step perplexity: 1.044 cost-time: 0.08 s\n",
            "20-step perplexity: 1.045 cost-time: 0.08 s\n",
            "25-step perplexity: 1.046 cost-time: 0.07 s\n",
            "Epoch: 426 Train Perplexity: 1.044\n",
            "Epoch: 427 Learning rate: 0.0010\n",
            "5-step perplexity: 1.055 cost-time: 0.10 s\n",
            "10-step perplexity: 1.047 cost-time: 0.07 s\n",
            "15-step perplexity: 1.048 cost-time: 0.08 s\n",
            "20-step perplexity: 1.048 cost-time: 0.08 s\n",
            "25-step perplexity: 1.047 cost-time: 0.07 s\n",
            "Epoch: 427 Train Perplexity: 1.048\n",
            "Epoch: 428 Learning rate: 0.0010\n",
            "5-step perplexity: 1.034 cost-time: 0.09 s\n",
            "10-step perplexity: 1.048 cost-time: 0.07 s\n",
            "15-step perplexity: 1.045 cost-time: 0.08 s\n",
            "20-step perplexity: 1.045 cost-time: 0.08 s\n",
            "25-step perplexity: 1.048 cost-time: 0.07 s\n",
            "Epoch: 428 Train Perplexity: 1.047\n",
            "Epoch: 429 Learning rate: 0.0010\n",
            "5-step perplexity: 1.058 cost-time: 0.10 s\n",
            "10-step perplexity: 1.049 cost-time: 0.07 s\n",
            "15-step perplexity: 1.050 cost-time: 0.07 s\n",
            "20-step perplexity: 1.048 cost-time: 0.07 s\n",
            "25-step perplexity: 1.046 cost-time: 0.08 s\n",
            "Epoch: 429 Train Perplexity: 1.047\n",
            "Epoch: 430 Learning rate: 0.0010\n",
            "5-step perplexity: 1.035 cost-time: 0.10 s\n",
            "10-step perplexity: 1.046 cost-time: 0.08 s\n",
            "15-step perplexity: 1.043 cost-time: 0.07 s\n",
            "20-step perplexity: 1.043 cost-time: 0.07 s\n",
            "25-step perplexity: 1.046 cost-time: 0.07 s\n",
            "Epoch: 430 Train Perplexity: 1.043\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 431 Learning rate: 0.0010\n",
            "5-step perplexity: 1.057 cost-time: 0.10 s\n",
            "10-step perplexity: 1.049 cost-time: 0.07 s\n",
            "15-step perplexity: 1.049 cost-time: 0.08 s\n",
            "20-step perplexity: 1.050 cost-time: 0.07 s\n",
            "25-step perplexity: 1.049 cost-time: 0.07 s\n",
            "Epoch: 431 Train Perplexity: 1.050\n",
            "Epoch: 432 Learning rate: 0.0010\n",
            "5-step perplexity: 1.036 cost-time: 0.10 s\n",
            "10-step perplexity: 1.047 cost-time: 0.07 s\n",
            "15-step perplexity: 1.042 cost-time: 0.07 s\n",
            "20-step perplexity: 1.041 cost-time: 0.09 s\n",
            "25-step perplexity: 1.044 cost-time: 0.08 s\n",
            "Epoch: 432 Train Perplexity: 1.042\n",
            "Epoch: 433 Learning rate: 0.0010\n",
            "5-step perplexity: 1.052 cost-time: 0.10 s\n",
            "10-step perplexity: 1.045 cost-time: 0.08 s\n",
            "15-step perplexity: 1.047 cost-time: 0.07 s\n",
            "20-step perplexity: 1.048 cost-time: 0.08 s\n",
            "25-step perplexity: 1.045 cost-time: 0.08 s\n",
            "Epoch: 433 Train Perplexity: 1.047\n",
            "Epoch: 434 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.10 s\n",
            "10-step perplexity: 1.052 cost-time: 0.07 s\n",
            "15-step perplexity: 1.046 cost-time: 0.08 s\n",
            "20-step perplexity: 1.047 cost-time: 0.08 s\n",
            "25-step perplexity: 1.048 cost-time: 0.07 s\n",
            "Epoch: 434 Train Perplexity: 1.046\n",
            "Epoch: 435 Learning rate: 0.0010\n",
            "5-step perplexity: 1.053 cost-time: 0.10 s\n",
            "10-step perplexity: 1.048 cost-time: 0.08 s\n",
            "15-step perplexity: 1.049 cost-time: 0.08 s\n",
            "20-step perplexity: 1.048 cost-time: 0.09 s\n",
            "25-step perplexity: 1.045 cost-time: 0.08 s\n",
            "Epoch: 435 Train Perplexity: 1.046\n",
            "Epoch: 436 Learning rate: 0.0010\n",
            "5-step perplexity: 1.035 cost-time: 0.10 s\n",
            "10-step perplexity: 1.048 cost-time: 0.08 s\n",
            "15-step perplexity: 1.048 cost-time: 0.07 s\n",
            "20-step perplexity: 1.046 cost-time: 0.07 s\n",
            "25-step perplexity: 1.047 cost-time: 0.07 s\n",
            "Epoch: 436 Train Perplexity: 1.044\n",
            "Epoch: 437 Learning rate: 0.0010\n",
            "5-step perplexity: 1.054 cost-time: 0.09 s\n",
            "10-step perplexity: 1.045 cost-time: 0.08 s\n",
            "15-step perplexity: 1.048 cost-time: 0.07 s\n",
            "20-step perplexity: 1.048 cost-time: 0.07 s\n",
            "25-step perplexity: 1.046 cost-time: 0.07 s\n",
            "Epoch: 437 Train Perplexity: 1.047\n",
            "Epoch: 438 Learning rate: 0.0010\n",
            "5-step perplexity: 1.040 cost-time: 0.09 s\n",
            "10-step perplexity: 1.048 cost-time: 0.08 s\n",
            "15-step perplexity: 1.042 cost-time: 0.07 s\n",
            "20-step perplexity: 1.043 cost-time: 0.08 s\n",
            "25-step perplexity: 1.044 cost-time: 0.07 s\n",
            "Epoch: 438 Train Perplexity: 1.042\n",
            "Epoch: 439 Learning rate: 0.0010\n",
            "5-step perplexity: 1.049 cost-time: 0.09 s\n",
            "10-step perplexity: 1.045 cost-time: 0.07 s\n",
            "15-step perplexity: 1.046 cost-time: 0.07 s\n",
            "20-step perplexity: 1.045 cost-time: 0.07 s\n",
            "25-step perplexity: 1.044 cost-time: 0.08 s\n",
            "Epoch: 439 Train Perplexity: 1.045\n",
            "Epoch: 440 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.10 s\n",
            "10-step perplexity: 1.046 cost-time: 0.08 s\n",
            "15-step perplexity: 1.042 cost-time: 0.07 s\n",
            "20-step perplexity: 1.043 cost-time: 0.08 s\n",
            "25-step perplexity: 1.046 cost-time: 0.08 s\n",
            "Epoch: 440 Train Perplexity: 1.042\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 441 Learning rate: 0.0010\n",
            "5-step perplexity: 1.045 cost-time: 0.09 s\n",
            "10-step perplexity: 1.040 cost-time: 0.07 s\n",
            "15-step perplexity: 1.042 cost-time: 0.08 s\n",
            "20-step perplexity: 1.041 cost-time: 0.07 s\n",
            "25-step perplexity: 1.038 cost-time: 0.07 s\n",
            "Epoch: 441 Train Perplexity: 1.042\n",
            "Epoch: 442 Learning rate: 0.0010\n",
            "5-step perplexity: 1.046 cost-time: 0.10 s\n",
            "10-step perplexity: 1.051 cost-time: 0.08 s\n",
            "15-step perplexity: 1.044 cost-time: 0.08 s\n",
            "20-step perplexity: 1.045 cost-time: 0.08 s\n",
            "25-step perplexity: 1.046 cost-time: 0.08 s\n",
            "Epoch: 442 Train Perplexity: 1.045\n",
            "Epoch: 443 Learning rate: 0.0010\n",
            "5-step perplexity: 1.061 cost-time: 0.09 s\n",
            "10-step perplexity: 1.047 cost-time: 0.08 s\n",
            "15-step perplexity: 1.049 cost-time: 0.08 s\n",
            "20-step perplexity: 1.048 cost-time: 0.08 s\n",
            "25-step perplexity: 1.046 cost-time: 0.08 s\n",
            "Epoch: 443 Train Perplexity: 1.046\n",
            "Epoch: 444 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.09 s\n",
            "10-step perplexity: 1.041 cost-time: 0.07 s\n",
            "15-step perplexity: 1.038 cost-time: 0.07 s\n",
            "20-step perplexity: 1.039 cost-time: 0.07 s\n",
            "25-step perplexity: 1.042 cost-time: 0.08 s\n",
            "Epoch: 444 Train Perplexity: 1.040\n",
            "Epoch: 445 Learning rate: 0.0010\n",
            "5-step perplexity: 1.058 cost-time: 0.09 s\n",
            "10-step perplexity: 1.046 cost-time: 0.08 s\n",
            "15-step perplexity: 1.050 cost-time: 0.07 s\n",
            "20-step perplexity: 1.048 cost-time: 0.08 s\n",
            "25-step perplexity: 1.046 cost-time: 0.07 s\n",
            "Epoch: 445 Train Perplexity: 1.046\n",
            "Epoch: 446 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.10 s\n",
            "10-step perplexity: 1.041 cost-time: 0.08 s\n",
            "15-step perplexity: 1.038 cost-time: 0.08 s\n",
            "20-step perplexity: 1.040 cost-time: 0.08 s\n",
            "25-step perplexity: 1.041 cost-time: 0.08 s\n",
            "Epoch: 446 Train Perplexity: 1.038\n",
            "Epoch: 447 Learning rate: 0.0010\n",
            "5-step perplexity: 1.057 cost-time: 0.09 s\n",
            "10-step perplexity: 1.050 cost-time: 0.07 s\n",
            "15-step perplexity: 1.050 cost-time: 0.07 s\n",
            "20-step perplexity: 1.047 cost-time: 0.07 s\n",
            "25-step perplexity: 1.045 cost-time: 0.07 s\n",
            "Epoch: 447 Train Perplexity: 1.046\n",
            "Epoch: 448 Learning rate: 0.0010\n",
            "5-step perplexity: 1.035 cost-time: 0.09 s\n",
            "10-step perplexity: 1.043 cost-time: 0.07 s\n",
            "15-step perplexity: 1.041 cost-time: 0.07 s\n",
            "20-step perplexity: 1.042 cost-time: 0.08 s\n",
            "25-step perplexity: 1.042 cost-time: 0.08 s\n",
            "Epoch: 448 Train Perplexity: 1.040\n",
            "Epoch: 449 Learning rate: 0.0010\n",
            "5-step perplexity: 1.056 cost-time: 0.09 s\n",
            "10-step perplexity: 1.047 cost-time: 0.07 s\n",
            "15-step perplexity: 1.049 cost-time: 0.08 s\n",
            "20-step perplexity: 1.048 cost-time: 0.08 s\n",
            "25-step perplexity: 1.045 cost-time: 0.07 s\n",
            "Epoch: 449 Train Perplexity: 1.046\n",
            "Epoch: 450 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.09 s\n",
            "10-step perplexity: 1.043 cost-time: 0.07 s\n",
            "15-step perplexity: 1.041 cost-time: 0.07 s\n",
            "20-step perplexity: 1.042 cost-time: 0.08 s\n",
            "25-step perplexity: 1.044 cost-time: 0.07 s\n",
            "Epoch: 450 Train Perplexity: 1.043\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 451 Learning rate: 0.0010\n",
            "5-step perplexity: 1.046 cost-time: 0.09 s\n",
            "10-step perplexity: 1.041 cost-time: 0.08 s\n",
            "15-step perplexity: 1.045 cost-time: 0.08 s\n",
            "20-step perplexity: 1.045 cost-time: 0.07 s\n",
            "25-step perplexity: 1.045 cost-time: 0.07 s\n",
            "Epoch: 451 Train Perplexity: 1.045\n",
            "Epoch: 452 Learning rate: 0.0010\n",
            "5-step perplexity: 1.031 cost-time: 0.09 s\n",
            "10-step perplexity: 1.043 cost-time: 0.08 s\n",
            "15-step perplexity: 1.041 cost-time: 0.07 s\n",
            "20-step perplexity: 1.040 cost-time: 0.09 s\n",
            "25-step perplexity: 1.040 cost-time: 0.08 s\n",
            "Epoch: 452 Train Perplexity: 1.039\n",
            "Epoch: 453 Learning rate: 0.0010\n",
            "5-step perplexity: 1.058 cost-time: 0.09 s\n",
            "10-step perplexity: 1.048 cost-time: 0.08 s\n",
            "15-step perplexity: 1.051 cost-time: 0.08 s\n",
            "20-step perplexity: 1.047 cost-time: 0.08 s\n",
            "25-step perplexity: 1.045 cost-time: 0.08 s\n",
            "Epoch: 453 Train Perplexity: 1.048\n",
            "Epoch: 454 Learning rate: 0.0010\n",
            "5-step perplexity: 1.034 cost-time: 0.10 s\n",
            "10-step perplexity: 1.041 cost-time: 0.07 s\n",
            "15-step perplexity: 1.038 cost-time: 0.08 s\n",
            "20-step perplexity: 1.041 cost-time: 0.07 s\n",
            "25-step perplexity: 1.041 cost-time: 0.07 s\n",
            "Epoch: 454 Train Perplexity: 1.038\n",
            "Epoch: 455 Learning rate: 0.0010\n",
            "5-step perplexity: 1.050 cost-time: 0.10 s\n",
            "10-step perplexity: 1.039 cost-time: 0.07 s\n",
            "15-step perplexity: 1.042 cost-time: 0.07 s\n",
            "20-step perplexity: 1.042 cost-time: 0.08 s\n",
            "25-step perplexity: 1.041 cost-time: 0.08 s\n",
            "Epoch: 455 Train Perplexity: 1.043\n",
            "Epoch: 456 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.09 s\n",
            "10-step perplexity: 1.042 cost-time: 0.08 s\n",
            "15-step perplexity: 1.040 cost-time: 0.08 s\n",
            "20-step perplexity: 1.039 cost-time: 0.07 s\n",
            "25-step perplexity: 1.041 cost-time: 0.08 s\n",
            "Epoch: 456 Train Perplexity: 1.040\n",
            "Epoch: 457 Learning rate: 0.0010\n",
            "5-step perplexity: 1.053 cost-time: 0.10 s\n",
            "10-step perplexity: 1.043 cost-time: 0.08 s\n",
            "15-step perplexity: 1.048 cost-time: 0.07 s\n",
            "20-step perplexity: 1.045 cost-time: 0.08 s\n",
            "25-step perplexity: 1.044 cost-time: 0.07 s\n",
            "Epoch: 457 Train Perplexity: 1.045\n",
            "Epoch: 458 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.09 s\n",
            "10-step perplexity: 1.041 cost-time: 0.08 s\n",
            "15-step perplexity: 1.042 cost-time: 0.08 s\n",
            "20-step perplexity: 1.041 cost-time: 0.08 s\n",
            "25-step perplexity: 1.042 cost-time: 0.08 s\n",
            "Epoch: 458 Train Perplexity: 1.040\n",
            "Epoch: 459 Learning rate: 0.0010\n",
            "5-step perplexity: 1.048 cost-time: 0.09 s\n",
            "10-step perplexity: 1.042 cost-time: 0.08 s\n",
            "15-step perplexity: 1.044 cost-time: 0.08 s\n",
            "20-step perplexity: 1.043 cost-time: 0.08 s\n",
            "25-step perplexity: 1.042 cost-time: 0.07 s\n",
            "Epoch: 459 Train Perplexity: 1.044\n",
            "Epoch: 460 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.09 s\n",
            "10-step perplexity: 1.040 cost-time: 0.07 s\n",
            "15-step perplexity: 1.037 cost-time: 0.07 s\n",
            "20-step perplexity: 1.037 cost-time: 0.08 s\n",
            "25-step perplexity: 1.039 cost-time: 0.07 s\n",
            "Epoch: 460 Train Perplexity: 1.037\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 461 Learning rate: 0.0010\n",
            "5-step perplexity: 1.050 cost-time: 0.11 s\n",
            "10-step perplexity: 1.043 cost-time: 0.08 s\n",
            "15-step perplexity: 1.044 cost-time: 0.08 s\n",
            "20-step perplexity: 1.045 cost-time: 0.08 s\n",
            "25-step perplexity: 1.043 cost-time: 0.07 s\n",
            "Epoch: 461 Train Perplexity: 1.043\n",
            "Epoch: 462 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.09 s\n",
            "10-step perplexity: 1.040 cost-time: 0.07 s\n",
            "15-step perplexity: 1.037 cost-time: 0.07 s\n",
            "20-step perplexity: 1.038 cost-time: 0.09 s\n",
            "25-step perplexity: 1.039 cost-time: 0.08 s\n",
            "Epoch: 462 Train Perplexity: 1.038\n",
            "Epoch: 463 Learning rate: 0.0010\n",
            "5-step perplexity: 1.050 cost-time: 0.09 s\n",
            "10-step perplexity: 1.044 cost-time: 0.07 s\n",
            "15-step perplexity: 1.044 cost-time: 0.08 s\n",
            "20-step perplexity: 1.043 cost-time: 0.07 s\n",
            "25-step perplexity: 1.041 cost-time: 0.08 s\n",
            "Epoch: 463 Train Perplexity: 1.041\n",
            "Epoch: 464 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.11 s\n",
            "10-step perplexity: 1.041 cost-time: 0.08 s\n",
            "15-step perplexity: 1.039 cost-time: 0.07 s\n",
            "20-step perplexity: 1.038 cost-time: 0.08 s\n",
            "25-step perplexity: 1.039 cost-time: 0.07 s\n",
            "Epoch: 464 Train Perplexity: 1.039\n",
            "Epoch: 465 Learning rate: 0.0010\n",
            "5-step perplexity: 1.047 cost-time: 0.11 s\n",
            "10-step perplexity: 1.040 cost-time: 0.08 s\n",
            "15-step perplexity: 1.042 cost-time: 0.07 s\n",
            "20-step perplexity: 1.040 cost-time: 0.08 s\n",
            "25-step perplexity: 1.039 cost-time: 0.08 s\n",
            "Epoch: 465 Train Perplexity: 1.041\n",
            "Epoch: 466 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.10 s\n",
            "10-step perplexity: 1.037 cost-time: 0.07 s\n",
            "15-step perplexity: 1.036 cost-time: 0.08 s\n",
            "20-step perplexity: 1.039 cost-time: 0.07 s\n",
            "25-step perplexity: 1.040 cost-time: 0.07 s\n",
            "Epoch: 466 Train Perplexity: 1.038\n",
            "Epoch: 467 Learning rate: 0.0010\n",
            "5-step perplexity: 1.051 cost-time: 0.09 s\n",
            "10-step perplexity: 1.039 cost-time: 0.08 s\n",
            "15-step perplexity: 1.041 cost-time: 0.07 s\n",
            "20-step perplexity: 1.040 cost-time: 0.08 s\n",
            "25-step perplexity: 1.040 cost-time: 0.08 s\n",
            "Epoch: 467 Train Perplexity: 1.042\n",
            "Epoch: 468 Learning rate: 0.0010\n",
            "5-step perplexity: 1.034 cost-time: 0.09 s\n",
            "10-step perplexity: 1.046 cost-time: 0.07 s\n",
            "15-step perplexity: 1.041 cost-time: 0.08 s\n",
            "20-step perplexity: 1.042 cost-time: 0.08 s\n",
            "25-step perplexity: 1.041 cost-time: 0.08 s\n",
            "Epoch: 468 Train Perplexity: 1.040\n",
            "Epoch: 469 Learning rate: 0.0010\n",
            "5-step perplexity: 1.042 cost-time: 0.10 s\n",
            "10-step perplexity: 1.039 cost-time: 0.09 s\n",
            "15-step perplexity: 1.041 cost-time: 0.07 s\n",
            "20-step perplexity: 1.041 cost-time: 0.08 s\n",
            "25-step perplexity: 1.038 cost-time: 0.07 s\n",
            "Epoch: 469 Train Perplexity: 1.041\n",
            "Epoch: 470 Learning rate: 0.0010\n",
            "5-step perplexity: 1.028 cost-time: 0.09 s\n",
            "10-step perplexity: 1.039 cost-time: 0.08 s\n",
            "15-step perplexity: 1.038 cost-time: 0.09 s\n",
            "20-step perplexity: 1.038 cost-time: 0.09 s\n",
            "25-step perplexity: 1.040 cost-time: 0.08 s\n",
            "Epoch: 470 Train Perplexity: 1.039\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 471 Learning rate: 0.0010\n",
            "5-step perplexity: 1.057 cost-time: 0.09 s\n",
            "10-step perplexity: 1.047 cost-time: 0.09 s\n",
            "15-step perplexity: 1.045 cost-time: 0.08 s\n",
            "20-step perplexity: 1.044 cost-time: 0.08 s\n",
            "25-step perplexity: 1.041 cost-time: 0.07 s\n",
            "Epoch: 471 Train Perplexity: 1.041\n",
            "Epoch: 472 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.09 s\n",
            "10-step perplexity: 1.041 cost-time: 0.07 s\n",
            "15-step perplexity: 1.039 cost-time: 0.08 s\n",
            "20-step perplexity: 1.039 cost-time: 0.07 s\n",
            "25-step perplexity: 1.039 cost-time: 0.07 s\n",
            "Epoch: 472 Train Perplexity: 1.037\n",
            "Epoch: 473 Learning rate: 0.0010\n",
            "5-step perplexity: 1.053 cost-time: 0.10 s\n",
            "10-step perplexity: 1.044 cost-time: 0.08 s\n",
            "15-step perplexity: 1.046 cost-time: 0.08 s\n",
            "20-step perplexity: 1.044 cost-time: 0.08 s\n",
            "25-step perplexity: 1.042 cost-time: 0.07 s\n",
            "Epoch: 473 Train Perplexity: 1.045\n",
            "Epoch: 474 Learning rate: 0.0010\n",
            "5-step perplexity: 1.030 cost-time: 0.09 s\n",
            "10-step perplexity: 1.043 cost-time: 0.07 s\n",
            "15-step perplexity: 1.039 cost-time: 0.08 s\n",
            "20-step perplexity: 1.041 cost-time: 0.09 s\n",
            "25-step perplexity: 1.042 cost-time: 0.07 s\n",
            "Epoch: 474 Train Perplexity: 1.040\n",
            "Epoch: 475 Learning rate: 0.0010\n",
            "5-step perplexity: 1.053 cost-time: 0.10 s\n",
            "10-step perplexity: 1.043 cost-time: 0.07 s\n",
            "15-step perplexity: 1.043 cost-time: 0.08 s\n",
            "20-step perplexity: 1.042 cost-time: 0.08 s\n",
            "25-step perplexity: 1.042 cost-time: 0.08 s\n",
            "Epoch: 475 Train Perplexity: 1.042\n",
            "Epoch: 476 Learning rate: 0.0010\n",
            "5-step perplexity: 1.030 cost-time: 0.10 s\n",
            "10-step perplexity: 1.039 cost-time: 0.08 s\n",
            "15-step perplexity: 1.036 cost-time: 0.08 s\n",
            "20-step perplexity: 1.038 cost-time: 0.08 s\n",
            "25-step perplexity: 1.038 cost-time: 0.07 s\n",
            "Epoch: 476 Train Perplexity: 1.037\n",
            "Epoch: 477 Learning rate: 0.0010\n",
            "5-step perplexity: 1.044 cost-time: 0.09 s\n",
            "10-step perplexity: 1.037 cost-time: 0.07 s\n",
            "15-step perplexity: 1.039 cost-time: 0.07 s\n",
            "20-step perplexity: 1.039 cost-time: 0.08 s\n",
            "25-step perplexity: 1.038 cost-time: 0.07 s\n",
            "Epoch: 477 Train Perplexity: 1.039\n",
            "Epoch: 478 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.09 s\n",
            "10-step perplexity: 1.039 cost-time: 0.08 s\n",
            "15-step perplexity: 1.038 cost-time: 0.08 s\n",
            "20-step perplexity: 1.038 cost-time: 0.08 s\n",
            "25-step perplexity: 1.038 cost-time: 0.07 s\n",
            "Epoch: 478 Train Perplexity: 1.037\n",
            "Epoch: 479 Learning rate: 0.0010\n",
            "5-step perplexity: 1.044 cost-time: 0.10 s\n",
            "10-step perplexity: 1.039 cost-time: 0.08 s\n",
            "15-step perplexity: 1.041 cost-time: 0.08 s\n",
            "20-step perplexity: 1.039 cost-time: 0.07 s\n",
            "25-step perplexity: 1.037 cost-time: 0.08 s\n",
            "Epoch: 479 Train Perplexity: 1.039\n",
            "Epoch: 480 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.09 s\n",
            "10-step perplexity: 1.041 cost-time: 0.07 s\n",
            "15-step perplexity: 1.037 cost-time: 0.07 s\n",
            "20-step perplexity: 1.036 cost-time: 0.07 s\n",
            "25-step perplexity: 1.037 cost-time: 0.07 s\n",
            "Epoch: 480 Train Perplexity: 1.035\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 481 Learning rate: 0.0010\n",
            "5-step perplexity: 1.051 cost-time: 0.09 s\n",
            "10-step perplexity: 1.041 cost-time: 0.07 s\n",
            "15-step perplexity: 1.042 cost-time: 0.07 s\n",
            "20-step perplexity: 1.043 cost-time: 0.08 s\n",
            "25-step perplexity: 1.041 cost-time: 0.07 s\n",
            "Epoch: 481 Train Perplexity: 1.041\n",
            "Epoch: 482 Learning rate: 0.0010\n",
            "5-step perplexity: 1.031 cost-time: 0.10 s\n",
            "10-step perplexity: 1.041 cost-time: 0.08 s\n",
            "15-step perplexity: 1.039 cost-time: 0.07 s\n",
            "20-step perplexity: 1.039 cost-time: 0.08 s\n",
            "25-step perplexity: 1.039 cost-time: 0.07 s\n",
            "Epoch: 482 Train Perplexity: 1.038\n",
            "Epoch: 483 Learning rate: 0.0010\n",
            "5-step perplexity: 1.041 cost-time: 0.09 s\n",
            "10-step perplexity: 1.035 cost-time: 0.07 s\n",
            "15-step perplexity: 1.037 cost-time: 0.09 s\n",
            "20-step perplexity: 1.035 cost-time: 0.08 s\n",
            "25-step perplexity: 1.035 cost-time: 0.07 s\n",
            "Epoch: 483 Train Perplexity: 1.036\n",
            "Epoch: 484 Learning rate: 0.0010\n",
            "5-step perplexity: 1.034 cost-time: 0.09 s\n",
            "10-step perplexity: 1.040 cost-time: 0.08 s\n",
            "15-step perplexity: 1.039 cost-time: 0.08 s\n",
            "20-step perplexity: 1.038 cost-time: 0.08 s\n",
            "25-step perplexity: 1.039 cost-time: 0.07 s\n",
            "Epoch: 484 Train Perplexity: 1.037\n",
            "Epoch: 485 Learning rate: 0.0010\n",
            "5-step perplexity: 1.047 cost-time: 0.10 s\n",
            "10-step perplexity: 1.036 cost-time: 0.07 s\n",
            "15-step perplexity: 1.039 cost-time: 0.07 s\n",
            "20-step perplexity: 1.038 cost-time: 0.07 s\n",
            "25-step perplexity: 1.036 cost-time: 0.07 s\n",
            "Epoch: 485 Train Perplexity: 1.037\n",
            "Epoch: 486 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.09 s\n",
            "10-step perplexity: 1.042 cost-time: 0.08 s\n",
            "15-step perplexity: 1.041 cost-time: 0.08 s\n",
            "20-step perplexity: 1.039 cost-time: 0.07 s\n",
            "25-step perplexity: 1.040 cost-time: 0.08 s\n",
            "Epoch: 486 Train Perplexity: 1.040\n",
            "Epoch: 487 Learning rate: 0.0010\n",
            "5-step perplexity: 1.043 cost-time: 0.09 s\n",
            "10-step perplexity: 1.038 cost-time: 0.07 s\n",
            "15-step perplexity: 1.041 cost-time: 0.07 s\n",
            "20-step perplexity: 1.040 cost-time: 0.07 s\n",
            "25-step perplexity: 1.038 cost-time: 0.07 s\n",
            "Epoch: 487 Train Perplexity: 1.039\n",
            "Epoch: 488 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.09 s\n",
            "10-step perplexity: 1.036 cost-time: 0.08 s\n",
            "15-step perplexity: 1.035 cost-time: 0.08 s\n",
            "20-step perplexity: 1.037 cost-time: 0.08 s\n",
            "25-step perplexity: 1.037 cost-time: 0.07 s\n",
            "Epoch: 488 Train Perplexity: 1.036\n",
            "Epoch: 489 Learning rate: 0.0010\n",
            "5-step perplexity: 1.044 cost-time: 0.09 s\n",
            "10-step perplexity: 1.041 cost-time: 0.07 s\n",
            "15-step perplexity: 1.042 cost-time: 0.07 s\n",
            "20-step perplexity: 1.042 cost-time: 0.07 s\n",
            "25-step perplexity: 1.039 cost-time: 0.07 s\n",
            "Epoch: 489 Train Perplexity: 1.040\n",
            "Epoch: 490 Learning rate: 0.0010\n",
            "5-step perplexity: 1.031 cost-time: 0.10 s\n",
            "10-step perplexity: 1.040 cost-time: 0.07 s\n",
            "15-step perplexity: 1.037 cost-time: 0.07 s\n",
            "20-step perplexity: 1.037 cost-time: 0.07 s\n",
            "25-step perplexity: 1.037 cost-time: 0.07 s\n",
            "Epoch: 490 Train Perplexity: 1.035\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 491 Learning rate: 0.0010\n",
            "5-step perplexity: 1.046 cost-time: 0.10 s\n",
            "10-step perplexity: 1.036 cost-time: 0.07 s\n",
            "15-step perplexity: 1.040 cost-time: 0.07 s\n",
            "20-step perplexity: 1.040 cost-time: 0.08 s\n",
            "25-step perplexity: 1.039 cost-time: 0.08 s\n",
            "Epoch: 491 Train Perplexity: 1.039\n",
            "Epoch: 492 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.10 s\n",
            "10-step perplexity: 1.038 cost-time: 0.07 s\n",
            "15-step perplexity: 1.035 cost-time: 0.08 s\n",
            "20-step perplexity: 1.036 cost-time: 0.08 s\n",
            "25-step perplexity: 1.037 cost-time: 0.07 s\n",
            "Epoch: 492 Train Perplexity: 1.036\n",
            "Epoch: 493 Learning rate: 0.0010\n",
            "5-step perplexity: 1.048 cost-time: 0.09 s\n",
            "10-step perplexity: 1.039 cost-time: 0.08 s\n",
            "15-step perplexity: 1.042 cost-time: 0.07 s\n",
            "20-step perplexity: 1.042 cost-time: 0.08 s\n",
            "25-step perplexity: 1.041 cost-time: 0.08 s\n",
            "Epoch: 493 Train Perplexity: 1.041\n",
            "Epoch: 494 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.10 s\n",
            "10-step perplexity: 1.036 cost-time: 0.08 s\n",
            "15-step perplexity: 1.032 cost-time: 0.07 s\n",
            "20-step perplexity: 1.034 cost-time: 0.08 s\n",
            "25-step perplexity: 1.034 cost-time: 0.07 s\n",
            "Epoch: 494 Train Perplexity: 1.033\n",
            "Epoch: 495 Learning rate: 0.0010\n",
            "5-step perplexity: 1.047 cost-time: 0.09 s\n",
            "10-step perplexity: 1.039 cost-time: 0.08 s\n",
            "15-step perplexity: 1.041 cost-time: 0.08 s\n",
            "20-step perplexity: 1.038 cost-time: 0.07 s\n",
            "25-step perplexity: 1.038 cost-time: 0.09 s\n",
            "Epoch: 495 Train Perplexity: 1.038\n",
            "Epoch: 496 Learning rate: 0.0010\n",
            "5-step perplexity: 1.034 cost-time: 0.10 s\n",
            "10-step perplexity: 1.044 cost-time: 0.08 s\n",
            "15-step perplexity: 1.040 cost-time: 0.07 s\n",
            "20-step perplexity: 1.039 cost-time: 0.08 s\n",
            "25-step perplexity: 1.039 cost-time: 0.07 s\n",
            "Epoch: 496 Train Perplexity: 1.037\n",
            "Epoch: 497 Learning rate: 0.0010\n",
            "5-step perplexity: 1.041 cost-time: 0.10 s\n",
            "10-step perplexity: 1.035 cost-time: 0.08 s\n",
            "15-step perplexity: 1.039 cost-time: 0.07 s\n",
            "20-step perplexity: 1.039 cost-time: 0.07 s\n",
            "25-step perplexity: 1.036 cost-time: 0.07 s\n",
            "Epoch: 497 Train Perplexity: 1.038\n",
            "Epoch: 498 Learning rate: 0.0010\n",
            "5-step perplexity: 1.030 cost-time: 0.09 s\n",
            "10-step perplexity: 1.039 cost-time: 0.08 s\n",
            "15-step perplexity: 1.034 cost-time: 0.08 s\n",
            "20-step perplexity: 1.035 cost-time: 0.08 s\n",
            "25-step perplexity: 1.035 cost-time: 0.08 s\n",
            "Epoch: 498 Train Perplexity: 1.033\n",
            "Epoch: 499 Learning rate: 0.0010\n",
            "5-step perplexity: 1.039 cost-time: 0.09 s\n",
            "10-step perplexity: 1.034 cost-time: 0.07 s\n",
            "15-step perplexity: 1.036 cost-time: 0.07 s\n",
            "20-step perplexity: 1.036 cost-time: 0.08 s\n",
            "25-step perplexity: 1.036 cost-time: 0.07 s\n",
            "Epoch: 499 Train Perplexity: 1.037\n",
            "Epoch: 500 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.09 s\n",
            "10-step perplexity: 1.036 cost-time: 0.08 s\n",
            "15-step perplexity: 1.033 cost-time: 0.09 s\n",
            "20-step perplexity: 1.033 cost-time: 0.08 s\n",
            "25-step perplexity: 1.035 cost-time: 0.07 s\n",
            "Epoch: 500 Train Perplexity: 1.034\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 501 Learning rate: 0.0010\n",
            "5-step perplexity: 1.047 cost-time: 0.10 s\n",
            "10-step perplexity: 1.041 cost-time: 0.08 s\n",
            "15-step perplexity: 1.040 cost-time: 0.07 s\n",
            "20-step perplexity: 1.040 cost-time: 0.07 s\n",
            "25-step perplexity: 1.037 cost-time: 0.07 s\n",
            "Epoch: 501 Train Perplexity: 1.039\n",
            "Epoch: 502 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.09 s\n",
            "10-step perplexity: 1.036 cost-time: 0.07 s\n",
            "15-step perplexity: 1.033 cost-time: 0.08 s\n",
            "20-step perplexity: 1.033 cost-time: 0.07 s\n",
            "25-step perplexity: 1.035 cost-time: 0.07 s\n",
            "Epoch: 502 Train Perplexity: 1.034\n",
            "Epoch: 503 Learning rate: 0.0010\n",
            "5-step perplexity: 1.045 cost-time: 0.10 s\n",
            "10-step perplexity: 1.036 cost-time: 0.07 s\n",
            "15-step perplexity: 1.037 cost-time: 0.08 s\n",
            "20-step perplexity: 1.036 cost-time: 0.08 s\n",
            "25-step perplexity: 1.035 cost-time: 0.07 s\n",
            "Epoch: 503 Train Perplexity: 1.036\n",
            "Epoch: 504 Learning rate: 0.0010\n",
            "5-step perplexity: 1.035 cost-time: 0.09 s\n",
            "10-step perplexity: 1.039 cost-time: 0.08 s\n",
            "15-step perplexity: 1.035 cost-time: 0.09 s\n",
            "20-step perplexity: 1.037 cost-time: 0.08 s\n",
            "25-step perplexity: 1.037 cost-time: 0.07 s\n",
            "Epoch: 504 Train Perplexity: 1.036\n",
            "Epoch: 505 Learning rate: 0.0010\n",
            "5-step perplexity: 1.040 cost-time: 0.10 s\n",
            "10-step perplexity: 1.035 cost-time: 0.07 s\n",
            "15-step perplexity: 1.038 cost-time: 0.08 s\n",
            "20-step perplexity: 1.037 cost-time: 0.07 s\n",
            "25-step perplexity: 1.034 cost-time: 0.08 s\n",
            "Epoch: 505 Train Perplexity: 1.036\n",
            "Epoch: 506 Learning rate: 0.0010\n",
            "5-step perplexity: 1.028 cost-time: 0.10 s\n",
            "10-step perplexity: 1.034 cost-time: 0.07 s\n",
            "15-step perplexity: 1.033 cost-time: 0.08 s\n",
            "20-step perplexity: 1.034 cost-time: 0.08 s\n",
            "25-step perplexity: 1.035 cost-time: 0.07 s\n",
            "Epoch: 506 Train Perplexity: 1.034\n",
            "Epoch: 507 Learning rate: 0.0010\n",
            "5-step perplexity: 1.047 cost-time: 0.09 s\n",
            "10-step perplexity: 1.038 cost-time: 0.08 s\n",
            "15-step perplexity: 1.040 cost-time: 0.08 s\n",
            "20-step perplexity: 1.038 cost-time: 0.08 s\n",
            "25-step perplexity: 1.038 cost-time: 0.08 s\n",
            "Epoch: 507 Train Perplexity: 1.037\n",
            "Epoch: 508 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.032 cost-time: 0.07 s\n",
            "15-step perplexity: 1.032 cost-time: 0.08 s\n",
            "20-step perplexity: 1.032 cost-time: 0.07 s\n",
            "25-step perplexity: 1.032 cost-time: 0.07 s\n",
            "Epoch: 508 Train Perplexity: 1.031\n",
            "Epoch: 509 Learning rate: 0.0010\n",
            "5-step perplexity: 1.038 cost-time: 0.09 s\n",
            "10-step perplexity: 1.034 cost-time: 0.08 s\n",
            "15-step perplexity: 1.036 cost-time: 0.07 s\n",
            "20-step perplexity: 1.037 cost-time: 0.08 s\n",
            "25-step perplexity: 1.034 cost-time: 0.08 s\n",
            "Epoch: 509 Train Perplexity: 1.036\n",
            "Epoch: 510 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.10 s\n",
            "10-step perplexity: 1.037 cost-time: 0.07 s\n",
            "15-step perplexity: 1.034 cost-time: 0.07 s\n",
            "20-step perplexity: 1.034 cost-time: 0.08 s\n",
            "25-step perplexity: 1.035 cost-time: 0.07 s\n",
            "Epoch: 510 Train Perplexity: 1.034\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 511 Learning rate: 0.0010\n",
            "5-step perplexity: 1.045 cost-time: 0.10 s\n",
            "10-step perplexity: 1.037 cost-time: 0.08 s\n",
            "15-step perplexity: 1.037 cost-time: 0.08 s\n",
            "20-step perplexity: 1.036 cost-time: 0.08 s\n",
            "25-step perplexity: 1.035 cost-time: 0.08 s\n",
            "Epoch: 511 Train Perplexity: 1.035\n",
            "Epoch: 512 Learning rate: 0.0010\n",
            "5-step perplexity: 1.028 cost-time: 0.09 s\n",
            "10-step perplexity: 1.036 cost-time: 0.08 s\n",
            "15-step perplexity: 1.034 cost-time: 0.08 s\n",
            "20-step perplexity: 1.034 cost-time: 0.08 s\n",
            "25-step perplexity: 1.034 cost-time: 0.08 s\n",
            "Epoch: 512 Train Perplexity: 1.034\n",
            "Epoch: 513 Learning rate: 0.0010\n",
            "5-step perplexity: 1.047 cost-time: 0.10 s\n",
            "10-step perplexity: 1.040 cost-time: 0.08 s\n",
            "15-step perplexity: 1.040 cost-time: 0.07 s\n",
            "20-step perplexity: 1.038 cost-time: 0.08 s\n",
            "25-step perplexity: 1.036 cost-time: 0.08 s\n",
            "Epoch: 513 Train Perplexity: 1.038\n",
            "Epoch: 514 Learning rate: 0.0010\n",
            "5-step perplexity: 1.030 cost-time: 0.10 s\n",
            "10-step perplexity: 1.035 cost-time: 0.08 s\n",
            "15-step perplexity: 1.032 cost-time: 0.08 s\n",
            "20-step perplexity: 1.032 cost-time: 0.07 s\n",
            "25-step perplexity: 1.033 cost-time: 0.08 s\n",
            "Epoch: 514 Train Perplexity: 1.032\n",
            "Epoch: 515 Learning rate: 0.0010\n",
            "5-step perplexity: 1.040 cost-time: 0.09 s\n",
            "10-step perplexity: 1.031 cost-time: 0.08 s\n",
            "15-step perplexity: 1.036 cost-time: 0.08 s\n",
            "20-step perplexity: 1.034 cost-time: 0.07 s\n",
            "25-step perplexity: 1.033 cost-time: 0.08 s\n",
            "Epoch: 515 Train Perplexity: 1.035\n",
            "Epoch: 516 Learning rate: 0.0010\n",
            "5-step perplexity: 1.030 cost-time: 0.10 s\n",
            "10-step perplexity: 1.034 cost-time: 0.08 s\n",
            "15-step perplexity: 1.034 cost-time: 0.09 s\n",
            "20-step perplexity: 1.034 cost-time: 0.09 s\n",
            "25-step perplexity: 1.035 cost-time: 0.08 s\n",
            "Epoch: 516 Train Perplexity: 1.034\n",
            "Epoch: 517 Learning rate: 0.0010\n",
            "5-step perplexity: 1.040 cost-time: 0.10 s\n",
            "10-step perplexity: 1.036 cost-time: 0.07 s\n",
            "15-step perplexity: 1.038 cost-time: 0.08 s\n",
            "20-step perplexity: 1.037 cost-time: 0.08 s\n",
            "25-step perplexity: 1.036 cost-time: 0.08 s\n",
            "Epoch: 517 Train Perplexity: 1.039\n",
            "Epoch: 518 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.11 s\n",
            "10-step perplexity: 1.040 cost-time: 0.08 s\n",
            "15-step perplexity: 1.036 cost-time: 0.07 s\n",
            "20-step perplexity: 1.036 cost-time: 0.09 s\n",
            "25-step perplexity: 1.034 cost-time: 0.08 s\n",
            "Epoch: 518 Train Perplexity: 1.034\n",
            "Epoch: 519 Learning rate: 0.0010\n",
            "5-step perplexity: 1.031 cost-time: 0.10 s\n",
            "10-step perplexity: 1.031 cost-time: 0.08 s\n",
            "15-step perplexity: 1.033 cost-time: 0.09 s\n",
            "20-step perplexity: 1.033 cost-time: 0.08 s\n",
            "25-step perplexity: 1.031 cost-time: 0.08 s\n",
            "Epoch: 519 Train Perplexity: 1.032\n",
            "Epoch: 520 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.10 s\n",
            "10-step perplexity: 1.035 cost-time: 0.07 s\n",
            "15-step perplexity: 1.035 cost-time: 0.08 s\n",
            "20-step perplexity: 1.035 cost-time: 0.08 s\n",
            "25-step perplexity: 1.037 cost-time: 0.07 s\n",
            "Epoch: 520 Train Perplexity: 1.035\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 521 Learning rate: 0.0010\n",
            "5-step perplexity: 1.034 cost-time: 0.10 s\n",
            "10-step perplexity: 1.028 cost-time: 0.08 s\n",
            "15-step perplexity: 1.033 cost-time: 0.07 s\n",
            "20-step perplexity: 1.032 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.08 s\n",
            "Epoch: 521 Train Perplexity: 1.031\n",
            "Epoch: 522 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.09 s\n",
            "10-step perplexity: 1.034 cost-time: 0.08 s\n",
            "15-step perplexity: 1.031 cost-time: 0.08 s\n",
            "20-step perplexity: 1.032 cost-time: 0.08 s\n",
            "25-step perplexity: 1.035 cost-time: 0.07 s\n",
            "Epoch: 522 Train Perplexity: 1.034\n",
            "Epoch: 523 Learning rate: 0.0010\n",
            "5-step perplexity: 1.038 cost-time: 0.11 s\n",
            "10-step perplexity: 1.032 cost-time: 0.09 s\n",
            "15-step perplexity: 1.035 cost-time: 0.09 s\n",
            "20-step perplexity: 1.034 cost-time: 0.08 s\n",
            "25-step perplexity: 1.032 cost-time: 0.08 s\n",
            "Epoch: 523 Train Perplexity: 1.034\n",
            "Epoch: 524 Learning rate: 0.0010\n",
            "5-step perplexity: 1.030 cost-time: 0.09 s\n",
            "10-step perplexity: 1.040 cost-time: 0.07 s\n",
            "15-step perplexity: 1.035 cost-time: 0.08 s\n",
            "20-step perplexity: 1.034 cost-time: 0.08 s\n",
            "25-step perplexity: 1.034 cost-time: 0.08 s\n",
            "Epoch: 524 Train Perplexity: 1.034\n",
            "Epoch: 525 Learning rate: 0.0010\n",
            "5-step perplexity: 1.040 cost-time: 0.10 s\n",
            "10-step perplexity: 1.033 cost-time: 0.08 s\n",
            "15-step perplexity: 1.035 cost-time: 0.08 s\n",
            "20-step perplexity: 1.032 cost-time: 0.08 s\n",
            "25-step perplexity: 1.032 cost-time: 0.08 s\n",
            "Epoch: 525 Train Perplexity: 1.032\n",
            "Epoch: 526 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.11 s\n",
            "10-step perplexity: 1.031 cost-time: 0.09 s\n",
            "15-step perplexity: 1.030 cost-time: 0.08 s\n",
            "20-step perplexity: 1.030 cost-time: 0.07 s\n",
            "25-step perplexity: 1.031 cost-time: 0.08 s\n",
            "Epoch: 526 Train Perplexity: 1.029\n",
            "Epoch: 527 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.10 s\n",
            "10-step perplexity: 1.031 cost-time: 0.08 s\n",
            "15-step perplexity: 1.037 cost-time: 0.07 s\n",
            "20-step perplexity: 1.035 cost-time: 0.08 s\n",
            "25-step perplexity: 1.033 cost-time: 0.07 s\n",
            "Epoch: 527 Train Perplexity: 1.035\n",
            "Epoch: 528 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.11 s\n",
            "10-step perplexity: 1.035 cost-time: 0.08 s\n",
            "15-step perplexity: 1.032 cost-time: 0.08 s\n",
            "20-step perplexity: 1.032 cost-time: 0.08 s\n",
            "25-step perplexity: 1.033 cost-time: 0.08 s\n",
            "Epoch: 528 Train Perplexity: 1.032\n",
            "Epoch: 529 Learning rate: 0.0010\n",
            "5-step perplexity: 1.042 cost-time: 0.10 s\n",
            "10-step perplexity: 1.032 cost-time: 0.08 s\n",
            "15-step perplexity: 1.035 cost-time: 0.08 s\n",
            "20-step perplexity: 1.033 cost-time: 0.08 s\n",
            "25-step perplexity: 1.033 cost-time: 0.08 s\n",
            "Epoch: 529 Train Perplexity: 1.034\n",
            "Epoch: 530 Learning rate: 0.0010\n",
            "5-step perplexity: 1.030 cost-time: 0.11 s\n",
            "10-step perplexity: 1.035 cost-time: 0.08 s\n",
            "15-step perplexity: 1.033 cost-time: 0.08 s\n",
            "20-step perplexity: 1.032 cost-time: 0.07 s\n",
            "25-step perplexity: 1.032 cost-time: 0.08 s\n",
            "Epoch: 530 Train Perplexity: 1.031\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 531 Learning rate: 0.0010\n",
            "5-step perplexity: 1.051 cost-time: 0.10 s\n",
            "10-step perplexity: 1.044 cost-time: 0.08 s\n",
            "15-step perplexity: 1.041 cost-time: 0.08 s\n",
            "20-step perplexity: 1.040 cost-time: 0.08 s\n",
            "25-step perplexity: 1.038 cost-time: 0.07 s\n",
            "Epoch: 531 Train Perplexity: 1.037\n",
            "Epoch: 532 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.11 s\n",
            "10-step perplexity: 1.034 cost-time: 0.08 s\n",
            "15-step perplexity: 1.031 cost-time: 0.08 s\n",
            "20-step perplexity: 1.031 cost-time: 0.08 s\n",
            "25-step perplexity: 1.032 cost-time: 0.07 s\n",
            "Epoch: 532 Train Perplexity: 1.032\n",
            "Epoch: 533 Learning rate: 0.0010\n",
            "5-step perplexity: 1.035 cost-time: 0.10 s\n",
            "10-step perplexity: 1.030 cost-time: 0.08 s\n",
            "15-step perplexity: 1.032 cost-time: 0.07 s\n",
            "20-step perplexity: 1.030 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.08 s\n",
            "Epoch: 533 Train Perplexity: 1.032\n",
            "Epoch: 534 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.032 cost-time: 0.09 s\n",
            "15-step perplexity: 1.031 cost-time: 0.07 s\n",
            "20-step perplexity: 1.033 cost-time: 0.07 s\n",
            "25-step perplexity: 1.034 cost-time: 0.07 s\n",
            "Epoch: 534 Train Perplexity: 1.033\n",
            "Epoch: 535 Learning rate: 0.0010\n",
            "5-step perplexity: 1.044 cost-time: 0.09 s\n",
            "10-step perplexity: 1.037 cost-time: 0.07 s\n",
            "15-step perplexity: 1.037 cost-time: 0.08 s\n",
            "20-step perplexity: 1.037 cost-time: 0.08 s\n",
            "25-step perplexity: 1.034 cost-time: 0.07 s\n",
            "Epoch: 535 Train Perplexity: 1.034\n",
            "Epoch: 536 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.10 s\n",
            "10-step perplexity: 1.032 cost-time: 0.07 s\n",
            "15-step perplexity: 1.029 cost-time: 0.08 s\n",
            "20-step perplexity: 1.031 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.07 s\n",
            "Epoch: 536 Train Perplexity: 1.030\n",
            "Epoch: 537 Learning rate: 0.0010\n",
            "5-step perplexity: 1.041 cost-time: 0.10 s\n",
            "10-step perplexity: 1.034 cost-time: 0.07 s\n",
            "15-step perplexity: 1.037 cost-time: 0.08 s\n",
            "20-step perplexity: 1.036 cost-time: 0.08 s\n",
            "25-step perplexity: 1.034 cost-time: 0.07 s\n",
            "Epoch: 537 Train Perplexity: 1.036\n",
            "Epoch: 538 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.09 s\n",
            "10-step perplexity: 1.032 cost-time: 0.07 s\n",
            "15-step perplexity: 1.032 cost-time: 0.07 s\n",
            "20-step perplexity: 1.033 cost-time: 0.09 s\n",
            "25-step perplexity: 1.033 cost-time: 0.07 s\n",
            "Epoch: 538 Train Perplexity: 1.032\n",
            "Epoch: 539 Learning rate: 0.0010\n",
            "5-step perplexity: 1.043 cost-time: 0.10 s\n",
            "10-step perplexity: 1.033 cost-time: 0.07 s\n",
            "15-step perplexity: 1.035 cost-time: 0.08 s\n",
            "20-step perplexity: 1.034 cost-time: 0.08 s\n",
            "25-step perplexity: 1.034 cost-time: 0.08 s\n",
            "Epoch: 539 Train Perplexity: 1.035\n",
            "Epoch: 540 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.09 s\n",
            "10-step perplexity: 1.033 cost-time: 0.07 s\n",
            "15-step perplexity: 1.029 cost-time: 0.08 s\n",
            "20-step perplexity: 1.031 cost-time: 0.08 s\n",
            "25-step perplexity: 1.031 cost-time: 0.07 s\n",
            "Epoch: 540 Train Perplexity: 1.031\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 541 Learning rate: 0.0010\n",
            "5-step perplexity: 1.043 cost-time: 0.09 s\n",
            "10-step perplexity: 1.039 cost-time: 0.08 s\n",
            "15-step perplexity: 1.038 cost-time: 0.07 s\n",
            "20-step perplexity: 1.037 cost-time: 0.08 s\n",
            "25-step perplexity: 1.034 cost-time: 0.07 s\n",
            "Epoch: 541 Train Perplexity: 1.034\n",
            "Epoch: 542 Learning rate: 0.0010\n",
            "5-step perplexity: 1.028 cost-time: 0.09 s\n",
            "10-step perplexity: 1.037 cost-time: 0.08 s\n",
            "15-step perplexity: 1.033 cost-time: 0.07 s\n",
            "20-step perplexity: 1.032 cost-time: 0.08 s\n",
            "25-step perplexity: 1.033 cost-time: 0.08 s\n",
            "Epoch: 542 Train Perplexity: 1.032\n",
            "Epoch: 543 Learning rate: 0.0010\n",
            "5-step perplexity: 1.039 cost-time: 0.09 s\n",
            "10-step perplexity: 1.031 cost-time: 0.07 s\n",
            "15-step perplexity: 1.033 cost-time: 0.08 s\n",
            "20-step perplexity: 1.033 cost-time: 0.07 s\n",
            "25-step perplexity: 1.031 cost-time: 0.08 s\n",
            "Epoch: 543 Train Perplexity: 1.032\n",
            "Epoch: 544 Learning rate: 0.0010\n",
            "5-step perplexity: 1.024 cost-time: 0.10 s\n",
            "10-step perplexity: 1.029 cost-time: 0.08 s\n",
            "15-step perplexity: 1.029 cost-time: 0.08 s\n",
            "20-step perplexity: 1.032 cost-time: 0.08 s\n",
            "25-step perplexity: 1.031 cost-time: 0.07 s\n",
            "Epoch: 544 Train Perplexity: 1.031\n",
            "Epoch: 545 Learning rate: 0.0010\n",
            "5-step perplexity: 1.035 cost-time: 0.10 s\n",
            "10-step perplexity: 1.033 cost-time: 0.07 s\n",
            "15-step perplexity: 1.034 cost-time: 0.08 s\n",
            "20-step perplexity: 1.032 cost-time: 0.07 s\n",
            "25-step perplexity: 1.032 cost-time: 0.07 s\n",
            "Epoch: 545 Train Perplexity: 1.033\n",
            "Epoch: 546 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.09 s\n",
            "10-step perplexity: 1.035 cost-time: 0.08 s\n",
            "15-step perplexity: 1.033 cost-time: 0.07 s\n",
            "20-step perplexity: 1.032 cost-time: 0.07 s\n",
            "25-step perplexity: 1.031 cost-time: 0.08 s\n",
            "Epoch: 546 Train Perplexity: 1.030\n",
            "Epoch: 547 Learning rate: 0.0010\n",
            "5-step perplexity: 1.036 cost-time: 0.09 s\n",
            "10-step perplexity: 1.031 cost-time: 0.08 s\n",
            "15-step perplexity: 1.032 cost-time: 0.08 s\n",
            "20-step perplexity: 1.030 cost-time: 0.08 s\n",
            "25-step perplexity: 1.029 cost-time: 0.08 s\n",
            "Epoch: 547 Train Perplexity: 1.030\n",
            "Epoch: 548 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.09 s\n",
            "10-step perplexity: 1.033 cost-time: 0.07 s\n",
            "15-step perplexity: 1.032 cost-time: 0.09 s\n",
            "20-step perplexity: 1.032 cost-time: 0.08 s\n",
            "25-step perplexity: 1.033 cost-time: 0.08 s\n",
            "Epoch: 548 Train Perplexity: 1.032\n",
            "Epoch: 549 Learning rate: 0.0010\n",
            "5-step perplexity: 1.036 cost-time: 0.09 s\n",
            "10-step perplexity: 1.029 cost-time: 0.07 s\n",
            "15-step perplexity: 1.030 cost-time: 0.08 s\n",
            "20-step perplexity: 1.031 cost-time: 0.08 s\n",
            "25-step perplexity: 1.031 cost-time: 0.07 s\n",
            "Epoch: 549 Train Perplexity: 1.031\n",
            "Epoch: 550 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.09 s\n",
            "10-step perplexity: 1.035 cost-time: 0.07 s\n",
            "15-step perplexity: 1.031 cost-time: 0.07 s\n",
            "20-step perplexity: 1.029 cost-time: 0.08 s\n",
            "25-step perplexity: 1.029 cost-time: 0.08 s\n",
            "Epoch: 550 Train Perplexity: 1.029\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 551 Learning rate: 0.0010\n",
            "5-step perplexity: 1.046 cost-time: 0.10 s\n",
            "10-step perplexity: 1.037 cost-time: 0.07 s\n",
            "15-step perplexity: 1.035 cost-time: 0.08 s\n",
            "20-step perplexity: 1.033 cost-time: 0.07 s\n",
            "25-step perplexity: 1.032 cost-time: 0.07 s\n",
            "Epoch: 551 Train Perplexity: 1.033\n",
            "Epoch: 552 Learning rate: 0.0010\n",
            "5-step perplexity: 1.024 cost-time: 0.09 s\n",
            "10-step perplexity: 1.033 cost-time: 0.07 s\n",
            "15-step perplexity: 1.032 cost-time: 0.08 s\n",
            "20-step perplexity: 1.031 cost-time: 0.08 s\n",
            "25-step perplexity: 1.032 cost-time: 0.07 s\n",
            "Epoch: 552 Train Perplexity: 1.031\n",
            "Epoch: 553 Learning rate: 0.0010\n",
            "5-step perplexity: 1.047 cost-time: 0.09 s\n",
            "10-step perplexity: 1.040 cost-time: 0.07 s\n",
            "15-step perplexity: 1.040 cost-time: 0.07 s\n",
            "20-step perplexity: 1.038 cost-time: 0.08 s\n",
            "25-step perplexity: 1.036 cost-time: 0.07 s\n",
            "Epoch: 553 Train Perplexity: 1.037\n",
            "Epoch: 554 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.10 s\n",
            "10-step perplexity: 1.029 cost-time: 0.08 s\n",
            "15-step perplexity: 1.028 cost-time: 0.08 s\n",
            "20-step perplexity: 1.029 cost-time: 0.07 s\n",
            "25-step perplexity: 1.029 cost-time: 0.08 s\n",
            "Epoch: 554 Train Perplexity: 1.029\n",
            "Epoch: 555 Learning rate: 0.0010\n",
            "5-step perplexity: 1.041 cost-time: 0.10 s\n",
            "10-step perplexity: 1.032 cost-time: 0.08 s\n",
            "15-step perplexity: 1.034 cost-time: 0.08 s\n",
            "20-step perplexity: 1.032 cost-time: 0.08 s\n",
            "25-step perplexity: 1.032 cost-time: 0.08 s\n",
            "Epoch: 555 Train Perplexity: 1.032\n",
            "Epoch: 556 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.032 cost-time: 0.07 s\n",
            "15-step perplexity: 1.030 cost-time: 0.07 s\n",
            "20-step perplexity: 1.032 cost-time: 0.08 s\n",
            "25-step perplexity: 1.032 cost-time: 0.08 s\n",
            "Epoch: 556 Train Perplexity: 1.030\n",
            "Epoch: 557 Learning rate: 0.0010\n",
            "5-step perplexity: 1.031 cost-time: 0.10 s\n",
            "10-step perplexity: 1.026 cost-time: 0.08 s\n",
            "15-step perplexity: 1.029 cost-time: 0.07 s\n",
            "20-step perplexity: 1.029 cost-time: 0.08 s\n",
            "25-step perplexity: 1.029 cost-time: 0.07 s\n",
            "Epoch: 557 Train Perplexity: 1.030\n",
            "Epoch: 558 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.033 cost-time: 0.08 s\n",
            "15-step perplexity: 1.030 cost-time: 0.08 s\n",
            "20-step perplexity: 1.030 cost-time: 0.07 s\n",
            "25-step perplexity: 1.030 cost-time: 0.07 s\n",
            "Epoch: 558 Train Perplexity: 1.029\n",
            "Epoch: 559 Learning rate: 0.0010\n",
            "5-step perplexity: 1.042 cost-time: 0.09 s\n",
            "10-step perplexity: 1.034 cost-time: 0.07 s\n",
            "15-step perplexity: 1.034 cost-time: 0.08 s\n",
            "20-step perplexity: 1.032 cost-time: 0.08 s\n",
            "25-step perplexity: 1.031 cost-time: 0.08 s\n",
            "Epoch: 559 Train Perplexity: 1.032\n",
            "Epoch: 560 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.10 s\n",
            "10-step perplexity: 1.029 cost-time: 0.09 s\n",
            "15-step perplexity: 1.029 cost-time: 0.08 s\n",
            "20-step perplexity: 1.029 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.08 s\n",
            "Epoch: 560 Train Perplexity: 1.028\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 561 Learning rate: 0.0010\n",
            "5-step perplexity: 1.040 cost-time: 0.10 s\n",
            "10-step perplexity: 1.033 cost-time: 0.08 s\n",
            "15-step perplexity: 1.034 cost-time: 0.08 s\n",
            "20-step perplexity: 1.033 cost-time: 0.07 s\n",
            "25-step perplexity: 1.032 cost-time: 0.07 s\n",
            "Epoch: 561 Train Perplexity: 1.032\n",
            "Epoch: 562 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.10 s\n",
            "10-step perplexity: 1.030 cost-time: 0.07 s\n",
            "15-step perplexity: 1.028 cost-time: 0.08 s\n",
            "20-step perplexity: 1.028 cost-time: 0.08 s\n",
            "25-step perplexity: 1.029 cost-time: 0.08 s\n",
            "Epoch: 562 Train Perplexity: 1.028\n",
            "Epoch: 563 Learning rate: 0.0010\n",
            "5-step perplexity: 1.038 cost-time: 0.10 s\n",
            "10-step perplexity: 1.032 cost-time: 0.07 s\n",
            "15-step perplexity: 1.034 cost-time: 0.08 s\n",
            "20-step perplexity: 1.035 cost-time: 0.07 s\n",
            "25-step perplexity: 1.034 cost-time: 0.07 s\n",
            "Epoch: 563 Train Perplexity: 1.035\n",
            "Epoch: 564 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.031 cost-time: 0.07 s\n",
            "15-step perplexity: 1.029 cost-time: 0.08 s\n",
            "20-step perplexity: 1.031 cost-time: 0.08 s\n",
            "25-step perplexity: 1.032 cost-time: 0.08 s\n",
            "Epoch: 564 Train Perplexity: 1.031\n",
            "Epoch: 565 Learning rate: 0.0010\n",
            "5-step perplexity: 1.035 cost-time: 0.09 s\n",
            "10-step perplexity: 1.030 cost-time: 0.08 s\n",
            "15-step perplexity: 1.033 cost-time: 0.08 s\n",
            "20-step perplexity: 1.031 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.08 s\n",
            "Epoch: 565 Train Perplexity: 1.031\n",
            "Epoch: 566 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.10 s\n",
            "10-step perplexity: 1.034 cost-time: 0.08 s\n",
            "15-step perplexity: 1.034 cost-time: 0.09 s\n",
            "20-step perplexity: 1.032 cost-time: 0.07 s\n",
            "25-step perplexity: 1.032 cost-time: 0.07 s\n",
            "Epoch: 566 Train Perplexity: 1.030\n",
            "Epoch: 567 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.10 s\n",
            "10-step perplexity: 1.027 cost-time: 0.09 s\n",
            "15-step perplexity: 1.030 cost-time: 0.08 s\n",
            "20-step perplexity: 1.029 cost-time: 0.08 s\n",
            "25-step perplexity: 1.029 cost-time: 0.08 s\n",
            "Epoch: 567 Train Perplexity: 1.030\n",
            "Epoch: 568 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.11 s\n",
            "10-step perplexity: 1.031 cost-time: 0.08 s\n",
            "15-step perplexity: 1.029 cost-time: 0.08 s\n",
            "20-step perplexity: 1.030 cost-time: 0.07 s\n",
            "25-step perplexity: 1.031 cost-time: 0.07 s\n",
            "Epoch: 568 Train Perplexity: 1.029\n",
            "Epoch: 569 Learning rate: 0.0010\n",
            "5-step perplexity: 1.038 cost-time: 0.09 s\n",
            "10-step perplexity: 1.031 cost-time: 0.08 s\n",
            "15-step perplexity: 1.033 cost-time: 0.08 s\n",
            "20-step perplexity: 1.032 cost-time: 0.08 s\n",
            "25-step perplexity: 1.033 cost-time: 0.08 s\n",
            "Epoch: 569 Train Perplexity: 1.033\n",
            "Epoch: 570 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.10 s\n",
            "10-step perplexity: 1.032 cost-time: 0.08 s\n",
            "15-step perplexity: 1.031 cost-time: 0.08 s\n",
            "20-step perplexity: 1.032 cost-time: 0.08 s\n",
            "25-step perplexity: 1.031 cost-time: 0.08 s\n",
            "Epoch: 570 Train Perplexity: 1.030\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 571 Learning rate: 0.0010\n",
            "5-step perplexity: 1.037 cost-time: 0.11 s\n",
            "10-step perplexity: 1.031 cost-time: 0.08 s\n",
            "15-step perplexity: 1.032 cost-time: 0.07 s\n",
            "20-step perplexity: 1.029 cost-time: 0.07 s\n",
            "25-step perplexity: 1.029 cost-time: 0.07 s\n",
            "Epoch: 571 Train Perplexity: 1.031\n",
            "Epoch: 572 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.09 s\n",
            "10-step perplexity: 1.026 cost-time: 0.07 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.029 cost-time: 0.07 s\n",
            "25-step perplexity: 1.030 cost-time: 0.07 s\n",
            "Epoch: 572 Train Perplexity: 1.028\n",
            "Epoch: 573 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.09 s\n",
            "10-step perplexity: 1.027 cost-time: 0.07 s\n",
            "15-step perplexity: 1.032 cost-time: 0.07 s\n",
            "20-step perplexity: 1.031 cost-time: 0.08 s\n",
            "25-step perplexity: 1.031 cost-time: 0.08 s\n",
            "Epoch: 573 Train Perplexity: 1.032\n",
            "Epoch: 574 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.09 s\n",
            "10-step perplexity: 1.035 cost-time: 0.08 s\n",
            "15-step perplexity: 1.031 cost-time: 0.09 s\n",
            "20-step perplexity: 1.030 cost-time: 0.07 s\n",
            "25-step perplexity: 1.030 cost-time: 0.07 s\n",
            "Epoch: 574 Train Perplexity: 1.029\n",
            "Epoch: 575 Learning rate: 0.0010\n",
            "5-step perplexity: 1.034 cost-time: 0.09 s\n",
            "10-step perplexity: 1.032 cost-time: 0.08 s\n",
            "15-step perplexity: 1.032 cost-time: 0.07 s\n",
            "20-step perplexity: 1.031 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.07 s\n",
            "Epoch: 575 Train Perplexity: 1.030\n",
            "Epoch: 576 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.028 cost-time: 0.07 s\n",
            "15-step perplexity: 1.030 cost-time: 0.07 s\n",
            "20-step perplexity: 1.030 cost-time: 0.08 s\n",
            "25-step perplexity: 1.031 cost-time: 0.07 s\n",
            "Epoch: 576 Train Perplexity: 1.030\n",
            "Epoch: 577 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.10 s\n",
            "10-step perplexity: 1.029 cost-time: 0.08 s\n",
            "15-step perplexity: 1.029 cost-time: 0.07 s\n",
            "20-step perplexity: 1.029 cost-time: 0.09 s\n",
            "25-step perplexity: 1.029 cost-time: 0.08 s\n",
            "Epoch: 577 Train Perplexity: 1.030\n",
            "Epoch: 578 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.09 s\n",
            "10-step perplexity: 1.030 cost-time: 0.08 s\n",
            "15-step perplexity: 1.029 cost-time: 0.07 s\n",
            "20-step perplexity: 1.031 cost-time: 0.08 s\n",
            "25-step perplexity: 1.031 cost-time: 0.07 s\n",
            "Epoch: 578 Train Perplexity: 1.030\n",
            "Epoch: 579 Learning rate: 0.0010\n",
            "5-step perplexity: 1.037 cost-time: 0.10 s\n",
            "10-step perplexity: 1.029 cost-time: 0.07 s\n",
            "15-step perplexity: 1.031 cost-time: 0.08 s\n",
            "20-step perplexity: 1.031 cost-time: 0.08 s\n",
            "25-step perplexity: 1.031 cost-time: 0.08 s\n",
            "Epoch: 579 Train Perplexity: 1.032\n",
            "Epoch: 580 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.025 cost-time: 0.08 s\n",
            "15-step perplexity: 1.024 cost-time: 0.08 s\n",
            "20-step perplexity: 1.024 cost-time: 0.07 s\n",
            "25-step perplexity: 1.025 cost-time: 0.08 s\n",
            "Epoch: 580 Train Perplexity: 1.025\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 581 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.025 cost-time: 0.08 s\n",
            "15-step perplexity: 1.028 cost-time: 0.08 s\n",
            "20-step perplexity: 1.028 cost-time: 0.08 s\n",
            "25-step perplexity: 1.028 cost-time: 0.07 s\n",
            "Epoch: 581 Train Perplexity: 1.028\n",
            "Epoch: 582 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.10 s\n",
            "10-step perplexity: 1.028 cost-time: 0.07 s\n",
            "15-step perplexity: 1.029 cost-time: 0.08 s\n",
            "20-step perplexity: 1.030 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.07 s\n",
            "Epoch: 582 Train Perplexity: 1.030\n",
            "Epoch: 583 Learning rate: 0.0010\n",
            "5-step perplexity: 1.039 cost-time: 0.10 s\n",
            "10-step perplexity: 1.031 cost-time: 0.07 s\n",
            "15-step perplexity: 1.032 cost-time: 0.07 s\n",
            "20-step perplexity: 1.032 cost-time: 0.08 s\n",
            "25-step perplexity: 1.031 cost-time: 0.08 s\n",
            "Epoch: 583 Train Perplexity: 1.031\n",
            "Epoch: 584 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.032 cost-time: 0.07 s\n",
            "15-step perplexity: 1.029 cost-time: 0.07 s\n",
            "20-step perplexity: 1.029 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.08 s\n",
            "Epoch: 584 Train Perplexity: 1.029\n",
            "Epoch: 585 Learning rate: 0.0010\n",
            "5-step perplexity: 1.039 cost-time: 0.09 s\n",
            "10-step perplexity: 1.032 cost-time: 0.07 s\n",
            "15-step perplexity: 1.033 cost-time: 0.09 s\n",
            "20-step perplexity: 1.032 cost-time: 0.07 s\n",
            "25-step perplexity: 1.031 cost-time: 0.07 s\n",
            "Epoch: 585 Train Perplexity: 1.033\n",
            "Epoch: 586 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.09 s\n",
            "10-step perplexity: 1.030 cost-time: 0.08 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.028 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.07 s\n",
            "Epoch: 586 Train Perplexity: 1.029\n",
            "Epoch: 587 Learning rate: 0.0010\n",
            "5-step perplexity: 1.036 cost-time: 0.09 s\n",
            "10-step perplexity: 1.030 cost-time: 0.08 s\n",
            "15-step perplexity: 1.032 cost-time: 0.07 s\n",
            "20-step perplexity: 1.030 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.07 s\n",
            "Epoch: 587 Train Perplexity: 1.031\n",
            "Epoch: 588 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.09 s\n",
            "10-step perplexity: 1.026 cost-time: 0.09 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.029 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.08 s\n",
            "Epoch: 588 Train Perplexity: 1.028\n",
            "Epoch: 589 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.09 s\n",
            "10-step perplexity: 1.027 cost-time: 0.07 s\n",
            "15-step perplexity: 1.029 cost-time: 0.08 s\n",
            "20-step perplexity: 1.029 cost-time: 0.09 s\n",
            "25-step perplexity: 1.029 cost-time: 0.07 s\n",
            "Epoch: 589 Train Perplexity: 1.032\n",
            "Epoch: 590 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.10 s\n",
            "10-step perplexity: 1.033 cost-time: 0.07 s\n",
            "15-step perplexity: 1.030 cost-time: 0.07 s\n",
            "20-step perplexity: 1.030 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.08 s\n",
            "Epoch: 590 Train Perplexity: 1.029\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 591 Learning rate: 0.0010\n",
            "5-step perplexity: 1.038 cost-time: 0.10 s\n",
            "10-step perplexity: 1.029 cost-time: 0.08 s\n",
            "15-step perplexity: 1.029 cost-time: 0.08 s\n",
            "20-step perplexity: 1.028 cost-time: 0.08 s\n",
            "25-step perplexity: 1.029 cost-time: 0.07 s\n",
            "Epoch: 591 Train Perplexity: 1.029\n",
            "Epoch: 592 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.09 s\n",
            "10-step perplexity: 1.029 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.08 s\n",
            "25-step perplexity: 1.028 cost-time: 0.07 s\n",
            "Epoch: 592 Train Perplexity: 1.027\n",
            "Epoch: 593 Learning rate: 0.0010\n",
            "5-step perplexity: 1.031 cost-time: 0.09 s\n",
            "10-step perplexity: 1.026 cost-time: 0.07 s\n",
            "15-step perplexity: 1.030 cost-time: 0.08 s\n",
            "20-step perplexity: 1.028 cost-time: 0.08 s\n",
            "25-step perplexity: 1.028 cost-time: 0.07 s\n",
            "Epoch: 593 Train Perplexity: 1.028\n",
            "Epoch: 594 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.09 s\n",
            "10-step perplexity: 1.026 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.08 s\n",
            "25-step perplexity: 1.028 cost-time: 0.08 s\n",
            "Epoch: 594 Train Perplexity: 1.027\n",
            "Epoch: 595 Learning rate: 0.0010\n",
            "5-step perplexity: 1.036 cost-time: 0.10 s\n",
            "10-step perplexity: 1.032 cost-time: 0.07 s\n",
            "15-step perplexity: 1.032 cost-time: 0.07 s\n",
            "20-step perplexity: 1.030 cost-time: 0.08 s\n",
            "25-step perplexity: 1.029 cost-time: 0.07 s\n",
            "Epoch: 595 Train Perplexity: 1.029\n",
            "Epoch: 596 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.09 s\n",
            "10-step perplexity: 1.030 cost-time: 0.07 s\n",
            "15-step perplexity: 1.028 cost-time: 0.07 s\n",
            "20-step perplexity: 1.030 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.08 s\n",
            "Epoch: 596 Train Perplexity: 1.027\n",
            "Epoch: 597 Learning rate: 0.0010\n",
            "5-step perplexity: 1.034 cost-time: 0.09 s\n",
            "10-step perplexity: 1.029 cost-time: 0.08 s\n",
            "15-step perplexity: 1.030 cost-time: 0.08 s\n",
            "20-step perplexity: 1.029 cost-time: 0.08 s\n",
            "25-step perplexity: 1.029 cost-time: 0.08 s\n",
            "Epoch: 597 Train Perplexity: 1.030\n",
            "Epoch: 598 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.10 s\n",
            "10-step perplexity: 1.029 cost-time: 0.07 s\n",
            "15-step perplexity: 1.028 cost-time: 0.07 s\n",
            "20-step perplexity: 1.028 cost-time: 0.08 s\n",
            "25-step perplexity: 1.029 cost-time: 0.07 s\n",
            "Epoch: 598 Train Perplexity: 1.027\n",
            "Epoch: 599 Learning rate: 0.0010\n",
            "5-step perplexity: 1.034 cost-time: 0.10 s\n",
            "10-step perplexity: 1.029 cost-time: 0.08 s\n",
            "15-step perplexity: 1.029 cost-time: 0.08 s\n",
            "20-step perplexity: 1.030 cost-time: 0.07 s\n",
            "25-step perplexity: 1.030 cost-time: 0.07 s\n",
            "Epoch: 599 Train Perplexity: 1.030\n",
            "Epoch: 600 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.09 s\n",
            "10-step perplexity: 1.028 cost-time: 0.07 s\n",
            "15-step perplexity: 1.027 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.07 s\n",
            "25-step perplexity: 1.027 cost-time: 0.07 s\n",
            "Epoch: 600 Train Perplexity: 1.026\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 601 Learning rate: 0.0010\n",
            "5-step perplexity: 1.036 cost-time: 0.09 s\n",
            "10-step perplexity: 1.036 cost-time: 0.07 s\n",
            "15-step perplexity: 1.035 cost-time: 0.08 s\n",
            "20-step perplexity: 1.033 cost-time: 0.08 s\n",
            "25-step perplexity: 1.032 cost-time: 0.08 s\n",
            "Epoch: 601 Train Perplexity: 1.032\n",
            "Epoch: 602 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.10 s\n",
            "10-step perplexity: 1.027 cost-time: 0.08 s\n",
            "15-step perplexity: 1.028 cost-time: 0.07 s\n",
            "20-step perplexity: 1.027 cost-time: 0.07 s\n",
            "25-step perplexity: 1.027 cost-time: 0.08 s\n",
            "Epoch: 602 Train Perplexity: 1.026\n",
            "Epoch: 603 Learning rate: 0.0010\n",
            "5-step perplexity: 1.035 cost-time: 0.11 s\n",
            "10-step perplexity: 1.031 cost-time: 0.07 s\n",
            "15-step perplexity: 1.032 cost-time: 0.07 s\n",
            "20-step perplexity: 1.030 cost-time: 0.08 s\n",
            "25-step perplexity: 1.029 cost-time: 0.08 s\n",
            "Epoch: 603 Train Perplexity: 1.029\n",
            "Epoch: 604 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.028 cost-time: 0.08 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.026 cost-time: 0.07 s\n",
            "25-step perplexity: 1.027 cost-time: 0.08 s\n",
            "Epoch: 604 Train Perplexity: 1.026\n",
            "Epoch: 605 Learning rate: 0.0010\n",
            "5-step perplexity: 1.035 cost-time: 0.09 s\n",
            "10-step perplexity: 1.028 cost-time: 0.08 s\n",
            "15-step perplexity: 1.033 cost-time: 0.08 s\n",
            "20-step perplexity: 1.031 cost-time: 0.08 s\n",
            "25-step perplexity: 1.030 cost-time: 0.07 s\n",
            "Epoch: 605 Train Perplexity: 1.031\n",
            "Epoch: 606 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.029 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.07 s\n",
            "25-step perplexity: 1.026 cost-time: 0.08 s\n",
            "Epoch: 606 Train Perplexity: 1.026\n",
            "Epoch: 607 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.10 s\n",
            "10-step perplexity: 1.025 cost-time: 0.08 s\n",
            "15-step perplexity: 1.026 cost-time: 0.07 s\n",
            "20-step perplexity: 1.025 cost-time: 0.08 s\n",
            "25-step perplexity: 1.025 cost-time: 0.08 s\n",
            "Epoch: 607 Train Perplexity: 1.027\n",
            "Epoch: 608 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.10 s\n",
            "10-step perplexity: 1.027 cost-time: 0.07 s\n",
            "15-step perplexity: 1.025 cost-time: 0.09 s\n",
            "20-step perplexity: 1.027 cost-time: 0.08 s\n",
            "25-step perplexity: 1.027 cost-time: 0.07 s\n",
            "Epoch: 608 Train Perplexity: 1.025\n",
            "Epoch: 609 Learning rate: 0.0010\n",
            "5-step perplexity: 1.028 cost-time: 0.10 s\n",
            "10-step perplexity: 1.029 cost-time: 0.07 s\n",
            "15-step perplexity: 1.028 cost-time: 0.07 s\n",
            "20-step perplexity: 1.026 cost-time: 0.08 s\n",
            "25-step perplexity: 1.025 cost-time: 0.08 s\n",
            "Epoch: 609 Train Perplexity: 1.027\n",
            "Epoch: 610 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.028 cost-time: 0.08 s\n",
            "15-step perplexity: 1.025 cost-time: 0.08 s\n",
            "20-step perplexity: 1.025 cost-time: 0.08 s\n",
            "25-step perplexity: 1.027 cost-time: 0.07 s\n",
            "Epoch: 610 Train Perplexity: 1.026\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 611 Learning rate: 0.0010\n",
            "5-step perplexity: 1.038 cost-time: 0.09 s\n",
            "10-step perplexity: 1.028 cost-time: 0.08 s\n",
            "15-step perplexity: 1.028 cost-time: 0.07 s\n",
            "20-step perplexity: 1.029 cost-time: 0.08 s\n",
            "25-step perplexity: 1.028 cost-time: 0.08 s\n",
            "Epoch: 611 Train Perplexity: 1.030\n",
            "Epoch: 612 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.09 s\n",
            "10-step perplexity: 1.030 cost-time: 0.08 s\n",
            "15-step perplexity: 1.030 cost-time: 0.07 s\n",
            "20-step perplexity: 1.027 cost-time: 0.07 s\n",
            "25-step perplexity: 1.027 cost-time: 0.07 s\n",
            "Epoch: 612 Train Perplexity: 1.027\n",
            "Epoch: 613 Learning rate: 0.0010\n",
            "5-step perplexity: 1.037 cost-time: 0.09 s\n",
            "10-step perplexity: 1.029 cost-time: 0.08 s\n",
            "15-step perplexity: 1.029 cost-time: 0.07 s\n",
            "20-step perplexity: 1.029 cost-time: 0.08 s\n",
            "25-step perplexity: 1.028 cost-time: 0.08 s\n",
            "Epoch: 613 Train Perplexity: 1.027\n",
            "Epoch: 614 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.11 s\n",
            "10-step perplexity: 1.025 cost-time: 0.08 s\n",
            "15-step perplexity: 1.025 cost-time: 0.08 s\n",
            "20-step perplexity: 1.025 cost-time: 0.08 s\n",
            "25-step perplexity: 1.026 cost-time: 0.08 s\n",
            "Epoch: 614 Train Perplexity: 1.025\n",
            "Epoch: 615 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.10 s\n",
            "10-step perplexity: 1.028 cost-time: 0.08 s\n",
            "15-step perplexity: 1.028 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.08 s\n",
            "25-step perplexity: 1.026 cost-time: 0.08 s\n",
            "Epoch: 615 Train Perplexity: 1.027\n",
            "Epoch: 616 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.023 cost-time: 0.08 s\n",
            "15-step perplexity: 1.023 cost-time: 0.07 s\n",
            "20-step perplexity: 1.024 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 616 Train Perplexity: 1.024\n",
            "Epoch: 617 Learning rate: 0.0010\n",
            "5-step perplexity: 1.036 cost-time: 0.09 s\n",
            "10-step perplexity: 1.028 cost-time: 0.07 s\n",
            "15-step perplexity: 1.028 cost-time: 0.08 s\n",
            "20-step perplexity: 1.028 cost-time: 0.08 s\n",
            "25-step perplexity: 1.027 cost-time: 0.07 s\n",
            "Epoch: 617 Train Perplexity: 1.028\n",
            "Epoch: 618 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.025 cost-time: 0.07 s\n",
            "15-step perplexity: 1.023 cost-time: 0.08 s\n",
            "20-step perplexity: 1.024 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 618 Train Perplexity: 1.024\n",
            "Epoch: 619 Learning rate: 0.0010\n",
            "5-step perplexity: 1.034 cost-time: 0.10 s\n",
            "10-step perplexity: 1.026 cost-time: 0.08 s\n",
            "15-step perplexity: 1.031 cost-time: 0.07 s\n",
            "20-step perplexity: 1.030 cost-time: 0.08 s\n",
            "25-step perplexity: 1.027 cost-time: 0.07 s\n",
            "Epoch: 619 Train Perplexity: 1.027\n",
            "Epoch: 620 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.10 s\n",
            "10-step perplexity: 1.024 cost-time: 0.07 s\n",
            "15-step perplexity: 1.023 cost-time: 0.07 s\n",
            "20-step perplexity: 1.023 cost-time: 0.08 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 620 Train Perplexity: 1.021\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 621 Learning rate: 0.0010\n",
            "5-step perplexity: 1.031 cost-time: 0.09 s\n",
            "10-step perplexity: 1.028 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.08 s\n",
            "20-step perplexity: 1.026 cost-time: 0.08 s\n",
            "25-step perplexity: 1.026 cost-time: 0.07 s\n",
            "Epoch: 621 Train Perplexity: 1.028\n",
            "Epoch: 622 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.10 s\n",
            "10-step perplexity: 1.027 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.08 s\n",
            "25-step perplexity: 1.028 cost-time: 0.08 s\n",
            "Epoch: 622 Train Perplexity: 1.027\n",
            "Epoch: 623 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.10 s\n",
            "10-step perplexity: 1.027 cost-time: 0.08 s\n",
            "15-step perplexity: 1.032 cost-time: 0.08 s\n",
            "20-step perplexity: 1.030 cost-time: 0.08 s\n",
            "25-step perplexity: 1.029 cost-time: 0.07 s\n",
            "Epoch: 623 Train Perplexity: 1.030\n",
            "Epoch: 624 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.027 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.08 s\n",
            "25-step perplexity: 1.027 cost-time: 0.08 s\n",
            "Epoch: 624 Train Perplexity: 1.026\n",
            "Epoch: 625 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.10 s\n",
            "10-step perplexity: 1.027 cost-time: 0.08 s\n",
            "15-step perplexity: 1.028 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.08 s\n",
            "25-step perplexity: 1.028 cost-time: 0.08 s\n",
            "Epoch: 625 Train Perplexity: 1.028\n",
            "Epoch: 626 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.025 cost-time: 0.08 s\n",
            "15-step perplexity: 1.023 cost-time: 0.08 s\n",
            "20-step perplexity: 1.023 cost-time: 0.07 s\n",
            "25-step perplexity: 1.024 cost-time: 0.08 s\n",
            "Epoch: 626 Train Perplexity: 1.023\n",
            "Epoch: 627 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.10 s\n",
            "10-step perplexity: 1.028 cost-time: 0.08 s\n",
            "15-step perplexity: 1.029 cost-time: 0.08 s\n",
            "20-step perplexity: 1.028 cost-time: 0.08 s\n",
            "25-step perplexity: 1.027 cost-time: 0.07 s\n",
            "Epoch: 627 Train Perplexity: 1.027\n",
            "Epoch: 628 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.09 s\n",
            "10-step perplexity: 1.026 cost-time: 0.07 s\n",
            "15-step perplexity: 1.024 cost-time: 0.08 s\n",
            "20-step perplexity: 1.025 cost-time: 0.08 s\n",
            "25-step perplexity: 1.025 cost-time: 0.08 s\n",
            "Epoch: 628 Train Perplexity: 1.024\n",
            "Epoch: 629 Learning rate: 0.0010\n",
            "5-step perplexity: 1.031 cost-time: 0.10 s\n",
            "10-step perplexity: 1.026 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.07 s\n",
            "20-step perplexity: 1.027 cost-time: 0.08 s\n",
            "25-step perplexity: 1.026 cost-time: 0.08 s\n",
            "Epoch: 629 Train Perplexity: 1.025\n",
            "Epoch: 630 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.025 cost-time: 0.09 s\n",
            "15-step perplexity: 1.023 cost-time: 0.08 s\n",
            "20-step perplexity: 1.023 cost-time: 0.07 s\n",
            "25-step perplexity: 1.024 cost-time: 0.08 s\n",
            "Epoch: 630 Train Perplexity: 1.023\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 631 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.10 s\n",
            "10-step perplexity: 1.026 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.08 s\n",
            "25-step perplexity: 1.027 cost-time: 0.07 s\n",
            "Epoch: 631 Train Perplexity: 1.026\n",
            "Epoch: 632 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.10 s\n",
            "10-step perplexity: 1.025 cost-time: 0.08 s\n",
            "15-step perplexity: 1.024 cost-time: 0.08 s\n",
            "20-step perplexity: 1.023 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.08 s\n",
            "Epoch: 632 Train Perplexity: 1.024\n",
            "Epoch: 633 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.10 s\n",
            "10-step perplexity: 1.027 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.07 s\n",
            "20-step perplexity: 1.028 cost-time: 0.08 s\n",
            "25-step perplexity: 1.027 cost-time: 0.08 s\n",
            "Epoch: 633 Train Perplexity: 1.028\n",
            "Epoch: 634 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.11 s\n",
            "10-step perplexity: 1.030 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.08 s\n",
            "25-step perplexity: 1.027 cost-time: 0.08 s\n",
            "Epoch: 634 Train Perplexity: 1.027\n",
            "Epoch: 635 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.025 cost-time: 0.07 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.025 cost-time: 0.08 s\n",
            "25-step perplexity: 1.025 cost-time: 0.08 s\n",
            "Epoch: 635 Train Perplexity: 1.025\n",
            "Epoch: 636 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.10 s\n",
            "10-step perplexity: 1.022 cost-time: 0.08 s\n",
            "15-step perplexity: 1.021 cost-time: 0.07 s\n",
            "20-step perplexity: 1.024 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 636 Train Perplexity: 1.023\n",
            "Epoch: 637 Learning rate: 0.0010\n",
            "5-step perplexity: 1.024 cost-time: 0.09 s\n",
            "10-step perplexity: 1.021 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.08 s\n",
            "20-step perplexity: 1.025 cost-time: 0.08 s\n",
            "25-step perplexity: 1.025 cost-time: 0.07 s\n",
            "Epoch: 637 Train Perplexity: 1.026\n",
            "Epoch: 638 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.026 cost-time: 0.07 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.026 cost-time: 0.07 s\n",
            "25-step perplexity: 1.026 cost-time: 0.08 s\n",
            "Epoch: 638 Train Perplexity: 1.025\n",
            "Epoch: 639 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.027 cost-time: 0.07 s\n",
            "15-step perplexity: 1.026 cost-time: 0.07 s\n",
            "20-step perplexity: 1.026 cost-time: 0.08 s\n",
            "25-step perplexity: 1.026 cost-time: 0.08 s\n",
            "Epoch: 639 Train Perplexity: 1.027\n",
            "Epoch: 640 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.09 s\n",
            "10-step perplexity: 1.029 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.09 s\n",
            "25-step perplexity: 1.027 cost-time: 0.08 s\n",
            "Epoch: 640 Train Perplexity: 1.027\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 641 Learning rate: 0.0010\n",
            "5-step perplexity: 1.030 cost-time: 0.10 s\n",
            "10-step perplexity: 1.025 cost-time: 0.08 s\n",
            "15-step perplexity: 1.028 cost-time: 0.08 s\n",
            "20-step perplexity: 1.026 cost-time: 0.07 s\n",
            "25-step perplexity: 1.025 cost-time: 0.07 s\n",
            "Epoch: 641 Train Perplexity: 1.026\n",
            "Epoch: 642 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.09 s\n",
            "10-step perplexity: 1.026 cost-time: 0.08 s\n",
            "15-step perplexity: 1.026 cost-time: 0.07 s\n",
            "20-step perplexity: 1.026 cost-time: 0.07 s\n",
            "25-step perplexity: 1.026 cost-time: 0.07 s\n",
            "Epoch: 642 Train Perplexity: 1.025\n",
            "Epoch: 643 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.024 cost-time: 0.07 s\n",
            "15-step perplexity: 1.024 cost-time: 0.07 s\n",
            "20-step perplexity: 1.024 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 643 Train Perplexity: 1.025\n",
            "Epoch: 644 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.026 cost-time: 0.08 s\n",
            "15-step perplexity: 1.024 cost-time: 0.08 s\n",
            "20-step perplexity: 1.024 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 644 Train Perplexity: 1.023\n",
            "Epoch: 645 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.09 s\n",
            "10-step perplexity: 1.029 cost-time: 0.08 s\n",
            "15-step perplexity: 1.028 cost-time: 0.07 s\n",
            "20-step perplexity: 1.027 cost-time: 0.08 s\n",
            "25-step perplexity: 1.026 cost-time: 0.07 s\n",
            "Epoch: 645 Train Perplexity: 1.026\n",
            "Epoch: 646 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.026 cost-time: 0.07 s\n",
            "15-step perplexity: 1.024 cost-time: 0.07 s\n",
            "20-step perplexity: 1.023 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.08 s\n",
            "Epoch: 646 Train Perplexity: 1.023\n",
            "Epoch: 647 Learning rate: 0.0010\n",
            "5-step perplexity: 1.024 cost-time: 0.09 s\n",
            "10-step perplexity: 1.023 cost-time: 0.07 s\n",
            "15-step perplexity: 1.024 cost-time: 0.08 s\n",
            "20-step perplexity: 1.024 cost-time: 0.08 s\n",
            "25-step perplexity: 1.026 cost-time: 0.08 s\n",
            "Epoch: 647 Train Perplexity: 1.026\n",
            "Epoch: 648 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.08 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.022 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 648 Train Perplexity: 1.024\n",
            "Epoch: 649 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.09 s\n",
            "10-step perplexity: 1.023 cost-time: 0.08 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.08 s\n",
            "25-step perplexity: 1.026 cost-time: 0.07 s\n",
            "Epoch: 649 Train Perplexity: 1.027\n",
            "Epoch: 650 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.024 cost-time: 0.07 s\n",
            "15-step perplexity: 1.022 cost-time: 0.08 s\n",
            "20-step perplexity: 1.023 cost-time: 0.07 s\n",
            "25-step perplexity: 1.023 cost-time: 0.08 s\n",
            "Epoch: 650 Train Perplexity: 1.023\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 651 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.09 s\n",
            "10-step perplexity: 1.025 cost-time: 0.08 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.028 cost-time: 0.08 s\n",
            "25-step perplexity: 1.027 cost-time: 0.09 s\n",
            "Epoch: 651 Train Perplexity: 1.028\n",
            "Epoch: 652 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.024 cost-time: 0.08 s\n",
            "15-step perplexity: 1.024 cost-time: 0.08 s\n",
            "20-step perplexity: 1.025 cost-time: 0.08 s\n",
            "25-step perplexity: 1.025 cost-time: 0.07 s\n",
            "Epoch: 652 Train Perplexity: 1.024\n",
            "Epoch: 653 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.11 s\n",
            "10-step perplexity: 1.024 cost-time: 0.08 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.08 s\n",
            "25-step perplexity: 1.026 cost-time: 0.07 s\n",
            "Epoch: 653 Train Perplexity: 1.025\n",
            "Epoch: 654 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.09 s\n",
            "10-step perplexity: 1.025 cost-time: 0.08 s\n",
            "15-step perplexity: 1.025 cost-time: 0.08 s\n",
            "20-step perplexity: 1.024 cost-time: 0.08 s\n",
            "25-step perplexity: 1.026 cost-time: 0.07 s\n",
            "Epoch: 654 Train Perplexity: 1.024\n",
            "Epoch: 655 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.10 s\n",
            "10-step perplexity: 1.025 cost-time: 0.08 s\n",
            "15-step perplexity: 1.026 cost-time: 0.07 s\n",
            "20-step perplexity: 1.026 cost-time: 0.09 s\n",
            "25-step perplexity: 1.025 cost-time: 0.08 s\n",
            "Epoch: 655 Train Perplexity: 1.025\n",
            "Epoch: 656 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.024 cost-time: 0.08 s\n",
            "15-step perplexity: 1.022 cost-time: 0.08 s\n",
            "20-step perplexity: 1.024 cost-time: 0.07 s\n",
            "25-step perplexity: 1.023 cost-time: 0.07 s\n",
            "Epoch: 656 Train Perplexity: 1.023\n",
            "Epoch: 657 Learning rate: 0.0010\n",
            "5-step perplexity: 1.030 cost-time: 0.09 s\n",
            "10-step perplexity: 1.027 cost-time: 0.08 s\n",
            "15-step perplexity: 1.028 cost-time: 0.08 s\n",
            "20-step perplexity: 1.028 cost-time: 0.08 s\n",
            "25-step perplexity: 1.026 cost-time: 0.08 s\n",
            "Epoch: 657 Train Perplexity: 1.027\n",
            "Epoch: 658 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.022 cost-time: 0.08 s\n",
            "25-step perplexity: 1.023 cost-time: 0.07 s\n",
            "Epoch: 658 Train Perplexity: 1.023\n",
            "Epoch: 659 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.09 s\n",
            "10-step perplexity: 1.025 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.08 s\n",
            "20-step perplexity: 1.026 cost-time: 0.07 s\n",
            "25-step perplexity: 1.026 cost-time: 0.08 s\n",
            "Epoch: 659 Train Perplexity: 1.026\n",
            "Epoch: 660 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.07 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.022 cost-time: 0.08 s\n",
            "25-step perplexity: 1.022 cost-time: 0.08 s\n",
            "Epoch: 660 Train Perplexity: 1.022\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 661 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.09 s\n",
            "10-step perplexity: 1.026 cost-time: 0.08 s\n",
            "15-step perplexity: 1.027 cost-time: 0.07 s\n",
            "20-step perplexity: 1.026 cost-time: 0.09 s\n",
            "25-step perplexity: 1.026 cost-time: 0.08 s\n",
            "Epoch: 661 Train Perplexity: 1.026\n",
            "Epoch: 662 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.10 s\n",
            "10-step perplexity: 1.024 cost-time: 0.08 s\n",
            "15-step perplexity: 1.023 cost-time: 0.08 s\n",
            "20-step perplexity: 1.022 cost-time: 0.08 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 662 Train Perplexity: 1.021\n",
            "Epoch: 663 Learning rate: 0.0010\n",
            "5-step perplexity: 1.028 cost-time: 0.10 s\n",
            "10-step perplexity: 1.024 cost-time: 0.07 s\n",
            "15-step perplexity: 1.024 cost-time: 0.08 s\n",
            "20-step perplexity: 1.025 cost-time: 0.07 s\n",
            "25-step perplexity: 1.025 cost-time: 0.07 s\n",
            "Epoch: 663 Train Perplexity: 1.026\n",
            "Epoch: 664 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.12 s\n",
            "10-step perplexity: 1.026 cost-time: 0.08 s\n",
            "15-step perplexity: 1.025 cost-time: 0.08 s\n",
            "20-step perplexity: 1.024 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 664 Train Perplexity: 1.024\n",
            "Epoch: 665 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.025 cost-time: 0.07 s\n",
            "15-step perplexity: 1.025 cost-time: 0.07 s\n",
            "20-step perplexity: 1.025 cost-time: 0.07 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 665 Train Perplexity: 1.024\n",
            "Epoch: 666 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.029 cost-time: 0.07 s\n",
            "15-step perplexity: 1.027 cost-time: 0.07 s\n",
            "20-step perplexity: 1.028 cost-time: 0.08 s\n",
            "25-step perplexity: 1.027 cost-time: 0.08 s\n",
            "Epoch: 666 Train Perplexity: 1.027\n",
            "Epoch: 667 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.025 cost-time: 0.07 s\n",
            "15-step perplexity: 1.027 cost-time: 0.07 s\n",
            "20-step perplexity: 1.026 cost-time: 0.07 s\n",
            "25-step perplexity: 1.027 cost-time: 0.07 s\n",
            "Epoch: 667 Train Perplexity: 1.026\n",
            "Epoch: 668 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.09 s\n",
            "10-step perplexity: 1.024 cost-time: 0.08 s\n",
            "15-step perplexity: 1.023 cost-time: 0.07 s\n",
            "20-step perplexity: 1.023 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 668 Train Perplexity: 1.023\n",
            "Epoch: 669 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.09 s\n",
            "10-step perplexity: 1.027 cost-time: 0.07 s\n",
            "15-step perplexity: 1.028 cost-time: 0.07 s\n",
            "20-step perplexity: 1.026 cost-time: 0.08 s\n",
            "25-step perplexity: 1.026 cost-time: 0.08 s\n",
            "Epoch: 669 Train Perplexity: 1.026\n",
            "Epoch: 670 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.10 s\n",
            "10-step perplexity: 1.028 cost-time: 0.07 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.025 cost-time: 0.07 s\n",
            "25-step perplexity: 1.025 cost-time: 0.07 s\n",
            "Epoch: 670 Train Perplexity: 1.024\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 671 Learning rate: 0.0010\n",
            "5-step perplexity: 1.028 cost-time: 0.09 s\n",
            "10-step perplexity: 1.024 cost-time: 0.08 s\n",
            "15-step perplexity: 1.025 cost-time: 0.08 s\n",
            "20-step perplexity: 1.025 cost-time: 0.07 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 671 Train Perplexity: 1.024\n",
            "Epoch: 672 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.11 s\n",
            "10-step perplexity: 1.024 cost-time: 0.07 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.023 cost-time: 0.08 s\n",
            "25-step perplexity: 1.026 cost-time: 0.07 s\n",
            "Epoch: 672 Train Perplexity: 1.024\n",
            "Epoch: 673 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.09 s\n",
            "10-step perplexity: 1.023 cost-time: 0.07 s\n",
            "15-step perplexity: 1.025 cost-time: 0.07 s\n",
            "20-step perplexity: 1.025 cost-time: 0.07 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 673 Train Perplexity: 1.024\n",
            "Epoch: 674 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.09 s\n",
            "10-step perplexity: 1.024 cost-time: 0.08 s\n",
            "15-step perplexity: 1.021 cost-time: 0.08 s\n",
            "20-step perplexity: 1.022 cost-time: 0.07 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 674 Train Perplexity: 1.021\n",
            "Epoch: 675 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.028 cost-time: 0.07 s\n",
            "15-step perplexity: 1.028 cost-time: 0.08 s\n",
            "20-step perplexity: 1.026 cost-time: 0.07 s\n",
            "25-step perplexity: 1.025 cost-time: 0.07 s\n",
            "Epoch: 675 Train Perplexity: 1.024\n",
            "Epoch: 676 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.07 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 676 Train Perplexity: 1.023\n",
            "Epoch: 677 Learning rate: 0.0010\n",
            "5-step perplexity: 1.033 cost-time: 0.09 s\n",
            "10-step perplexity: 1.028 cost-time: 0.07 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.028 cost-time: 0.07 s\n",
            "25-step perplexity: 1.027 cost-time: 0.08 s\n",
            "Epoch: 677 Train Perplexity: 1.028\n",
            "Epoch: 678 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.09 s\n",
            "10-step perplexity: 1.024 cost-time: 0.07 s\n",
            "15-step perplexity: 1.024 cost-time: 0.07 s\n",
            "20-step perplexity: 1.022 cost-time: 0.08 s\n",
            "25-step perplexity: 1.023 cost-time: 0.08 s\n",
            "Epoch: 678 Train Perplexity: 1.023\n",
            "Epoch: 679 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.08 s\n",
            "15-step perplexity: 1.023 cost-time: 0.08 s\n",
            "20-step perplexity: 1.022 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.09 s\n",
            "Epoch: 679 Train Perplexity: 1.022\n",
            "Epoch: 680 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.023 cost-time: 0.07 s\n",
            "15-step perplexity: 1.022 cost-time: 0.08 s\n",
            "20-step perplexity: 1.021 cost-time: 0.07 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 680 Train Perplexity: 1.020\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 681 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.10 s\n",
            "10-step perplexity: 1.023 cost-time: 0.07 s\n",
            "15-step perplexity: 1.024 cost-time: 0.07 s\n",
            "20-step perplexity: 1.023 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 681 Train Perplexity: 1.024\n",
            "Epoch: 682 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.09 s\n",
            "10-step perplexity: 1.029 cost-time: 0.07 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.025 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 682 Train Perplexity: 1.023\n",
            "Epoch: 683 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.10 s\n",
            "10-step perplexity: 1.024 cost-time: 0.07 s\n",
            "15-step perplexity: 1.026 cost-time: 0.07 s\n",
            "20-step perplexity: 1.025 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.08 s\n",
            "Epoch: 683 Train Perplexity: 1.025\n",
            "Epoch: 684 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.022 cost-time: 0.07 s\n",
            "15-step perplexity: 1.021 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.08 s\n",
            "Epoch: 684 Train Perplexity: 1.020\n",
            "Epoch: 685 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.09 s\n",
            "10-step perplexity: 1.024 cost-time: 0.07 s\n",
            "15-step perplexity: 1.027 cost-time: 0.07 s\n",
            "20-step perplexity: 1.025 cost-time: 0.07 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 685 Train Perplexity: 1.024\n",
            "Epoch: 686 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.09 s\n",
            "10-step perplexity: 1.028 cost-time: 0.07 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.025 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.08 s\n",
            "Epoch: 686 Train Perplexity: 1.023\n",
            "Epoch: 687 Learning rate: 0.0010\n",
            "5-step perplexity: 1.035 cost-time: 0.09 s\n",
            "10-step perplexity: 1.027 cost-time: 0.08 s\n",
            "15-step perplexity: 1.026 cost-time: 0.07 s\n",
            "20-step perplexity: 1.024 cost-time: 0.08 s\n",
            "25-step perplexity: 1.023 cost-time: 0.07 s\n",
            "Epoch: 687 Train Perplexity: 1.024\n",
            "Epoch: 688 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.024 cost-time: 0.07 s\n",
            "15-step perplexity: 1.023 cost-time: 0.08 s\n",
            "20-step perplexity: 1.024 cost-time: 0.07 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 688 Train Perplexity: 1.024\n",
            "Epoch: 689 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.022 cost-time: 0.08 s\n",
            "25-step perplexity: 1.022 cost-time: 0.08 s\n",
            "Epoch: 689 Train Perplexity: 1.023\n",
            "Epoch: 690 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.09 s\n",
            "10-step perplexity: 1.028 cost-time: 0.07 s\n",
            "15-step perplexity: 1.026 cost-time: 0.08 s\n",
            "20-step perplexity: 1.026 cost-time: 0.08 s\n",
            "25-step perplexity: 1.025 cost-time: 0.07 s\n",
            "Epoch: 690 Train Perplexity: 1.025\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 691 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.09 s\n",
            "10-step perplexity: 1.027 cost-time: 0.09 s\n",
            "15-step perplexity: 1.027 cost-time: 0.08 s\n",
            "20-step perplexity: 1.025 cost-time: 0.07 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 691 Train Perplexity: 1.024\n",
            "Epoch: 692 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.019 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 692 Train Perplexity: 1.019\n",
            "Epoch: 693 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.023 cost-time: 0.07 s\n",
            "15-step perplexity: 1.024 cost-time: 0.08 s\n",
            "20-step perplexity: 1.022 cost-time: 0.07 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 693 Train Perplexity: 1.023\n",
            "Epoch: 694 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.07 s\n",
            "15-step perplexity: 1.021 cost-time: 0.08 s\n",
            "20-step perplexity: 1.021 cost-time: 0.07 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 694 Train Perplexity: 1.021\n",
            "Epoch: 695 Learning rate: 0.0010\n",
            "5-step perplexity: 1.032 cost-time: 0.10 s\n",
            "10-step perplexity: 1.026 cost-time: 0.08 s\n",
            "15-step perplexity: 1.029 cost-time: 0.08 s\n",
            "20-step perplexity: 1.027 cost-time: 0.09 s\n",
            "25-step perplexity: 1.025 cost-time: 0.08 s\n",
            "Epoch: 695 Train Perplexity: 1.025\n",
            "Epoch: 696 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.09 s\n",
            "10-step perplexity: 1.024 cost-time: 0.07 s\n",
            "15-step perplexity: 1.023 cost-time: 0.08 s\n",
            "20-step perplexity: 1.023 cost-time: 0.08 s\n",
            "25-step perplexity: 1.023 cost-time: 0.07 s\n",
            "Epoch: 696 Train Perplexity: 1.022\n",
            "Epoch: 697 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.023 cost-time: 0.08 s\n",
            "15-step perplexity: 1.023 cost-time: 0.08 s\n",
            "20-step perplexity: 1.022 cost-time: 0.08 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 697 Train Perplexity: 1.023\n",
            "Epoch: 698 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.09 s\n",
            "10-step perplexity: 1.027 cost-time: 0.07 s\n",
            "15-step perplexity: 1.027 cost-time: 0.07 s\n",
            "20-step perplexity: 1.026 cost-time: 0.07 s\n",
            "25-step perplexity: 1.025 cost-time: 0.07 s\n",
            "Epoch: 698 Train Perplexity: 1.024\n",
            "Epoch: 699 Learning rate: 0.0010\n",
            "5-step perplexity: 1.028 cost-time: 0.10 s\n",
            "10-step perplexity: 1.022 cost-time: 0.07 s\n",
            "15-step perplexity: 1.023 cost-time: 0.07 s\n",
            "20-step perplexity: 1.023 cost-time: 0.07 s\n",
            "25-step perplexity: 1.023 cost-time: 0.08 s\n",
            "Epoch: 699 Train Perplexity: 1.024\n",
            "Epoch: 700 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.09 s\n",
            "10-step perplexity: 1.027 cost-time: 0.07 s\n",
            "15-step perplexity: 1.025 cost-time: 0.08 s\n",
            "20-step perplexity: 1.025 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 700 Train Perplexity: 1.024\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 701 Learning rate: 0.0010\n",
            "5-step perplexity: 1.024 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.022 cost-time: 0.08 s\n",
            "25-step perplexity: 1.022 cost-time: 0.08 s\n",
            "Epoch: 701 Train Perplexity: 1.023\n",
            "Epoch: 702 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.09 s\n",
            "10-step perplexity: 1.021 cost-time: 0.07 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.07 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 702 Train Perplexity: 1.021\n",
            "Epoch: 703 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.022 cost-time: 0.08 s\n",
            "15-step perplexity: 1.024 cost-time: 0.08 s\n",
            "20-step perplexity: 1.023 cost-time: 0.07 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 703 Train Perplexity: 1.023\n",
            "Epoch: 704 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.09 s\n",
            "10-step perplexity: 1.023 cost-time: 0.07 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.022 cost-time: 0.07 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 704 Train Perplexity: 1.021\n",
            "Epoch: 705 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.07 s\n",
            "15-step perplexity: 1.025 cost-time: 0.07 s\n",
            "20-step perplexity: 1.024 cost-time: 0.07 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 705 Train Perplexity: 1.024\n",
            "Epoch: 706 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.08 s\n",
            "15-step perplexity: 1.022 cost-time: 0.08 s\n",
            "20-step perplexity: 1.022 cost-time: 0.08 s\n",
            "25-step perplexity: 1.022 cost-time: 0.08 s\n",
            "Epoch: 706 Train Perplexity: 1.021\n",
            "Epoch: 707 Learning rate: 0.0010\n",
            "5-step perplexity: 1.030 cost-time: 0.09 s\n",
            "10-step perplexity: 1.025 cost-time: 0.07 s\n",
            "15-step perplexity: 1.024 cost-time: 0.07 s\n",
            "20-step perplexity: 1.024 cost-time: 0.08 s\n",
            "25-step perplexity: 1.024 cost-time: 0.07 s\n",
            "Epoch: 707 Train Perplexity: 1.025\n",
            "Epoch: 708 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.021 cost-time: 0.07 s\n",
            "15-step perplexity: 1.019 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 708 Train Perplexity: 1.020\n",
            "Epoch: 709 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.023 cost-time: 0.07 s\n",
            "15-step perplexity: 1.024 cost-time: 0.08 s\n",
            "20-step perplexity: 1.024 cost-time: 0.08 s\n",
            "25-step perplexity: 1.023 cost-time: 0.08 s\n",
            "Epoch: 709 Train Perplexity: 1.024\n",
            "Epoch: 710 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.09 s\n",
            "10-step perplexity: 1.027 cost-time: 0.07 s\n",
            "15-step perplexity: 1.025 cost-time: 0.07 s\n",
            "20-step perplexity: 1.024 cost-time: 0.07 s\n",
            "25-step perplexity: 1.025 cost-time: 0.07 s\n",
            "Epoch: 710 Train Perplexity: 1.024\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 711 Learning rate: 0.0010\n",
            "5-step perplexity: 1.024 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.07 s\n",
            "15-step perplexity: 1.025 cost-time: 0.07 s\n",
            "20-step perplexity: 1.024 cost-time: 0.07 s\n",
            "25-step perplexity: 1.023 cost-time: 0.07 s\n",
            "Epoch: 711 Train Perplexity: 1.023\n",
            "Epoch: 712 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.023 cost-time: 0.08 s\n",
            "15-step perplexity: 1.023 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.07 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 712 Train Perplexity: 1.020\n",
            "Epoch: 713 Learning rate: 0.0010\n",
            "5-step perplexity: 1.034 cost-time: 0.10 s\n",
            "10-step perplexity: 1.027 cost-time: 0.07 s\n",
            "15-step perplexity: 1.025 cost-time: 0.08 s\n",
            "20-step perplexity: 1.023 cost-time: 0.08 s\n",
            "25-step perplexity: 1.023 cost-time: 0.07 s\n",
            "Epoch: 713 Train Perplexity: 1.023\n",
            "Epoch: 714 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.09 s\n",
            "10-step perplexity: 1.026 cost-time: 0.08 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.022 cost-time: 0.08 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 714 Train Perplexity: 1.022\n",
            "Epoch: 715 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.10 s\n",
            "10-step perplexity: 1.022 cost-time: 0.07 s\n",
            "15-step perplexity: 1.022 cost-time: 0.08 s\n",
            "20-step perplexity: 1.022 cost-time: 0.07 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 715 Train Perplexity: 1.022\n",
            "Epoch: 716 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.024 cost-time: 0.07 s\n",
            "15-step perplexity: 1.023 cost-time: 0.08 s\n",
            "20-step perplexity: 1.023 cost-time: 0.07 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 716 Train Perplexity: 1.021\n",
            "Epoch: 717 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.07 s\n",
            "15-step perplexity: 1.025 cost-time: 0.07 s\n",
            "20-step perplexity: 1.024 cost-time: 0.08 s\n",
            "25-step perplexity: 1.023 cost-time: 0.08 s\n",
            "Epoch: 717 Train Perplexity: 1.023\n",
            "Epoch: 718 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.021 cost-time: 0.08 s\n",
            "15-step perplexity: 1.021 cost-time: 0.08 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 718 Train Perplexity: 1.020\n",
            "Epoch: 719 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.07 s\n",
            "15-step perplexity: 1.020 cost-time: 0.08 s\n",
            "20-step perplexity: 1.021 cost-time: 0.07 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 719 Train Perplexity: 1.021\n",
            "Epoch: 720 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.07 s\n",
            "15-step perplexity: 1.019 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 720 Train Perplexity: 1.020\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 721 Learning rate: 0.0010\n",
            "5-step perplexity: 1.024 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.022 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 721 Train Perplexity: 1.021\n",
            "Epoch: 722 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.07 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 722 Train Perplexity: 1.020\n",
            "Epoch: 723 Learning rate: 0.0010\n",
            "5-step perplexity: 1.024 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.07 s\n",
            "15-step perplexity: 1.021 cost-time: 0.08 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 723 Train Perplexity: 1.020\n",
            "Epoch: 724 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.019 cost-time: 0.07 s\n",
            "20-step perplexity: 1.018 cost-time: 0.07 s\n",
            "25-step perplexity: 1.019 cost-time: 0.07 s\n",
            "Epoch: 724 Train Perplexity: 1.018\n",
            "Epoch: 725 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.10 s\n",
            "10-step perplexity: 1.021 cost-time: 0.07 s\n",
            "15-step perplexity: 1.023 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.09 s\n",
            "25-step perplexity: 1.021 cost-time: 0.08 s\n",
            "Epoch: 725 Train Perplexity: 1.022\n",
            "Epoch: 726 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.07 s\n",
            "15-step perplexity: 1.021 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 726 Train Perplexity: 1.021\n",
            "Epoch: 727 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.09 s\n",
            "10-step perplexity: 1.021 cost-time: 0.07 s\n",
            "15-step perplexity: 1.023 cost-time: 0.08 s\n",
            "20-step perplexity: 1.022 cost-time: 0.07 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 727 Train Perplexity: 1.020\n",
            "Epoch: 728 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.07 s\n",
            "25-step perplexity: 1.019 cost-time: 0.08 s\n",
            "Epoch: 728 Train Perplexity: 1.019\n",
            "Epoch: 729 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.08 s\n",
            "10-step perplexity: 1.024 cost-time: 0.07 s\n",
            "15-step perplexity: 1.025 cost-time: 0.07 s\n",
            "20-step perplexity: 1.024 cost-time: 0.08 s\n",
            "25-step perplexity: 1.025 cost-time: 0.08 s\n",
            "Epoch: 729 Train Perplexity: 1.025\n",
            "Epoch: 730 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.023 cost-time: 0.08 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 730 Train Perplexity: 1.021\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 731 Learning rate: 0.0010\n",
            "5-step perplexity: 1.028 cost-time: 0.10 s\n",
            "10-step perplexity: 1.023 cost-time: 0.07 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.023 cost-time: 0.07 s\n",
            "25-step perplexity: 1.023 cost-time: 0.07 s\n",
            "Epoch: 731 Train Perplexity: 1.023\n",
            "Epoch: 732 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.020 cost-time: 0.09 s\n",
            "25-step perplexity: 1.020 cost-time: 0.08 s\n",
            "Epoch: 732 Train Perplexity: 1.019\n",
            "Epoch: 733 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.023 cost-time: 0.08 s\n",
            "15-step perplexity: 1.024 cost-time: 0.08 s\n",
            "20-step perplexity: 1.023 cost-time: 0.07 s\n",
            "25-step perplexity: 1.022 cost-time: 0.08 s\n",
            "Epoch: 733 Train Perplexity: 1.023\n",
            "Epoch: 734 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.021 cost-time: 0.07 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.08 s\n",
            "Epoch: 734 Train Perplexity: 1.021\n",
            "Epoch: 735 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.07 s\n",
            "25-step perplexity: 1.020 cost-time: 0.08 s\n",
            "Epoch: 735 Train Perplexity: 1.020\n",
            "Epoch: 736 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.07 s\n",
            "25-step perplexity: 1.020 cost-time: 0.08 s\n",
            "Epoch: 736 Train Perplexity: 1.019\n",
            "Epoch: 737 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.10 s\n",
            "10-step perplexity: 1.021 cost-time: 0.07 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.023 cost-time: 0.07 s\n",
            "25-step perplexity: 1.022 cost-time: 0.08 s\n",
            "Epoch: 737 Train Perplexity: 1.022\n",
            "Epoch: 738 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.09 s\n",
            "10-step perplexity: 1.026 cost-time: 0.08 s\n",
            "15-step perplexity: 1.023 cost-time: 0.08 s\n",
            "20-step perplexity: 1.023 cost-time: 0.08 s\n",
            "25-step perplexity: 1.023 cost-time: 0.07 s\n",
            "Epoch: 738 Train Perplexity: 1.021\n",
            "Epoch: 739 Learning rate: 0.0010\n",
            "5-step perplexity: 1.034 cost-time: 0.09 s\n",
            "10-step perplexity: 1.026 cost-time: 0.07 s\n",
            "15-step perplexity: 1.023 cost-time: 0.08 s\n",
            "20-step perplexity: 1.022 cost-time: 0.07 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 739 Train Perplexity: 1.022\n",
            "Epoch: 740 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 740 Train Perplexity: 1.021\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 741 Learning rate: 0.0010\n",
            "5-step perplexity: 1.028 cost-time: 0.10 s\n",
            "10-step perplexity: 1.025 cost-time: 0.07 s\n",
            "15-step perplexity: 1.025 cost-time: 0.08 s\n",
            "20-step perplexity: 1.022 cost-time: 0.07 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 741 Train Perplexity: 1.022\n",
            "Epoch: 742 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.09 s\n",
            "10-step perplexity: 1.024 cost-time: 0.09 s\n",
            "15-step perplexity: 1.022 cost-time: 0.08 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.08 s\n",
            "Epoch: 742 Train Perplexity: 1.021\n",
            "Epoch: 743 Learning rate: 0.0010\n",
            "5-step perplexity: 1.024 cost-time: 0.10 s\n",
            "10-step perplexity: 1.023 cost-time: 0.07 s\n",
            "15-step perplexity: 1.023 cost-time: 0.07 s\n",
            "20-step perplexity: 1.022 cost-time: 0.07 s\n",
            "25-step perplexity: 1.021 cost-time: 0.08 s\n",
            "Epoch: 743 Train Perplexity: 1.021\n",
            "Epoch: 744 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.023 cost-time: 0.08 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.022 cost-time: 0.07 s\n",
            "25-step perplexity: 1.022 cost-time: 0.08 s\n",
            "Epoch: 744 Train Perplexity: 1.022\n",
            "Epoch: 745 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.021 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.08 s\n",
            "Epoch: 745 Train Perplexity: 1.020\n",
            "Epoch: 746 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.09 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 746 Train Perplexity: 1.020\n",
            "Epoch: 747 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.07 s\n",
            "15-step perplexity: 1.021 cost-time: 0.08 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 747 Train Perplexity: 1.021\n",
            "Epoch: 748 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.021 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.08 s\n",
            "20-step perplexity: 1.020 cost-time: 0.07 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 748 Train Perplexity: 1.019\n",
            "Epoch: 749 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.023 cost-time: 0.08 s\n",
            "15-step perplexity: 1.023 cost-time: 0.07 s\n",
            "20-step perplexity: 1.023 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 749 Train Perplexity: 1.022\n",
            "Epoch: 750 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.020 cost-time: 0.07 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 750 Train Perplexity: 1.020\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 751 Learning rate: 0.0010\n",
            "5-step perplexity: 1.029 cost-time: 0.11 s\n",
            "10-step perplexity: 1.025 cost-time: 0.08 s\n",
            "15-step perplexity: 1.024 cost-time: 0.08 s\n",
            "20-step perplexity: 1.023 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.08 s\n",
            "Epoch: 751 Train Perplexity: 1.022\n",
            "Epoch: 752 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.020 cost-time: 0.09 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 752 Train Perplexity: 1.019\n",
            "Epoch: 753 Learning rate: 0.0010\n",
            "5-step perplexity: 1.024 cost-time: 0.10 s\n",
            "10-step perplexity: 1.021 cost-time: 0.08 s\n",
            "15-step perplexity: 1.024 cost-time: 0.07 s\n",
            "20-step perplexity: 1.023 cost-time: 0.08 s\n",
            "25-step perplexity: 1.022 cost-time: 0.08 s\n",
            "Epoch: 753 Train Perplexity: 1.022\n",
            "Epoch: 754 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.021 cost-time: 0.07 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.09 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 754 Train Perplexity: 1.020\n",
            "Epoch: 755 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.019 cost-time: 0.07 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.09 s\n",
            "Epoch: 755 Train Perplexity: 1.018\n",
            "Epoch: 756 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.09 s\n",
            "10-step perplexity: 1.021 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.08 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.08 s\n",
            "Epoch: 756 Train Perplexity: 1.020\n",
            "Epoch: 757 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.10 s\n",
            "10-step perplexity: 1.023 cost-time: 0.08 s\n",
            "15-step perplexity: 1.023 cost-time: 0.08 s\n",
            "20-step perplexity: 1.023 cost-time: 0.07 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 757 Train Perplexity: 1.021\n",
            "Epoch: 758 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.09 s\n",
            "10-step perplexity: 1.026 cost-time: 0.08 s\n",
            "15-step perplexity: 1.023 cost-time: 0.07 s\n",
            "20-step perplexity: 1.022 cost-time: 0.07 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 758 Train Perplexity: 1.020\n",
            "Epoch: 759 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.08 s\n",
            "15-step perplexity: 1.023 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 759 Train Perplexity: 1.020\n",
            "Epoch: 760 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.07 s\n",
            "Epoch: 760 Train Perplexity: 1.018\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 761 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 761 Train Perplexity: 1.020\n",
            "Epoch: 762 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.09 s\n",
            "10-step perplexity: 1.022 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.08 s\n",
            "Epoch: 762 Train Perplexity: 1.020\n",
            "Epoch: 763 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.09 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.017 cost-time: 0.07 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 763 Train Perplexity: 1.019\n",
            "Epoch: 764 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.021 cost-time: 0.08 s\n",
            "15-step perplexity: 1.021 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.07 s\n",
            "25-step perplexity: 1.020 cost-time: 0.08 s\n",
            "Epoch: 764 Train Perplexity: 1.018\n",
            "Epoch: 765 Learning rate: 0.0010\n",
            "5-step perplexity: 1.030 cost-time: 0.10 s\n",
            "10-step perplexity: 1.024 cost-time: 0.08 s\n",
            "15-step perplexity: 1.024 cost-time: 0.07 s\n",
            "20-step perplexity: 1.022 cost-time: 0.07 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 765 Train Perplexity: 1.022\n",
            "Epoch: 766 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 766 Train Perplexity: 1.020\n",
            "Epoch: 767 Learning rate: 0.0010\n",
            "5-step perplexity: 1.024 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.021 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.07 s\n",
            "25-step perplexity: 1.019 cost-time: 0.08 s\n",
            "Epoch: 767 Train Perplexity: 1.020\n",
            "Epoch: 768 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.07 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 768 Train Perplexity: 1.020\n",
            "Epoch: 769 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.08 s\n",
            "Epoch: 769 Train Perplexity: 1.019\n",
            "Epoch: 770 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.021 cost-time: 0.07 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.07 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 770 Train Perplexity: 1.019\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 771 Learning rate: 0.0010\n",
            "5-step perplexity: 1.030 cost-time: 0.10 s\n",
            "10-step perplexity: 1.023 cost-time: 0.08 s\n",
            "15-step perplexity: 1.021 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.07 s\n",
            "25-step perplexity: 1.020 cost-time: 0.08 s\n",
            "Epoch: 771 Train Perplexity: 1.021\n",
            "Epoch: 772 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.07 s\n",
            "15-step perplexity: 1.021 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 772 Train Perplexity: 1.020\n",
            "Epoch: 773 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 773 Train Perplexity: 1.017\n",
            "Epoch: 774 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.021 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 774 Train Perplexity: 1.017\n",
            "Epoch: 775 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.07 s\n",
            "25-step perplexity: 1.019 cost-time: 0.08 s\n",
            "Epoch: 775 Train Perplexity: 1.020\n",
            "Epoch: 776 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.09 s\n",
            "10-step perplexity: 1.018 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 776 Train Perplexity: 1.019\n",
            "Epoch: 777 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.023 cost-time: 0.08 s\n",
            "25-step perplexity: 1.022 cost-time: 0.07 s\n",
            "Epoch: 777 Train Perplexity: 1.022\n",
            "Epoch: 778 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.07 s\n",
            "20-step perplexity: 1.018 cost-time: 0.07 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 778 Train Perplexity: 1.017\n",
            "Epoch: 779 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.09 s\n",
            "10-step perplexity: 1.021 cost-time: 0.08 s\n",
            "15-step perplexity: 1.021 cost-time: 0.08 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.08 s\n",
            "Epoch: 779 Train Perplexity: 1.021\n",
            "Epoch: 780 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 780 Train Perplexity: 1.017\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 781 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.11 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.021 cost-time: 0.08 s\n",
            "20-step perplexity: 1.020 cost-time: 0.09 s\n",
            "25-step perplexity: 1.019 cost-time: 0.07 s\n",
            "Epoch: 781 Train Perplexity: 1.019\n",
            "Epoch: 782 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.08 s\n",
            "Epoch: 782 Train Perplexity: 1.020\n",
            "Epoch: 783 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.09 s\n",
            "10-step perplexity: 1.021 cost-time: 0.08 s\n",
            "15-step perplexity: 1.022 cost-time: 0.08 s\n",
            "20-step perplexity: 1.022 cost-time: 0.07 s\n",
            "25-step perplexity: 1.020 cost-time: 0.08 s\n",
            "Epoch: 783 Train Perplexity: 1.020\n",
            "Epoch: 784 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 784 Train Perplexity: 1.018\n",
            "Epoch: 785 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.09 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 785 Train Perplexity: 1.019\n",
            "Epoch: 786 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.08 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 786 Train Perplexity: 1.019\n",
            "Epoch: 787 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.10 s\n",
            "10-step perplexity: 1.023 cost-time: 0.08 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.08 s\n",
            "Epoch: 787 Train Perplexity: 1.020\n",
            "Epoch: 788 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.07 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.07 s\n",
            "Epoch: 788 Train Perplexity: 1.020\n",
            "Epoch: 789 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.07 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 789 Train Perplexity: 1.017\n",
            "Epoch: 790 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.07 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 790 Train Perplexity: 1.017\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 791 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.09 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.07 s\n",
            "Epoch: 791 Train Perplexity: 1.019\n",
            "Epoch: 792 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 792 Train Perplexity: 1.018\n",
            "Epoch: 793 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 793 Train Perplexity: 1.018\n",
            "Epoch: 794 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.09 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 794 Train Perplexity: 1.017\n",
            "Epoch: 795 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.021 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.08 s\n",
            "Epoch: 795 Train Perplexity: 1.019\n",
            "Epoch: 796 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.07 s\n",
            "Epoch: 796 Train Perplexity: 1.018\n",
            "Epoch: 797 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.09 s\n",
            "20-step perplexity: 1.020 cost-time: 0.07 s\n",
            "25-step perplexity: 1.019 cost-time: 0.07 s\n",
            "Epoch: 797 Train Perplexity: 1.019\n",
            "Epoch: 798 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.021 cost-time: 0.07 s\n",
            "Epoch: 798 Train Perplexity: 1.020\n",
            "Epoch: 799 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.09 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.07 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 799 Train Perplexity: 1.018\n",
            "Epoch: 800 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.09 s\n",
            "25-step perplexity: 1.019 cost-time: 0.08 s\n",
            "Epoch: 800 Train Perplexity: 1.018\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 801 Learning rate: 0.0010\n",
            "5-step perplexity: 1.027 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.021 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.07 s\n",
            "Epoch: 801 Train Perplexity: 1.019\n",
            "Epoch: 802 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.07 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 802 Train Perplexity: 1.017\n",
            "Epoch: 803 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.09 s\n",
            "10-step perplexity: 1.017 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.07 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 803 Train Perplexity: 1.017\n",
            "Epoch: 804 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.09 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 804 Train Perplexity: 1.018\n",
            "Epoch: 805 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.10 s\n",
            "10-step perplexity: 1.023 cost-time: 0.07 s\n",
            "15-step perplexity: 1.023 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 805 Train Perplexity: 1.020\n",
            "Epoch: 806 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.07 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 806 Train Perplexity: 1.018\n",
            "Epoch: 807 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 807 Train Perplexity: 1.019\n",
            "Epoch: 808 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 808 Train Perplexity: 1.018\n",
            "Epoch: 809 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.07 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 809 Train Perplexity: 1.019\n",
            "Epoch: 810 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.09 s\n",
            "10-step perplexity: 1.018 cost-time: 0.07 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.07 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 810 Train Perplexity: 1.016\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 811 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 811 Train Perplexity: 1.019\n",
            "Epoch: 812 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.09 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.07 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 812 Train Perplexity: 1.017\n",
            "Epoch: 813 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.09 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.07 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 813 Train Perplexity: 1.018\n",
            "Epoch: 814 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.021 cost-time: 0.07 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 814 Train Perplexity: 1.018\n",
            "Epoch: 815 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.09 s\n",
            "10-step perplexity: 1.018 cost-time: 0.07 s\n",
            "15-step perplexity: 1.019 cost-time: 0.07 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 815 Train Perplexity: 1.018\n",
            "Epoch: 816 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.07 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 816 Train Perplexity: 1.017\n",
            "Epoch: 817 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.021 cost-time: 0.07 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.08 s\n",
            "Epoch: 817 Train Perplexity: 1.020\n",
            "Epoch: 818 Learning rate: 0.0010\n",
            "5-step perplexity: 1.010 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.07 s\n",
            "15-step perplexity: 1.014 cost-time: 0.07 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 818 Train Perplexity: 1.015\n",
            "Epoch: 819 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.021 cost-time: 0.07 s\n",
            "15-step perplexity: 1.022 cost-time: 0.07 s\n",
            "20-step perplexity: 1.021 cost-time: 0.08 s\n",
            "25-step perplexity: 1.020 cost-time: 0.07 s\n",
            "Epoch: 819 Train Perplexity: 1.020\n",
            "Epoch: 820 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.07 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 820 Train Perplexity: 1.017\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 821 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.07 s\n",
            "Epoch: 821 Train Perplexity: 1.020\n",
            "Epoch: 822 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.09 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.07 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 822 Train Perplexity: 1.017\n",
            "Epoch: 823 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.07 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.07 s\n",
            "Epoch: 823 Train Perplexity: 1.019\n",
            "Epoch: 824 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.07 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.07 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 824 Train Perplexity: 1.017\n",
            "Epoch: 825 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.07 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 825 Train Perplexity: 1.018\n",
            "Epoch: 826 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.07 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 826 Train Perplexity: 1.017\n",
            "Epoch: 827 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.07 s\n",
            "15-step perplexity: 1.017 cost-time: 0.07 s\n",
            "20-step perplexity: 1.017 cost-time: 0.07 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 827 Train Perplexity: 1.017\n",
            "Epoch: 828 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.07 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 828 Train Perplexity: 1.016\n",
            "Epoch: 829 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.09 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 829 Train Perplexity: 1.017\n",
            "Epoch: 830 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.09 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 830 Train Perplexity: 1.018\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 831 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.11 s\n",
            "10-step perplexity: 1.014 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.07 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 831 Train Perplexity: 1.016\n",
            "Epoch: 832 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.09 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.07 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.08 s\n",
            "Epoch: 832 Train Perplexity: 1.018\n",
            "Epoch: 833 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 833 Train Perplexity: 1.018\n",
            "Epoch: 834 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.07 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 834 Train Perplexity: 1.016\n",
            "Epoch: 835 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.09 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.07 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 835 Train Perplexity: 1.017\n",
            "Epoch: 836 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.11 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.07 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 836 Train Perplexity: 1.016\n",
            "Epoch: 837 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.09 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.07 s\n",
            "20-step perplexity: 1.017 cost-time: 0.07 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 837 Train Perplexity: 1.017\n",
            "Epoch: 838 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 838 Train Perplexity: 1.018\n",
            "Epoch: 839 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.07 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 839 Train Perplexity: 1.018\n",
            "Epoch: 840 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.09 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.07 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 840 Train Perplexity: 1.016\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 841 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.07 s\n",
            "15-step perplexity: 1.017 cost-time: 0.07 s\n",
            "20-step perplexity: 1.017 cost-time: 0.09 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 841 Train Perplexity: 1.017\n",
            "Epoch: 842 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 842 Train Perplexity: 1.016\n",
            "Epoch: 843 Learning rate: 0.0010\n",
            "5-step perplexity: 1.024 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 843 Train Perplexity: 1.018\n",
            "Epoch: 844 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.09 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 844 Train Perplexity: 1.017\n",
            "Epoch: 845 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.09 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.07 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 845 Train Perplexity: 1.017\n",
            "Epoch: 846 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.021 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.07 s\n",
            "Epoch: 846 Train Perplexity: 1.018\n",
            "Epoch: 847 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.07 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.019 cost-time: 0.07 s\n",
            "25-step perplexity: 1.019 cost-time: 0.08 s\n",
            "Epoch: 847 Train Perplexity: 1.019\n",
            "Epoch: 848 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.09 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 848 Train Perplexity: 1.016\n",
            "Epoch: 849 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 849 Train Perplexity: 1.018\n",
            "Epoch: 850 Learning rate: 0.0010\n",
            "5-step perplexity: 1.010 cost-time: 0.09 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 850 Train Perplexity: 1.015\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 851 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.07 s\n",
            "20-step perplexity: 1.018 cost-time: 0.09 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 851 Train Perplexity: 1.016\n",
            "Epoch: 852 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.07 s\n",
            "20-step perplexity: 1.016 cost-time: 0.07 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 852 Train Perplexity: 1.016\n",
            "Epoch: 853 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.10 s\n",
            "10-step perplexity: 1.021 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.08 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.07 s\n",
            "Epoch: 853 Train Perplexity: 1.019\n",
            "Epoch: 854 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.08 s\n",
            "20-step perplexity: 1.020 cost-time: 0.10 s\n",
            "25-step perplexity: 1.019 cost-time: 0.08 s\n",
            "Epoch: 854 Train Perplexity: 1.018\n",
            "Epoch: 855 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.09 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.07 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 855 Train Perplexity: 1.018\n",
            "Epoch: 856 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 856 Train Perplexity: 1.015\n",
            "Epoch: 857 Learning rate: 0.0010\n",
            "5-step perplexity: 1.024 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.022 cost-time: 0.08 s\n",
            "20-step perplexity: 1.020 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.08 s\n",
            "Epoch: 857 Train Perplexity: 1.019\n",
            "Epoch: 858 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.09 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 858 Train Perplexity: 1.017\n",
            "Epoch: 859 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 859 Train Perplexity: 1.018\n",
            "Epoch: 860 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 860 Train Perplexity: 1.016\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 861 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 861 Train Perplexity: 1.016\n",
            "Epoch: 862 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 862 Train Perplexity: 1.017\n",
            "Epoch: 863 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.07 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 863 Train Perplexity: 1.019\n",
            "Epoch: 864 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.09 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 864 Train Perplexity: 1.016\n",
            "Epoch: 865 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.09 s\n",
            "20-step perplexity: 1.018 cost-time: 0.07 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 865 Train Perplexity: 1.017\n",
            "Epoch: 866 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.12 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.07 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 866 Train Perplexity: 1.016\n",
            "Epoch: 867 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.12 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.07 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 867 Train Perplexity: 1.017\n",
            "Epoch: 868 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 868 Train Perplexity: 1.016\n",
            "Epoch: 869 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.07 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 869 Train Perplexity: 1.015\n",
            "Epoch: 870 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.09 s\n",
            "15-step perplexity: 1.015 cost-time: 0.07 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 870 Train Perplexity: 1.017\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 871 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.11 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.07 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 871 Train Perplexity: 1.017\n",
            "Epoch: 872 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.07 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 872 Train Perplexity: 1.016\n",
            "Epoch: 873 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.09 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 873 Train Perplexity: 1.017\n",
            "Epoch: 874 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.09 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 874 Train Perplexity: 1.016\n",
            "Epoch: 875 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 875 Train Perplexity: 1.018\n",
            "Epoch: 876 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.09 s\n",
            "20-step perplexity: 1.015 cost-time: 0.07 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 876 Train Perplexity: 1.015\n",
            "Epoch: 877 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.07 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 877 Train Perplexity: 1.016\n",
            "Epoch: 878 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.10 s\n",
            "10-step perplexity: 1.021 cost-time: 0.07 s\n",
            "15-step perplexity: 1.020 cost-time: 0.07 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 878 Train Perplexity: 1.018\n",
            "Epoch: 879 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.09 s\n",
            "20-step perplexity: 1.018 cost-time: 0.07 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 879 Train Perplexity: 1.017\n",
            "Epoch: 880 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.07 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 880 Train Perplexity: 1.017\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 881 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 881 Train Perplexity: 1.017\n",
            "Epoch: 882 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 882 Train Perplexity: 1.016\n",
            "Epoch: 883 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.11 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.09 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 883 Train Perplexity: 1.017\n",
            "Epoch: 884 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.09 s\n",
            "10-step perplexity: 1.020 cost-time: 0.09 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 884 Train Perplexity: 1.017\n",
            "Epoch: 885 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.07 s\n",
            "15-step perplexity: 1.014 cost-time: 0.07 s\n",
            "20-step perplexity: 1.015 cost-time: 0.07 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 885 Train Perplexity: 1.015\n",
            "Epoch: 886 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 886 Train Perplexity: 1.015\n",
            "Epoch: 887 Learning rate: 0.0010\n",
            "5-step perplexity: 1.021 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.07 s\n",
            "25-step perplexity: 1.018 cost-time: 0.08 s\n",
            "Epoch: 887 Train Perplexity: 1.019\n",
            "Epoch: 888 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.07 s\n",
            "20-step perplexity: 1.016 cost-time: 0.07 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 888 Train Perplexity: 1.016\n",
            "Epoch: 889 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.11 s\n",
            "10-step perplexity: 1.015 cost-time: 0.07 s\n",
            "15-step perplexity: 1.018 cost-time: 0.07 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 889 Train Perplexity: 1.015\n",
            "Epoch: 890 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.07 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 890 Train Perplexity: 1.016\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 891 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.07 s\n",
            "25-step perplexity: 1.014 cost-time: 0.07 s\n",
            "Epoch: 891 Train Perplexity: 1.016\n",
            "Epoch: 892 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 892 Train Perplexity: 1.016\n",
            "Epoch: 893 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.10 s\n",
            "10-step perplexity: 1.013 cost-time: 0.07 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 893 Train Perplexity: 1.015\n",
            "Epoch: 894 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.09 s\n",
            "10-step perplexity: 1.013 cost-time: 0.08 s\n",
            "15-step perplexity: 1.012 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 894 Train Perplexity: 1.015\n",
            "Epoch: 895 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.09 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 895 Train Perplexity: 1.017\n",
            "Epoch: 896 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.09 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.07 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 896 Train Perplexity: 1.015\n",
            "Epoch: 897 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.09 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 897 Train Perplexity: 1.016\n",
            "Epoch: 898 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.10 s\n",
            "10-step perplexity: 1.013 cost-time: 0.07 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.09 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 898 Train Perplexity: 1.015\n",
            "Epoch: 899 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.07 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.07 s\n",
            "Epoch: 899 Train Perplexity: 1.015\n",
            "Epoch: 900 Learning rate: 0.0010\n",
            "5-step perplexity: 1.008 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.07 s\n",
            "15-step perplexity: 1.013 cost-time: 0.08 s\n",
            "20-step perplexity: 1.013 cost-time: 0.08 s\n",
            "25-step perplexity: 1.013 cost-time: 0.07 s\n",
            "Epoch: 900 Train Perplexity: 1.013\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 901 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.07 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 901 Train Perplexity: 1.017\n",
            "Epoch: 902 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 902 Train Perplexity: 1.015\n",
            "Epoch: 903 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.013 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 903 Train Perplexity: 1.015\n",
            "Epoch: 904 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.08 s\n",
            "Epoch: 904 Train Perplexity: 1.018\n",
            "Epoch: 905 Learning rate: 0.0010\n",
            "5-step perplexity: 1.022 cost-time: 0.10 s\n",
            "10-step perplexity: 1.019 cost-time: 0.07 s\n",
            "15-step perplexity: 1.020 cost-time: 0.08 s\n",
            "20-step perplexity: 1.018 cost-time: 0.08 s\n",
            "25-step perplexity: 1.018 cost-time: 0.07 s\n",
            "Epoch: 905 Train Perplexity: 1.018\n",
            "Epoch: 906 Learning rate: 0.0010\n",
            "5-step perplexity: 1.010 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.015 cost-time: 0.07 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 906 Train Perplexity: 1.014\n",
            "Epoch: 907 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.09 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.07 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 907 Train Perplexity: 1.017\n",
            "Epoch: 908 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.07 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 908 Train Perplexity: 1.015\n",
            "Epoch: 909 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.020 cost-time: 0.08 s\n",
            "20-step perplexity: 1.019 cost-time: 0.08 s\n",
            "25-step perplexity: 1.019 cost-time: 0.08 s\n",
            "Epoch: 909 Train Perplexity: 1.018\n",
            "Epoch: 910 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.09 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.09 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 910 Train Perplexity: 1.015\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 911 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.09 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 911 Train Perplexity: 1.016\n",
            "Epoch: 912 Learning rate: 0.0010\n",
            "5-step perplexity: 1.009 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 912 Train Perplexity: 1.014\n",
            "Epoch: 913 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 913 Train Perplexity: 1.018\n",
            "Epoch: 914 Learning rate: 0.0010\n",
            "5-step perplexity: 1.009 cost-time: 0.09 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.07 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 914 Train Perplexity: 1.015\n",
            "Epoch: 915 Learning rate: 0.0010\n",
            "5-step perplexity: 1.023 cost-time: 0.09 s\n",
            "10-step perplexity: 1.017 cost-time: 0.07 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 915 Train Perplexity: 1.015\n",
            "Epoch: 916 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 916 Train Perplexity: 1.015\n",
            "Epoch: 917 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 917 Train Perplexity: 1.015\n",
            "Epoch: 918 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 918 Train Perplexity: 1.015\n",
            "Epoch: 919 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.013 cost-time: 0.08 s\n",
            "15-step perplexity: 1.013 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.07 s\n",
            "Epoch: 919 Train Perplexity: 1.014\n",
            "Epoch: 920 Learning rate: 0.0010\n",
            "5-step perplexity: 1.009 cost-time: 0.10 s\n",
            "10-step perplexity: 1.012 cost-time: 0.07 s\n",
            "15-step perplexity: 1.012 cost-time: 0.08 s\n",
            "20-step perplexity: 1.013 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 920 Train Perplexity: 1.013\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 921 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.09 s\n",
            "Epoch: 921 Train Perplexity: 1.016\n",
            "Epoch: 922 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.07 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 922 Train Perplexity: 1.014\n",
            "Epoch: 923 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.09 s\n",
            "10-step perplexity: 1.017 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.09 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 923 Train Perplexity: 1.016\n",
            "Epoch: 924 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.09 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.07 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 924 Train Perplexity: 1.014\n",
            "Epoch: 925 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.07 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 925 Train Perplexity: 1.015\n",
            "Epoch: 926 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.09 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 926 Train Perplexity: 1.014\n",
            "Epoch: 927 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.09 s\n",
            "10-step perplexity: 1.015 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.07 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 927 Train Perplexity: 1.016\n",
            "Epoch: 928 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.09 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.07 s\n",
            "Epoch: 928 Train Perplexity: 1.016\n",
            "Epoch: 929 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.013 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.07 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.013 cost-time: 0.08 s\n",
            "Epoch: 929 Train Perplexity: 1.014\n",
            "Epoch: 930 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.09 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.015 cost-time: 0.07 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 930 Train Perplexity: 1.015\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 931 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 931 Train Perplexity: 1.015\n",
            "Epoch: 932 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.07 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 932 Train Perplexity: 1.014\n",
            "Epoch: 933 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.013 cost-time: 0.07 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 933 Train Perplexity: 1.015\n",
            "Epoch: 934 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.09 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 934 Train Perplexity: 1.015\n",
            "Epoch: 935 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 935 Train Perplexity: 1.015\n",
            "Epoch: 936 Learning rate: 0.0010\n",
            "5-step perplexity: 1.009 cost-time: 0.10 s\n",
            "10-step perplexity: 1.010 cost-time: 0.07 s\n",
            "15-step perplexity: 1.011 cost-time: 0.08 s\n",
            "20-step perplexity: 1.012 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 936 Train Perplexity: 1.013\n",
            "Epoch: 937 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.09 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.07 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 937 Train Perplexity: 1.015\n",
            "Epoch: 938 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.11 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 938 Train Perplexity: 1.016\n",
            "Epoch: 939 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.09 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 939 Train Perplexity: 1.015\n",
            "Epoch: 940 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 940 Train Perplexity: 1.016\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 941 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.07 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 941 Train Perplexity: 1.016\n",
            "Epoch: 942 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.09 s\n",
            "10-step perplexity: 1.013 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 942 Train Perplexity: 1.013\n",
            "Epoch: 943 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.07 s\n",
            "Epoch: 943 Train Perplexity: 1.014\n",
            "Epoch: 944 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 944 Train Perplexity: 1.015\n",
            "Epoch: 945 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.10 s\n",
            "10-step perplexity: 1.012 cost-time: 0.08 s\n",
            "15-step perplexity: 1.013 cost-time: 0.08 s\n",
            "20-step perplexity: 1.013 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 945 Train Perplexity: 1.014\n",
            "Epoch: 946 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 946 Train Perplexity: 1.015\n",
            "Epoch: 947 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.11 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.09 s\n",
            "Epoch: 947 Train Perplexity: 1.016\n",
            "Epoch: 948 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.09 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 948 Train Perplexity: 1.015\n",
            "Epoch: 949 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.07 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 949 Train Perplexity: 1.016\n",
            "Epoch: 950 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.09 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.013 cost-time: 0.08 s\n",
            "25-step perplexity: 1.013 cost-time: 0.08 s\n",
            "Epoch: 950 Train Perplexity: 1.013\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 951 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.07 s\n",
            "Epoch: 951 Train Perplexity: 1.014\n",
            "Epoch: 952 Learning rate: 0.0010\n",
            "5-step perplexity: 1.010 cost-time: 0.09 s\n",
            "10-step perplexity: 1.013 cost-time: 0.08 s\n",
            "15-step perplexity: 1.013 cost-time: 0.08 s\n",
            "20-step perplexity: 1.013 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 952 Train Perplexity: 1.014\n",
            "Epoch: 953 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.09 s\n",
            "10-step perplexity: 1.014 cost-time: 0.07 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.07 s\n",
            "Epoch: 953 Train Perplexity: 1.014\n",
            "Epoch: 954 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.09 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 954 Train Perplexity: 1.015\n",
            "Epoch: 955 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 955 Train Perplexity: 1.017\n",
            "Epoch: 956 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.018 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 956 Train Perplexity: 1.015\n",
            "Epoch: 957 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.12 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 957 Train Perplexity: 1.015\n",
            "Epoch: 958 Learning rate: 0.0010\n",
            "5-step perplexity: 1.014 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 958 Train Perplexity: 1.014\n",
            "Epoch: 959 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.07 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 959 Train Perplexity: 1.016\n",
            "Epoch: 960 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.07 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 960 Train Perplexity: 1.013\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 961 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.07 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 961 Train Perplexity: 1.016\n",
            "Epoch: 962 Learning rate: 0.0010\n",
            "5-step perplexity: 1.010 cost-time: 0.10 s\n",
            "10-step perplexity: 1.011 cost-time: 0.08 s\n",
            "15-step perplexity: 1.010 cost-time: 0.09 s\n",
            "20-step perplexity: 1.011 cost-time: 0.07 s\n",
            "25-step perplexity: 1.011 cost-time: 0.08 s\n",
            "Epoch: 962 Train Perplexity: 1.012\n",
            "Epoch: 963 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 963 Train Perplexity: 1.015\n",
            "Epoch: 964 Learning rate: 0.0010\n",
            "5-step perplexity: 1.009 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.09 s\n",
            "Epoch: 964 Train Perplexity: 1.015\n",
            "Epoch: 965 Learning rate: 0.0010\n",
            "5-step perplexity: 1.025 cost-time: 0.09 s\n",
            "10-step perplexity: 1.019 cost-time: 0.08 s\n",
            "15-step perplexity: 1.018 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.017 cost-time: 0.08 s\n",
            "Epoch: 965 Train Perplexity: 1.016\n",
            "Epoch: 966 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 966 Train Perplexity: 1.015\n",
            "Epoch: 967 Learning rate: 0.0010\n",
            "5-step perplexity: 1.020 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.07 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.07 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 967 Train Perplexity: 1.015\n",
            "Epoch: 968 Learning rate: 0.0010\n",
            "5-step perplexity: 1.008 cost-time: 0.09 s\n",
            "10-step perplexity: 1.011 cost-time: 0.08 s\n",
            "15-step perplexity: 1.011 cost-time: 0.08 s\n",
            "20-step perplexity: 1.012 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 968 Train Perplexity: 1.014\n",
            "Epoch: 969 Learning rate: 0.0010\n",
            "5-step perplexity: 1.026 cost-time: 0.10 s\n",
            "10-step perplexity: 1.020 cost-time: 0.08 s\n",
            "15-step perplexity: 1.019 cost-time: 0.08 s\n",
            "20-step perplexity: 1.017 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 969 Train Perplexity: 1.016\n",
            "Epoch: 970 Learning rate: 0.0010\n",
            "5-step perplexity: 1.013 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.013 cost-time: 0.08 s\n",
            "Epoch: 970 Train Perplexity: 1.012\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 971 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.07 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 971 Train Perplexity: 1.015\n",
            "Epoch: 972 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.10 s\n",
            "10-step perplexity: 1.012 cost-time: 0.08 s\n",
            "15-step perplexity: 1.012 cost-time: 0.08 s\n",
            "20-step perplexity: 1.012 cost-time: 0.08 s\n",
            "25-step perplexity: 1.012 cost-time: 0.08 s\n",
            "Epoch: 972 Train Perplexity: 1.012\n",
            "Epoch: 973 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 973 Train Perplexity: 1.015\n",
            "Epoch: 974 Learning rate: 0.0010\n",
            "5-step perplexity: 1.009 cost-time: 0.10 s\n",
            "10-step perplexity: 1.012 cost-time: 0.07 s\n",
            "15-step perplexity: 1.013 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.07 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 974 Train Perplexity: 1.013\n",
            "Epoch: 975 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.012 cost-time: 0.07 s\n",
            "15-step perplexity: 1.013 cost-time: 0.07 s\n",
            "20-step perplexity: 1.013 cost-time: 0.07 s\n",
            "25-step perplexity: 1.014 cost-time: 0.07 s\n",
            "Epoch: 975 Train Perplexity: 1.014\n",
            "Epoch: 976 Learning rate: 0.0010\n",
            "5-step perplexity: 1.010 cost-time: 0.09 s\n",
            "10-step perplexity: 1.012 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 976 Train Perplexity: 1.014\n",
            "Epoch: 977 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.013 cost-time: 0.08 s\n",
            "15-step perplexity: 1.013 cost-time: 0.08 s\n",
            "20-step perplexity: 1.013 cost-time: 0.07 s\n",
            "25-step perplexity: 1.013 cost-time: 0.07 s\n",
            "Epoch: 977 Train Perplexity: 1.014\n",
            "Epoch: 978 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.013 cost-time: 0.07 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 978 Train Perplexity: 1.013\n",
            "Epoch: 979 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.015 cost-time: 0.07 s\n",
            "15-step perplexity: 1.014 cost-time: 0.07 s\n",
            "20-step perplexity: 1.015 cost-time: 0.09 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 979 Train Perplexity: 1.014\n",
            "Epoch: 980 Learning rate: 0.0010\n",
            "5-step perplexity: 1.009 cost-time: 0.09 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.013 cost-time: 0.08 s\n",
            "20-step perplexity: 1.013 cost-time: 0.08 s\n",
            "25-step perplexity: 1.013 cost-time: 0.07 s\n",
            "Epoch: 980 Train Perplexity: 1.013\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 981 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.07 s\n",
            "Epoch: 981 Train Perplexity: 1.015\n",
            "Epoch: 982 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.10 s\n",
            "10-step perplexity: 1.013 cost-time: 0.07 s\n",
            "15-step perplexity: 1.012 cost-time: 0.08 s\n",
            "20-step perplexity: 1.013 cost-time: 0.08 s\n",
            "25-step perplexity: 1.013 cost-time: 0.07 s\n",
            "Epoch: 982 Train Perplexity: 1.013\n",
            "Epoch: 983 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.013 cost-time: 0.07 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 983 Train Perplexity: 1.015\n",
            "Epoch: 984 Learning rate: 0.0010\n",
            "5-step perplexity: 1.011 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.07 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 984 Train Perplexity: 1.015\n",
            "Epoch: 985 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.07 s\n",
            "25-step perplexity: 1.015 cost-time: 0.08 s\n",
            "Epoch: 985 Train Perplexity: 1.015\n",
            "Epoch: 986 Learning rate: 0.0010\n",
            "5-step perplexity: 1.010 cost-time: 0.10 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.017 cost-time: 0.07 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 986 Train Perplexity: 1.015\n",
            "Epoch: 987 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.015 cost-time: 0.07 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 987 Train Perplexity: 1.015\n",
            "Epoch: 988 Learning rate: 0.0010\n",
            "5-step perplexity: 1.015 cost-time: 0.10 s\n",
            "10-step perplexity: 1.013 cost-time: 0.08 s\n",
            "15-step perplexity: 1.012 cost-time: 0.08 s\n",
            "20-step perplexity: 1.012 cost-time: 0.08 s\n",
            "25-step perplexity: 1.012 cost-time: 0.07 s\n",
            "Epoch: 988 Train Perplexity: 1.012\n",
            "Epoch: 989 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.11 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.07 s\n",
            "Epoch: 989 Train Perplexity: 1.014\n",
            "Epoch: 990 Learning rate: 0.0010\n",
            "5-step perplexity: 1.008 cost-time: 0.09 s\n",
            "10-step perplexity: 1.012 cost-time: 0.07 s\n",
            "15-step perplexity: 1.013 cost-time: 0.07 s\n",
            "20-step perplexity: 1.013 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 990 Train Perplexity: 1.013\n",
            "model saving ...\n",
            "Done!\n",
            "Epoch: 991 Learning rate: 0.0010\n",
            "5-step perplexity: 1.019 cost-time: 0.10 s\n",
            "10-step perplexity: 1.017 cost-time: 0.09 s\n",
            "15-step perplexity: 1.017 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.08 s\n",
            "25-step perplexity: 1.016 cost-time: 0.08 s\n",
            "Epoch: 991 Train Perplexity: 1.016\n",
            "Epoch: 992 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.10 s\n",
            "10-step perplexity: 1.012 cost-time: 0.08 s\n",
            "15-step perplexity: 1.012 cost-time: 0.08 s\n",
            "20-step perplexity: 1.012 cost-time: 0.07 s\n",
            "25-step perplexity: 1.013 cost-time: 0.08 s\n",
            "Epoch: 992 Train Perplexity: 1.013\n",
            "Epoch: 993 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.11 s\n",
            "10-step perplexity: 1.013 cost-time: 0.08 s\n",
            "15-step perplexity: 1.014 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.07 s\n",
            "25-step perplexity: 1.013 cost-time: 0.08 s\n",
            "Epoch: 993 Train Perplexity: 1.014\n",
            "Epoch: 994 Learning rate: 0.0010\n",
            "5-step perplexity: 1.010 cost-time: 0.10 s\n",
            "10-step perplexity: 1.014 cost-time: 0.07 s\n",
            "15-step perplexity: 1.015 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 994 Train Perplexity: 1.013\n",
            "Epoch: 995 Learning rate: 0.0010\n",
            "5-step perplexity: 1.018 cost-time: 0.09 s\n",
            "10-step perplexity: 1.016 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.015 cost-time: 0.08 s\n",
            "25-step perplexity: 1.015 cost-time: 0.07 s\n",
            "Epoch: 995 Train Perplexity: 1.014\n",
            "Epoch: 996 Learning rate: 0.0010\n",
            "5-step perplexity: 1.010 cost-time: 0.09 s\n",
            "10-step perplexity: 1.015 cost-time: 0.08 s\n",
            "15-step perplexity: 1.013 cost-time: 0.08 s\n",
            "20-step perplexity: 1.014 cost-time: 0.08 s\n",
            "25-step perplexity: 1.014 cost-time: 0.08 s\n",
            "Epoch: 996 Train Perplexity: 1.014\n",
            "Epoch: 997 Learning rate: 0.0010\n",
            "5-step perplexity: 1.017 cost-time: 0.10 s\n",
            "10-step perplexity: 1.013 cost-time: 0.07 s\n",
            "15-step perplexity: 1.013 cost-time: 0.09 s\n",
            "20-step perplexity: 1.013 cost-time: 0.07 s\n",
            "25-step perplexity: 1.013 cost-time: 0.07 s\n",
            "Epoch: 997 Train Perplexity: 1.013\n",
            "Epoch: 998 Learning rate: 0.0010\n",
            "5-step perplexity: 1.012 cost-time: 0.09 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.013 cost-time: 0.07 s\n",
            "20-step perplexity: 1.013 cost-time: 0.08 s\n",
            "25-step perplexity: 1.013 cost-time: 0.07 s\n",
            "Epoch: 998 Train Perplexity: 1.012\n",
            "Epoch: 999 Learning rate: 0.0010\n",
            "5-step perplexity: 1.016 cost-time: 0.09 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.016 cost-time: 0.08 s\n",
            "20-step perplexity: 1.016 cost-time: 0.07 s\n",
            "25-step perplexity: 1.016 cost-time: 0.07 s\n",
            "Epoch: 999 Train Perplexity: 1.015\n",
            "Epoch: 1000 Learning rate: 0.0010\n",
            "5-step perplexity: 1.010 cost-time: 0.09 s\n",
            "10-step perplexity: 1.014 cost-time: 0.08 s\n",
            "15-step perplexity: 1.013 cost-time: 0.07 s\n",
            "20-step perplexity: 1.013 cost-time: 0.08 s\n",
            "25-step perplexity: 1.013 cost-time: 0.08 s\n",
            "Epoch: 1000 Train Perplexity: 1.013\n",
            "model saving ...\n",
            "Done!\n",
            "2020-03-09 20:59:12.643331: W tensorflow/core/kernels/queue_base.cc:277] _0_model/input_producer: Skipping cancelled enqueue attempt with queue not closed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zsef3FKDTyf",
        "colab_type": "code",
        "outputId": "79f32cc4-379b-4d9c-d5e8-d11be74c643b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!python '/content/gdrive/My Drive/CourseAllocation_NLG/generation.py'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter Keywords:\n",
            "Dr.MehwishHassan\n",
            "DigitalLogicDesign\n",
            "EE227\n",
            "Batch2018\n",
            "sectionA\n",
            "Repeat\n",
            "['Dr.MehwishHassan', 'DigitalLogicDesign', 'EE227', 'Batch2018', 'sectionA', 'Repeat']\n",
            "2020-03-09 21:28:58.866006: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "WARNING:tensorflow:<SC_LSTM_Model.SC_LSTM object at 0x7fac22a0c320>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
            "model loading ...\n",
            "Done!\n",
            "b'Dr.MehwishHassan is teaching DigitalLogicDesign(EE227) to sectionA Batch2018 Repeat  '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbXSZI9eDTwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}